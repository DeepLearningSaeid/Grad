{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras -q\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Embedding, Dense, concatenate, Dropout, Flatten, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects, to_categorical, plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.datasets import load_iris, load_digits, load_wine, load_diabetes, load_breast_cancer, fetch_olivetti_faces, load_linnerud\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.datasets import load_digits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYXZP4_9n-R7",
        "outputId": "125217db-089b-4d96-caef-70c714fadaba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(110)\n",
        "\n",
        "# Define custom activation functions and update the custom objects dictionary\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: tf.pow(x, 1)),\n",
        "        ('X_2', lambda x: tf.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: tf.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: tf.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: tf.pow(x, 2) / 40320),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model(input_dim, hidden_dim, output_dim, metrics='accuracy', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    concat_first_layer = concatenate([layer_1_x1, layer_1_x2])\n",
        "\n",
        "    # Second layer with custom activations\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "\n",
        "    # Third layer with custom activations\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4)\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1, layer_1_x2, concat_first_layer,\n",
        "                                       layer_x3_x4, layer_x5_x6])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model with specified loss and metrics\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[metrics])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define custom activation functions and update the custom objects dictionary\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: tf.pow(x, 1)),\n",
        "        ('X_2', lambda x: tf.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: tf.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: tf.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: tf.pow(x, 2) / 40320),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model_normalization(input_dim, hidden_dim, output_dim, metrics='accuracy', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations and batch normalization\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x1_bn = BatchNormalization()(layer_1_x1)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    layer_1_x2_bn = BatchNormalization()(layer_1_x2)\n",
        "    concat_first_layer = concatenate([layer_1_x1_bn, layer_1_x2_bn])\n",
        "\n",
        "    # Second layer with custom activations and batch normalization\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "    layer_x3_x4_bn = BatchNormalization()(layer_x3_x4)\n",
        "\n",
        "    # Third layer with custom activations and batch normalization\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4_bn)\n",
        "    layer_x5_x6_bn = BatchNormalization()(layer_x5_x6)\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1_bn, layer_1_x2_bn, concat_first_layer,\n",
        "                                       layer_x3_x4_bn, layer_x5_x6_bn])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model with specified loss and metrics\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[metrics])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "xID7aH81K83q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized_model = create_optimized_model(784,784, 10)\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "8aQhT2LoKZDH",
        "outputId": "7e03cba6-5160-4f92-b98a-fe8240a19029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "600/600 [==============================] - 63s 102ms/step - loss: 0.0414 - accuracy: 0.8385 - val_loss: 0.0271 - val_accuracy: 0.9073\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 39s 66ms/step - loss: 0.0206 - accuracy: 0.9351 - val_loss: 0.0198 - val_accuracy: 0.9310\n",
            "Training time: 102.71956073799993 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "\n",
        "\n",
        "\n",
        "# # AutoKeras model\n",
        "# ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True) # Set max_trials to an appropriate number\n",
        "\n",
        "# start_ak = timeit.default_timer()\n",
        "# ak_model.fit(x_train, y_train, epochs=10)\n",
        "# end_ak = timeit.default_timer()\n",
        "# print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# # Evaluate AutoKeras model\n",
        "# _, ak_accuracy = ak_model.evaluate(x_test, y_test)\n",
        "# print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNTPp71EwH5",
        "outputId": "9f7fd3ef-69fa-46e8-88b8-b9e59aeb4d60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/2\n",
            "600/600 [==============================] - 41s 67ms/step - loss: 0.1087 - accuracy: 0.7825 - val_loss: 0.0333 - val_accuracy: 0.8359\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 39s 65ms/step - loss: 0.0297 - accuracy: 0.8539 - val_loss: 0.0293 - val_accuracy: 0.8466\n",
            "Training time: 83.34362924000015 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True) # Set max_trials to an appropriate number\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=10)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "_, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 10, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "start = timeit.default_timer()\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n",
        "\n",
        "# Evaluate your model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "KXztQpoaiuYu",
        "outputId": "4ed7373c-9ac4-4fd8-a43a-69a89b465108",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.875\n",
            "\n",
            "Best val_accuracy So Far: 0.875\n",
            "Total elapsed time: 00h 00m 08s\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 1.0760 - accuracy: 0.2917\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.5750\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9378 - accuracy: 0.6583\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8775 - accuracy: 0.6917\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.7167\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7714 - accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.7583\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.7833\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.8083\n",
            "AutoKeras Training time: 10.993139431999225 seconds\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.5441 - accuracy: 0.8000\n",
            "AutoKeras Model Accuracy: 0.800000011920929\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 17ms/step - loss: 0.5822 - accuracy: 0.3583 - val_loss: 0.3527 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.6167 - val_loss: 0.2073 - val_accuracy: 0.7000\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2183 - accuracy: 0.6583 - val_loss: 0.1513 - val_accuracy: 0.7333\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.7167 - val_loss: 0.1224 - val_accuracy: 0.7667\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.7667 - val_loss: 0.1004 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1075 - accuracy: 0.8250 - val_loss: 0.0854 - val_accuracy: 0.8667\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.8667 - val_loss: 0.0748 - val_accuracy: 0.9000\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.8917 - val_loss: 0.0693 - val_accuracy: 0.9333\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9250 - val_loss: 0.0682 - val_accuracy: 0.9333\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9250 - val_loss: 0.0655 - val_accuracy: 0.9333\n",
            "Training time: 1.7637999349999518 seconds\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0655 - accuracy: 0.9333\n",
            "SWAG Model Accuracy: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = to_categorical(digits.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 200, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEhk7EEBPb6",
        "outputId": "cf84b6e1-ffd0-4f91-837b-da2466475dd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 16s]\n",
            "val_accuracy: 0.761403501033783\n",
            "\n",
            "Best val_accuracy So Far: 0.8035087585449219\n",
            "Total elapsed time: 00h 01m 23s\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 1s 4ms/step - loss: 2.1807 - accuracy: 0.2331\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.6286 - accuracy: 0.5741\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1478 - accuracy: 0.7244\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.8123 - accuracy: 0.7808\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.8225\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.8476\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8740\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8914\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.9047\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.9200\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.4214 - accuracy: 0.8778\n",
            "AutoKeras Model Accuracy: 0.8777777552604675\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 5ms/step - loss: 0.0518 - accuracy: 0.8636\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9729\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0168 - accuracy: 0.9861\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9916\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 7ms/step - loss: 0.0122 - accuracy: 0.9923\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9833\n",
            "SWAG Accuracy: 0.9833333492279053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = to_categorical(wine.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "u6pEsuuoBPYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36015995-9405-4a19-b54d-8bdc19e0640c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.8571428656578064\n",
            "\n",
            "Best val_accuracy So Far: 0.9285714030265808\n",
            "Total elapsed time: 00h 00m 10s\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 6ms/step - loss: 1.2260 - accuracy: 0.2535\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1685 - accuracy: 0.2746\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0251 - accuracy: 0.4225\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9024 - accuracy: 0.6127\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8963 - accuracy: 0.5141\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9247 - accuracy: 0.5000\n",
            "AutoKeras Model Accuracy: 0.5\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 2s 3ms/step - loss: 0.3778 - accuracy: 0.1901\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.6338\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.8803\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9085\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9225\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 1.0000\n",
            "SWAG Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7N_ZWiPBPS2",
        "outputId": "3f2baab1-31a1-457e-8048-a1deb02d9b52"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 05s]\n",
            "val_accuracy: 0.9295774698257446\n",
            "\n",
            "Best val_accuracy So Far: 0.9718309640884399\n",
            "Total elapsed time: 00h 00m 16s\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.6681\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.9121\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9231\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2050 - accuracy: 0.9297\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9407\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9561\n",
            "AutoKeras Model Accuracy: 0.9561403393745422\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.6044\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.8901\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.8813\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9297\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9253\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9474\n",
            "Accuracy: 0.9473684430122375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Boston Housing data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "batch_size = 5\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "input_dim = X_train.shape[1]\n",
        "optimized_model = create_optimized_model(input_dim, input_dim , 1 , 'mae') # input_dim and hidden_dim\n",
        "\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "id": "Bh72fFHYpQ3R",
        "outputId": "3316e2ea-970e-4e5f-91ed-d25dfc48dd62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 10s]\n",
            "val_loss: 15.444204330444336\n",
            "\n",
            "Best val_loss So Far: 11.460165977478027\n",
            "Total elapsed time: 00h 00m 31s\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 494.1383 - mean_squared_error: 494.1383\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 189.5028 - mean_squared_error: 189.5028\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 48.8732 - mean_squared_error: 48.8732\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 29.1533 - mean_squared_error: 29.1533\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 23.7598 - mean_squared_error: 23.7598\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.3025 - mean_squared_error: 21.3025\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 19.5732 - mean_squared_error: 19.5732\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.1768 - mean_squared_error: 18.1768\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.9985 - mean_squared_error: 16.9985\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.0053 - mean_squared_error: 16.0053\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.1468 - mean_squared_error: 15.1468\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 14.3894 - mean_squared_error: 14.3894\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 13.7256 - mean_squared_error: 13.7256\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 13.1313 - mean_squared_error: 13.1313\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.6128 - mean_squared_error: 12.6128\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.1640 - mean_squared_error: 12.1640\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.7633 - mean_squared_error: 11.7633\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.4131 - mean_squared_error: 11.4131\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 4ms/step - loss: 11.1047 - mean_squared_error: 11.1047\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.8253 - mean_squared_error: 10.8253\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.5926 - mean_squared_error: 10.5926\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.3571 - mean_squared_error: 10.3571\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.1454 - mean_squared_error: 10.1454\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.9639 - mean_squared_error: 9.9639\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.7813 - mean_squared_error: 9.7813\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.6186 - mean_squared_error: 9.6186\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.4520 - mean_squared_error: 9.4520\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.2979 - mean_squared_error: 9.2979\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.1378 - mean_squared_error: 9.1378\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.9936 - mean_squared_error: 8.9936\n",
            "AutoKeras Training time: 43.56136667900046 seconds\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 21.6099 - mean_squared_error: 21.6099\n",
            "AutoKeras Model MAE: 21.60993003845215\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 4ms/step - loss: 402.6156 - mae: 17.4268 - val_loss: 201.5049 - val_mae: 11.5369\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 130.5316 - mae: 8.8423 - val_loss: 112.2458 - val_mae: 8.1114\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 81.2555 - mae: 6.8540 - val_loss: 74.8694 - val_mae: 6.3492\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 59.5125 - mae: 5.5921 - val_loss: 60.4027 - val_mae: 5.9076\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 49.8412 - mae: 5.2001 - val_loss: 51.3798 - val_mae: 5.2164\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 41.9565 - mae: 4.7289 - val_loss: 45.5261 - val_mae: 5.1299\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 37.2877 - mae: 4.5053 - val_loss: 39.8927 - val_mae: 4.7051\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 33.1292 - mae: 4.2101 - val_loss: 36.8430 - val_mae: 4.5798\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 30.2794 - mae: 4.0704 - val_loss: 34.5553 - val_mae: 4.3943\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 27.4018 - mae: 3.9341 - val_loss: 33.4929 - val_mae: 4.2637\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 26.1885 - mae: 3.7912 - val_loss: 32.3279 - val_mae: 4.1866\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 24.7782 - mae: 3.6475 - val_loss: 30.2632 - val_mae: 4.0287\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 23.1851 - mae: 3.5562 - val_loss: 30.5125 - val_mae: 4.0468\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 22.0863 - mae: 3.4600 - val_loss: 29.1212 - val_mae: 3.9291\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 21.2615 - mae: 3.3650 - val_loss: 28.8021 - val_mae: 3.9319\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 20.4472 - mae: 3.2776 - val_loss: 27.9184 - val_mae: 3.8510\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 20.5174 - mae: 3.2453 - val_loss: 28.1768 - val_mae: 3.8349\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 19.1663 - mae: 3.1590 - val_loss: 26.5327 - val_mae: 3.7212\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.4791 - mae: 3.0951 - val_loss: 25.2001 - val_mae: 3.6076\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 17.6700 - mae: 3.0038 - val_loss: 24.2689 - val_mae: 3.5211\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 17.2057 - mae: 2.9497 - val_loss: 24.5354 - val_mae: 3.4940\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.0197 - mae: 2.8627 - val_loss: 27.6686 - val_mae: 3.7231\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.8729 - mae: 2.8079 - val_loss: 24.8185 - val_mae: 3.4776\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.2661 - mae: 2.7636 - val_loss: 25.8372 - val_mae: 3.5798\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 14.3739 - mae: 2.6479 - val_loss: 23.4334 - val_mae: 3.3704\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 13.7018 - mae: 2.5940 - val_loss: 24.0106 - val_mae: 3.3873\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.6804 - mae: 2.5694 - val_loss: 23.3148 - val_mae: 3.3648\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.1884 - mae: 2.5341 - val_loss: 27.6053 - val_mae: 3.6099\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.7620 - mae: 2.5491 - val_loss: 26.5324 - val_mae: 3.5238\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.9125 - mae: 2.5401 - val_loss: 24.0939 - val_mae: 3.3523\n",
            "Training time: 11.363539109000158 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyPriNtHq-OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc53a1a-d40b-44a6-d5de-61854d48a5b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 07s]\n",
            "val_loss: 2835.867431640625\n",
            "\n",
            "Best val_loss So Far: 2835.867431640625\n",
            "Total elapsed time: 00h 00m 33s\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 28179.5098 - mean_squared_error: 28179.5098\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 20143.5215 - mean_squared_error: 20143.5215\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 8530.6885 - mean_squared_error: 8530.6875\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5170.6201 - mean_squared_error: 5170.6201\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4225.0942 - mean_squared_error: 4225.0942\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3810.9146 - mean_squared_error: 3810.9146\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3589.4558 - mean_squared_error: 3589.4553\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3451.2327 - mean_squared_error: 3451.2327\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3350.7429 - mean_squared_error: 3350.7429\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3271.1533 - mean_squared_error: 3271.1533\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3203.5991 - mean_squared_error: 3203.5991\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3146.4939 - mean_squared_error: 3146.4939\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3096.9094 - mean_squared_error: 3096.9094\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3054.1030 - mean_squared_error: 3054.1030\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3019.1689 - mean_squared_error: 3019.1689\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2985.2554 - mean_squared_error: 2985.2554\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2954.9783 - mean_squared_error: 2954.9780\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2929.6096 - mean_squared_error: 2929.6099\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2905.2664 - mean_squared_error: 2905.2664\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2883.3792 - mean_squared_error: 2883.3792\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2861.7104 - mean_squared_error: 2861.7104\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2844.7163 - mean_squared_error: 2844.7163\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2824.6672 - mean_squared_error: 2824.6672\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2810.8843 - mean_squared_error: 2810.8843\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2793.9055 - mean_squared_error: 2793.9055\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2779.6226 - mean_squared_error: 2779.6226\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2763.4382 - mean_squared_error: 2763.4382\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2750.7942 - mean_squared_error: 2750.7942\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2735.5588 - mean_squared_error: 2735.5588\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2721.9170 - mean_squared_error: 2721.9170\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 2894.5586 - mean_squared_error: 2894.5586\n",
            "AutoKeras Model MAE: 2894.55859375\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 28941.3145 - mae: 151.3686\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25583.1250 - mae: 140.2794\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 15857.5879 - mae: 103.4786\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 6089.0459 - mae: 62.0469\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5105.3604 - mae: 57.2420\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4854.7427 - mae: 56.4608\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4671.5850 - mae: 55.2805\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4441.4902 - mae: 54.2944\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4294.1011 - mae: 53.5856\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4170.2544 - mae: 52.5586\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4044.9702 - mae: 51.8289\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3941.4023 - mae: 51.2817\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3876.9600 - mae: 50.8762\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3774.2058 - mae: 50.2748\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3762.3469 - mae: 49.9098\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3656.8811 - mae: 49.5830\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3599.2781 - mae: 48.8824\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3538.4727 - mae: 48.9086\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3540.0139 - mae: 48.5092\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3446.7493 - mae: 47.9662\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3455.2161 - mae: 48.2450\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3380.5874 - mae: 47.3727\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3350.1394 - mae: 47.3374\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3309.2729 - mae: 46.9673\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3280.4561 - mae: 46.6762\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3244.8774 - mae: 46.4974\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3247.6731 - mae: 46.3574\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3227.1499 - mae: 46.3340\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3191.3435 - mae: 46.0569\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3172.4653 - mae: 45.9494\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3101.7971 - mae: 44.9765\n",
            "SWAG Model MAE: 44.976539611816406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "\n",
        "X = faces.images\n",
        "y = to_categorical(faces.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape((-1, 64*64))\n",
        "X_test = X_test.reshape((-1, 64*64))\n",
        "\n",
        "min_max_scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "X_test_scaled = min_max_scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "print(num_classes)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 15\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 1000 , num_classes, 'accuracy',0.0001)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-zaXKibDx7L",
        "outputId": "f8c35bbc-ddf9-4108-93c3-d794580f93bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 19s]\n",
            "val_accuracy: 0.890625\n",
            "\n",
            "Best val_accuracy So Far: 0.90625\n",
            "Total elapsed time: 00h 11m 25s\n",
            "Epoch 1/15\n",
            "10/10 [==============================] - 56s 37ms/step - loss: 2.8344 - accuracy: 0.3000\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.4483 - accuracy: 0.9125\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0942 - accuracy: 0.9875\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 0s 33ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "3/3 [==============================] - 41s 42ms/step - loss: 0.3155 - accuracy: 0.9500\n",
            "AutoKeras Model Accuracy: 0.949999988079071\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 9s 222ms/step - loss: 0.3329 - accuracy: 0.0188\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 5s 168ms/step - loss: 0.0411 - accuracy: 0.2094\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.0306 - accuracy: 0.5125\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 7s 212ms/step - loss: 0.0272 - accuracy: 0.6687\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 5s 165ms/step - loss: 0.0243 - accuracy: 0.7625\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 6s 180ms/step - loss: 0.0218 - accuracy: 0.8625\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 6s 197ms/step - loss: 0.0191 - accuracy: 0.9312\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 5s 170ms/step - loss: 0.0165 - accuracy: 0.9500\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 6s 198ms/step - loss: 0.0174 - accuracy: 0.9500\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 6s 199ms/step - loss: 0.0149 - accuracy: 0.9844\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 5s 158ms/step - loss: 0.0145 - accuracy: 0.9812\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 6s 189ms/step - loss: 0.0126 - accuracy: 0.9906\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 6s 185ms/step - loss: 0.0129 - accuracy: 0.9937\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 5s 149ms/step - loss: 0.0114 - accuracy: 0.9969\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 5s 162ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0197 - accuracy: 0.8750\n",
            "SWAG Model MAE: 44.976539611816406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "linnerud = load_linnerud()\n",
        "X = linnerud.data\n",
        "y = linnerud.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHA1-SM7FDDf",
        "outputId": "90d365af-edc9-4150-a04d-be46f11215fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_loss: 12057.8095703125\n",
            "\n",
            "Best val_loss So Far: 12057.8095703125\n",
            "Total elapsed time: 00h 00m 14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7c16a8489d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 13ms/step - loss: 12149.7422 - mean_squared_error: 12149.7422\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12132.0010 - mean_squared_error: 12132.0010\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12113.8730 - mean_squared_error: 12113.8730\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12095.2832 - mean_squared_error: 12095.2832\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12075.8652 - mean_squared_error: 12075.8652\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12055.4844 - mean_squared_error: 12055.4844\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12034.0078 - mean_squared_error: 12034.0078\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12011.3105 - mean_squared_error: 12011.3105\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11986.5869 - mean_squared_error: 11986.5869\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11959.6367 - mean_squared_error: 11959.6367\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11930.5498 - mean_squared_error: 11930.5498\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11899.1348 - mean_squared_error: 11899.1348\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11865.1602 - mean_squared_error: 11865.1602\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11828.2383 - mean_squared_error: 11828.2383\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11788.2695 - mean_squared_error: 11788.2695\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11744.8574 - mean_squared_error: 11744.8574\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11697.6816 - mean_squared_error: 11697.6816\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11646.6240 - mean_squared_error: 11646.6240\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11591.0996 - mean_squared_error: 11591.0996\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11531.1523 - mean_squared_error: 11531.1523\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11466.5254 - mean_squared_error: 11466.5254\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11396.9062 - mean_squared_error: 11396.9062\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11322.0938 - mean_squared_error: 11322.0938\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11241.8145 - mean_squared_error: 11241.8145\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11155.8232 - mean_squared_error: 11155.8232\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11063.6084 - mean_squared_error: 11063.6094\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10964.7783 - mean_squared_error: 10964.7783\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10859.1992 - mean_squared_error: 10859.1992\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10746.5029 - mean_squared_error: 10746.5029\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10626.6621 - mean_squared_error: 10626.6621\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 11405.4521 - mean_squared_error: 11405.4521\n",
            "AutoKeras Model MAE: 11405.4521484375\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 12205.1504 - mae: 89.8783\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12176.0254 - mae: 89.7110\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12148.3594 - mae: 89.5529\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12119.9268 - mae: 89.3898\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12090.5996 - mae: 89.2195\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12060.5566 - mae: 89.0440\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12030.9473 - mae: 88.8747\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12002.6211 - mae: 88.7087\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11970.9238 - mae: 88.5249\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11938.9590 - mae: 88.3356\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11904.9199 - mae: 88.1363\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11873.6152 - mae: 87.9531\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11837.9805 - mae: 87.7430\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11801.0918 - mae: 87.5250\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11766.0156 - mae: 87.3188\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11724.7363 - mae: 87.0704\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11684.1289 - mae: 86.8295\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11640.8066 - mae: 86.5689\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11595.3604 - mae: 86.2916\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11544.5156 - mae: 85.9841\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11499.3008 - mae: 85.7124\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11447.6006 - mae: 85.3990\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11388.9023 - mae: 85.0338\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11332.4072 - mae: 84.6873\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11270.6074 - mae: 84.3006\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11205.7217 - mae: 83.8937\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11141.6758 - mae: 83.4961\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11068.4004 - mae: 83.0247\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10993.9121 - mae: 82.5541\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10918.9258 - mae: 82.0788\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 11477.0498 - mae: 83.3533\n",
            "SWAG Model MAE: 83.35327911376953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXIlXrDnG-PT"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}