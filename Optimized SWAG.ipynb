{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras -q\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65cd265-e28f-424b-b395-b53e51864466"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Embedding, Dense, concatenate, Dropout, Flatten, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects, to_categorical, plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.datasets import load_iris, load_digits, load_wine, load_diabetes, load_breast_cancer, fetch_olivetti_faces, load_linnerud\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.datasets import load_digits"
      ],
      "metadata": {
        "id": "MYXZP4_9n-R7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(110)\n",
        "\n",
        "# Define custom activation functions and update the custom objects dictionary\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: tf.pow(x, 1)),\n",
        "        ('X_2', lambda x: tf.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: tf.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: tf.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: tf.pow(x, 2) / 40320),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model(input_dim, hidden_dim, output_dim, metrics='accuracy', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    concat_first_layer = concatenate([layer_1_x1, layer_1_x2])\n",
        "\n",
        "    # Second layer with custom activations\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "\n",
        "    # Third layer with custom activations\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4)\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1, layer_1_x2, concat_first_layer,\n",
        "                                       layer_x3_x4, layer_x5_x6])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model with specified loss and metrics\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[metrics])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "xID7aH81K83q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized_model = create_optimized_model(784,784, 10)\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "8aQhT2LoKZDH",
        "outputId": "4808f8ea-5815-42ee-cabe-2731ac82d287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "600/600 [==============================] - 42s 68ms/step - loss: 0.0417 - accuracy: 0.8388 - val_loss: 0.0262 - val_accuracy: 0.9068\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 41s 69ms/step - loss: 0.0209 - accuracy: 0.9345 - val_loss: 0.0201 - val_accuracy: 0.9302\n",
            "Training time: 143.77909544299996 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "lVNTPp71EwH5",
        "outputId": "c4c58107-3436-4e1a-c811-75ead2565d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "600/600 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.7804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7d5f6df5e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 39s 63ms/step - loss: 0.1130 - accuracy: 0.7804 - val_loss: 0.0329 - val_accuracy: 0.8299\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 37s 62ms/step - loss: 0.0298 - accuracy: 0.8534 - val_loss: 0.0301 - val_accuracy: 0.8443\n",
            "Training time: 83.51366655300012 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True) # Set max_trials to an appropriate number\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=10)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "_, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 10, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "start = timeit.default_timer()\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n",
        "\n",
        "# Evaluate your model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "KXztQpoaiuYu",
        "outputId": "31b4f082-d31a-4ef0-cb15-c63b20d8c5ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.7083333134651184\n",
            "\n",
            "Best val_accuracy So Far: 0.9166666865348816\n",
            "Total elapsed time: 00h 00m 07s\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 1.1562 - accuracy: 0.3750\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.4500\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0367 - accuracy: 0.5167\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.5667\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9356 - accuracy: 0.5833\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8889 - accuracy: 0.6333\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8439 - accuracy: 0.6917\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8009 - accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7192 - accuracy: 0.8167\n",
            "AutoKeras Training time: 9.745031700000027 seconds\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.6444 - accuracy: 0.8667\n",
            "AutoKeras Model Accuracy: 0.8666666746139526\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 2.3860 - accuracy: 0.2667 - val_loss: 1.9895 - val_accuracy: 0.2333\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1718 - accuracy: 0.3083 - val_loss: 0.7984 - val_accuracy: 0.2333\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.4667 - val_loss: 0.3370 - val_accuracy: 0.7333\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.7083 - val_loss: 0.1795 - val_accuracy: 0.7333\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.7417 - val_loss: 0.1355 - val_accuracy: 0.8333\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.7917 - val_loss: 0.1186 - val_accuracy: 0.8333\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.8250 - val_loss: 0.1058 - val_accuracy: 0.8667\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.8500 - val_loss: 0.0979 - val_accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9000 - val_loss: 0.0926 - val_accuracy: 0.9333\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9250 - val_loss: 0.0871 - val_accuracy: 0.9667\n",
            "Training time: 1.7188232759999664 seconds\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0871 - accuracy: 0.9667\n",
            "SWAG Model Accuracy: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = to_categorical(digits.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 200, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEhk7EEBPb6",
        "outputId": "6a2dc92b-c15b-4601-acf9-fdd1a882d267"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 16s]\n",
            "val_accuracy: 0.7824561595916748\n",
            "\n",
            "Best val_accuracy So Far: 0.8070175647735596\n",
            "Total elapsed time: 00h 01m 21s\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 1s 4ms/step - loss: 2.2017 - accuracy: 0.2317\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.6601 - accuracy: 0.5428\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1857 - accuracy: 0.6701\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8611 - accuracy: 0.7662\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.8031\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.8441\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8629\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8831\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.9012\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.9123\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8833\n",
            "AutoKeras Model Accuracy: 0.8833333253860474\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.8587\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9638\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9812\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9930\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9861\n",
            "SWAG Accuracy: 0.9861111044883728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = to_categorical(wine.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "u6pEsuuoBPYI",
        "outputId": "1cca1ec1-439c-4392-b2aa-e5db3a92d784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.8571428656578064\n",
            "\n",
            "Best val_accuracy So Far: 0.9285714030265808\n",
            "Total elapsed time: 00h 00m 11s\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 1.2534 - accuracy: 0.2887\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0856 - accuracy: 0.4577\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0563 - accuracy: 0.4648\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9120 - accuracy: 0.5704\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8769 - accuracy: 0.6268\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8572 - accuracy: 0.7778\n",
            "AutoKeras Model Accuracy: 0.7777777910232544\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.3451\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.7113\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.8310\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.8873\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9437\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9722\n",
            "SWAG Accuracy: 0.9722222089767456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7N_ZWiPBPS2",
        "outputId": "66d4122c-909c-4d25-9628-cc2dd9e8cc91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.47887325286865234\n",
            "\n",
            "Best val_accuracy So Far: 0.98591548204422\n",
            "Total elapsed time: 00h 00m 15s\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.4757 - accuracy: 0.8703\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9495\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9604\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9758\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9802\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9649\n",
            "AutoKeras Model Accuracy: 0.9649122953414917\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "46/46 [==============================] - 2s 3ms/step - loss: 0.2519 - accuracy: 0.6132\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.8418\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.8813\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.8989\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9341\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9386\n",
            "Accuracy: 0.9385964870452881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Boston Housing data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "batch_size = 5\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "input_dim = X_train.shape[1]\n",
        "optimized_model = create_optimized_model(input_dim, input_dim , 1 , 'mae') # input_dim and hidden_dim\n",
        "\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "id": "Bh72fFHYpQ3R",
        "outputId": "c5b5d6db-1c85-4e8f-bd86-4d84c9ecff09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_loss: 12.89281177520752\n",
            "\n",
            "Best val_loss So Far: 12.217472076416016\n",
            "Total elapsed time: 00h 00m 26s\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 262.0479 - mean_squared_error: 262.0479\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 24.0782 - mean_squared_error: 24.0782\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.5472 - mean_squared_error: 16.5472\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.8998 - mean_squared_error: 13.8998\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.2794 - mean_squared_error: 12.2794\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.2639 - mean_squared_error: 11.2639\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.5905 - mean_squared_error: 10.5905\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.1265 - mean_squared_error: 10.1265\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.7682 - mean_squared_error: 9.7682\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.4873 - mean_squared_error: 9.4873\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.2291 - mean_squared_error: 9.2291\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.0142 - mean_squared_error: 9.0142\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 8.7991 - mean_squared_error: 8.7991\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.6172 - mean_squared_error: 8.6172\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.4351 - mean_squared_error: 8.4351\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.2566 - mean_squared_error: 8.2566\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.1072 - mean_squared_error: 8.1072\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.9492 - mean_squared_error: 7.9492\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.8037 - mean_squared_error: 7.8037\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.6526 - mean_squared_error: 7.6526\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.5227 - mean_squared_error: 7.5227\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.3995 - mean_squared_error: 7.3995\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.2654 - mean_squared_error: 7.2654\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.1495 - mean_squared_error: 7.1495\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.0357 - mean_squared_error: 7.0357\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.9244 - mean_squared_error: 6.9244\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.8264 - mean_squared_error: 6.8264\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.7361 - mean_squared_error: 6.7361\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.6276 - mean_squared_error: 6.6276\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.5353 - mean_squared_error: 6.5353\n",
            "AutoKeras Training time: 37.749356003 seconds\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 20.0172 - mean_squared_error: 20.0172\n",
            "AutoKeras Model MAE: 20.017202377319336\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 5ms/step - loss: 352.2473 - mae: 16.0676 - val_loss: 163.5985 - val_mae: 10.2490\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 120.4120 - mae: 8.4538 - val_loss: 104.2029 - val_mae: 7.7561\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 76.3062 - mae: 6.4739 - val_loss: 71.4652 - val_mae: 6.4464\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 55.4514 - mae: 5.4286 - val_loss: 55.7358 - val_mae: 5.5458\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 45.7745 - mae: 4.8650 - val_loss: 48.7308 - val_mae: 5.2400\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 40.5200 - mae: 4.5507 - val_loss: 42.9849 - val_mae: 4.9491\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 35.4368 - mae: 4.3301 - val_loss: 38.5175 - val_mae: 4.6535\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 32.2307 - mae: 4.0989 - val_loss: 34.8186 - val_mae: 4.4138\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 28.7158 - mae: 3.8248 - val_loss: 32.2421 - val_mae: 4.2001\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 26.0165 - mae: 3.6904 - val_loss: 31.9197 - val_mae: 4.1708\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 24.8996 - mae: 3.5717 - val_loss: 28.7128 - val_mae: 3.8773\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 23.4901 - mae: 3.4620 - val_loss: 29.9951 - val_mae: 4.0052\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 23.2670 - mae: 3.4063 - val_loss: 26.8082 - val_mae: 3.6532\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.4263 - mae: 3.2753 - val_loss: 26.1139 - val_mae: 3.6093\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.1000 - mae: 3.2206 - val_loss: 25.2478 - val_mae: 3.5523\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 20.5809 - mae: 3.1849 - val_loss: 24.0736 - val_mae: 3.4322\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 20.5083 - mae: 3.1830 - val_loss: 26.2785 - val_mae: 3.6622\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 20.2784 - mae: 3.0680 - val_loss: 23.7860 - val_mae: 3.4281\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 19.2496 - mae: 3.0528 - val_loss: 23.6450 - val_mae: 3.4102\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.5000 - mae: 2.9939 - val_loss: 25.2281 - val_mae: 3.5506\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.2406 - mae: 2.9317 - val_loss: 25.6203 - val_mae: 3.6024\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.7125 - mae: 3.0458 - val_loss: 23.2666 - val_mae: 3.3694\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.0480 - mae: 2.9422 - val_loss: 22.9319 - val_mae: 3.3559\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 17.4266 - mae: 2.8844 - val_loss: 22.3395 - val_mae: 3.3026\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.9039 - mae: 2.8781 - val_loss: 22.1580 - val_mae: 3.2710\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.5498 - mae: 2.8660 - val_loss: 21.9129 - val_mae: 3.2626\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 17.3677 - mae: 2.9606 - val_loss: 22.2063 - val_mae: 3.2744\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.5527 - mae: 2.7960 - val_loss: 22.9947 - val_mae: 3.3738\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.1358 - mae: 2.8517 - val_loss: 21.8297 - val_mae: 3.2307\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 15.7531 - mae: 2.7358 - val_loss: 24.0100 - val_mae: 3.4293\n",
            "Training time: 11.327014303000169 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyPriNtHq-OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd6385d-2b85-40d7-d2d7-29080076cc84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 09s]\n",
            "val_loss: 3579.044189453125\n",
            "\n",
            "Best val_loss So Far: 2992.968505859375\n",
            "Total elapsed time: 00h 00m 23s\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29118.2246 - mean_squared_error: 29118.2246\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27349.4844 - mean_squared_error: 27349.4844\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23291.1250 - mean_squared_error: 23291.1250\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 16400.8848 - mean_squared_error: 16400.8848\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 9049.7822 - mean_squared_error: 9049.7822\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5199.1216 - mean_squared_error: 5199.1216\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4316.0596 - mean_squared_error: 4316.0596\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3975.3679 - mean_squared_error: 3975.3677\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3746.4487 - mean_squared_error: 3746.4487\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3584.9932 - mean_squared_error: 3584.9932\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3464.8042 - mean_squared_error: 3464.8042\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3371.3445 - mean_squared_error: 3371.3445\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3295.4717 - mean_squared_error: 3295.4717\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3231.5793 - mean_squared_error: 3231.5793\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3177.4985 - mean_squared_error: 3177.4985\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3131.4841 - mean_squared_error: 3131.4841\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3091.9133 - mean_squared_error: 3091.9133\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3057.1589 - mean_squared_error: 3057.1589\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3026.4675 - mean_squared_error: 3026.4675\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2999.1863 - mean_squared_error: 2999.1863\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2974.5811 - mean_squared_error: 2974.5811\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2952.2864 - mean_squared_error: 2952.2864\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2931.2852 - mean_squared_error: 2931.2847\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2913.0957 - mean_squared_error: 2913.0957\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2895.8867 - mean_squared_error: 2895.8867\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2879.6763 - mean_squared_error: 2879.6763\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2864.6907 - mean_squared_error: 2864.6907\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2850.9714 - mean_squared_error: 2850.9714\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2837.8076 - mean_squared_error: 2837.8076\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2825.3850 - mean_squared_error: 2825.3850\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3124.2029 - mean_squared_error: 3124.2029\n",
            "AutoKeras Model MAE: 3124.202880859375\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29259.5469 - mae: 152.3281\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26856.0742 - mae: 144.7139\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18374.2031 - mae: 114.2175\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 6672.6367 - mae: 64.0288\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5206.6655 - mae: 58.0192\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4971.8965 - mae: 56.9463\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4753.2363 - mae: 55.9793\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4626.3203 - mae: 55.1261\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4556.3125 - mae: 55.0020\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4380.4062 - mae: 53.9596\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4283.3413 - mae: 53.4073\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4184.5508 - mae: 52.8733\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4118.5410 - mae: 52.4687\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4122.2944 - mae: 52.3839\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4019.8240 - mae: 52.0507\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3893.8394 - mae: 50.9216\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3865.3308 - mae: 50.8730\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3777.9419 - mae: 50.3772\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3735.6633 - mae: 50.1256\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3682.9385 - mae: 49.5993\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3656.1777 - mae: 49.3554\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3591.2903 - mae: 49.2973\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3548.5332 - mae: 48.6280\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3481.6453 - mae: 48.2408\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3487.2610 - mae: 48.4171\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3423.4180 - mae: 47.9145\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3393.7510 - mae: 47.7137\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3375.1550 - mae: 47.5822\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3339.5725 - mae: 47.3773\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3312.7634 - mae: 46.9221\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 3119.4688 - mae: 45.5820\n",
            "SWAG Model MAE: 45.58197784423828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "\n",
        "X = faces.images\n",
        "y = to_categorical(faces.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape((-1, 64*64))\n",
        "X_test = X_test.reshape((-1, 64*64))\n",
        "\n",
        "min_max_scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "X_test_scaled = min_max_scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "print(num_classes)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 6\n",
        "\n",
        "# # # AutoKeras model\n",
        "# # ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# # # Train the AutoKeras model\n",
        "# # ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# # # Evaluate AutoKeras model\n",
        "# # loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "# # print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 3000 , num_classes, 'accuracy',0.00005)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "c-zaXKibDx7L",
        "outputId": "c79789fd-7932-4246-ee52-d65ffd6c93e8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-892a789e62dc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and preprocess the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_olivetti_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fetch_olivetti_faces' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[1])"
      ],
      "metadata": {
        "id": "VlWsGdHSHoOE",
        "outputId": "f04ea1c7-8547-4ffd-a572-00b64501963c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.18595041 0.12809917 0.11570248 ... 0.19008264 0.2107438  0.2107438 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "linnerud = load_linnerud()\n",
        "X = linnerud.data\n",
        "y = linnerud.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "batch_size = 10\n",
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHA1-SM7FDDf",
        "outputId": "497a7a94-d6e5-401c-c4c9-dd670df94142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 12ms/step - loss: 12236.7773 - mae: 90.0593\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12203.7246 - mae: 89.8693\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12176.3438 - mae: 89.7125\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12145.0156 - mae: 89.5329\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12115.8711 - mae: 89.3676\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12086.8057 - mae: 89.1992\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12056.2979 - mae: 89.0207\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12025.0195 - mae: 88.8407\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11993.6465 - mae: 88.6577\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11962.9824 - mae: 88.4801\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11927.8486 - mae: 88.2728\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11895.4570 - mae: 88.0840\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11860.9844 - mae: 87.8825\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11823.7891 - mae: 87.6602\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11786.8887 - mae: 87.4423\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11748.6445 - mae: 87.2185\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11705.3770 - mae: 86.9583\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11664.4600 - mae: 86.7130\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11616.4834 - mae: 86.4236\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11571.5771 - mae: 86.1548\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11518.8789 - mae: 85.8315\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11469.7803 - mae: 85.5330\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11416.7871 - mae: 85.2113\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11360.4844 - mae: 84.8658\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11299.5381 - mae: 84.4909\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11234.8555 - mae: 84.0785\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11168.6143 - mae: 83.6630\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11097.1650 - mae: 83.2180\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11024.9404 - mae: 82.7554\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10953.6484 - mae: 82.3030\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 10867.5801 - mae: 81.7369\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10783.4453 - mae: 81.1922\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10689.8047 - mae: 80.5563\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10602.1914 - mae: 79.9884\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10501.5312 - mae: 79.2989\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10403.5059 - mae: 78.6397\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10296.8828 - mae: 77.9055\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10177.3936 - mae: 77.0458\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10066.5703 - mae: 76.2703\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9943.4941 - mae: 75.4206\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9814.3848 - mae: 74.5331\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 9684.3906 - mae: 73.6652\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9549.6699 - mae: 72.7481\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 9411.0879 - mae: 71.7846\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9261.1426 - mae: 70.6476\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9115.9648 - mae: 69.5662\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 8967.2744 - mae: 68.5133\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8808.5371 - mae: 67.6406\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8654.9854 - mae: 66.8941\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8496.7900 - mae: 66.1780\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8333.2559 - mae: 65.3101\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 8168.9893 - mae: 64.5558\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8027.2056 - mae: 63.9070\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7869.0420 - mae: 63.0722\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7728.7837 - mae: 62.5513\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7591.6528 - mae: 61.9907\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7445.8965 - mae: 61.3914\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7341.0459 - mae: 61.1652\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7215.4741 - mae: 61.0139\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7119.9844 - mae: 60.9716\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7034.5566 - mae: 60.9366\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6960.7939 - mae: 60.8394\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6901.5327 - mae: 60.7268\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6856.1055 - mae: 60.6510\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6822.7388 - mae: 60.7688\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6809.7217 - mae: 60.8300\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6757.3613 - mae: 60.7793\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6740.3032 - mae: 60.9052\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6709.3726 - mae: 60.8998\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6679.0342 - mae: 60.8200\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6649.1855 - mae: 60.7038\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6616.2871 - mae: 60.5629\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6589.5288 - mae: 60.4388\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6562.0542 - mae: 60.2934\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6532.2310 - mae: 60.1189\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6503.1602 - mae: 59.9919\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6477.6831 - mae: 59.9062\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6451.7612 - mae: 59.8209\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6424.9326 - mae: 59.7398\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6401.9082 - mae: 59.6521\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6376.5615 - mae: 59.5517\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6354.0625 - mae: 59.4934\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6328.3584 - mae: 59.4050\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6307.5693 - mae: 59.3345\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6284.2935 - mae: 59.2526\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6262.9556 - mae: 59.1832\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6242.1157 - mae: 59.1170\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6220.2104 - mae: 59.0179\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6197.0000 - mae: 58.9251\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6175.7573 - mae: 58.8361\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6158.7451 - mae: 58.7454\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6136.9961 - mae: 58.6318\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6119.0508 - mae: 58.5639\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6097.4697 - mae: 58.4775\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6080.5371 - mae: 58.4065\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6058.9189 - mae: 58.3165\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6041.9248 - mae: 58.2615\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6022.2554 - mae: 58.1981\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6005.0840 - mae: 58.1635\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5986.4810 - mae: 58.0967\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 5904.2275 - mae: 57.3307\n",
            "Accuracy: 57.33065414428711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXIlXrDnG-PT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}