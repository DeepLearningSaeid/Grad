{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras -q\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Embedding, Dense, concatenate, Dropout, Flatten, Activation, BatchNormalization\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects, to_categorical, plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.datasets import load_iris, load_digits, load_wine, load_diabetes, load_breast_cancer, fetch_olivetti_faces, load_linnerud\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.datasets import load_digits"
      ],
      "metadata": {
        "id": "MYXZP4_9n-R7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Custom Activation Functions:\n",
        "# We create a function define_activation_functions to define a series of polynomial-based custom activation functions.\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(110)\n",
        "\n",
        "# Define custom activation functions and update the custom objects dictionary\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: tf.pow(x, 1)),\n",
        "        ('X_2', lambda x: tf.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: tf.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: tf.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: tf.pow(x, 2) / 40320),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model(input_dim, hidden_dim, output_dim, metrics='accuracy', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    concat_first_layer = concatenate([layer_1_x1, layer_1_x2])\n",
        "\n",
        "    # Second layer with custom activations\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "\n",
        "    # Third layer with custom activations\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4)\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1, layer_1_x2, concat_first_layer,\n",
        "                                       layer_x3_x4, layer_x5_x6])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model with specified loss and metrics\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[metrics])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "xID7aH81K83q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create an instance of the optimized model\n",
        "# Input dimension is 784 (28x28 pixels, flattened),\n",
        "# 500 hidden units in each layer,\n",
        "# 10 output units (one for each digit)\n",
        "optimized_model = create_optimized_model(784, 500, 10, 'accuracy')\n",
        "\n",
        "# Load the MNIST dataset\n",
        "# MNIST dataset contains 28x28 pixel grayscale images of handwritten digits (0-9)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "# Normalize the pixel values of the images by adding 10 and dividing by 300\n",
        "# This changes the range of pixel values and can help with model training\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "\n",
        "# Reshape the data\n",
        "# Flatten the 28x28 images into 1D arrays of 784 elements for model input\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# One-hot encode the labels\n",
        "# Convert class vectors (integers) to binary class matrices for use with categorical crossentropy\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Training the model\n",
        "# Specify batch size and number of epochs for training\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "\n",
        "# Start a timer to measure training time\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# Fit the model on the training data\n",
        "# x_train and y_train are the training data and labels\n",
        "# Batch size determines the number of samples processed before the model is updated\n",
        "# Epochs is the number of complete passes through the training dataset\n",
        "# Verbose=1 shows a progress bar during training\n",
        "# Validation data is used to evaluate the loss and any model metrics at the end of each epoch\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Stop the timer\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Output the training time\n",
        "# Print the time taken by the training process\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "id": "8aQhT2LoKZDH",
        "outputId": "51dc4498-c8e5-4c51-bf2c-9d3572cd700e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "600/600 [==============================] - 62s 102ms/step - loss: 0.0418 - accuracy: 0.8399 - val_loss: 0.0268 - val_accuracy: 0.9053\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 0.0208 - accuracy: 0.9355 - val_loss: 0.0202 - val_accuracy: 0.9320\n",
            "Training time: 143.82728279399998 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "# Fashion MNIST is a dataset of Zalando's article images, consisting of 60,000 training and 10,000 test examples.\n",
        "# Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "# Normalize the pixel values of the images by adding 10 and then dividing by 300.\n",
        "# This changes the range of pixel values and can help with model training.\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "\n",
        "# Reshape the data\n",
        "# Flatten the 28x28 images into 1D arrays of 784 elements for model input.\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "# One-hot encode the labels\n",
        "# Convert class vectors (integers) to binary class matrices for use with categorical crossentropy.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 100\n",
        "epochs = 5\n",
        "\n",
        "# # AutoKeras model\n",
        "# # AutoKeras is an AutoML system based on Keras. It tries different model architectures automatically.\n",
        "# # Here, StructuredDataClassifier is used, suitable for structured data classification.\n",
        "# # max_trials parameter indicates how many different models to try.\n",
        "# ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True)\n",
        "\n",
        "# # Start a timer for the AutoKeras model training\n",
        "# start_ak = timeit.default_timer()\n",
        "\n",
        "# # Fit the AutoKeras model on the training data\n",
        "# ak_model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# # Stop the timer and print the training time\n",
        "# end_ak = timeit.default_timer()\n",
        "# print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# # Evaluate the AutoKeras model\n",
        "# # The evaluate function returns the loss value & metrics values for the model in test mode.\n",
        "# _, ak_accuracy = ak_model.evaluate(x_test, y_test)\n",
        "# print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "# # Print separator for clarity in output\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model\n",
        "# Create an instance of a custom optimized model with specific parameters.\n",
        "optimized_model = create_optimized_model(784, 500, 10, 'accuracy')\n",
        "\n",
        "# Start a timer for the custom model training\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# Fit the custom model on the training data\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Stop the timer and print the training time\n",
        "end = timeit.default_timer()\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNTPp71EwH5",
        "outputId": "842b7a95-e62e-45ba-f8cd-f45a4f30ff01"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "600/600 [==============================] - 43s 69ms/step - loss: 0.1146 - accuracy: 0.7702 - val_loss: 0.0326 - val_accuracy: 0.8342\n",
            "Epoch 2/5\n",
            "600/600 [==============================] - 41s 68ms/step - loss: 0.0298 - accuracy: 0.8526 - val_loss: 0.0282 - val_accuracy: 0.8533\n",
            "Epoch 3/5\n",
            "600/600 [==============================] - 47s 78ms/step - loss: 0.0263 - accuracy: 0.8695 - val_loss: 0.0272 - val_accuracy: 0.8559\n",
            "Epoch 4/5\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 0.0245 - accuracy: 0.8806 - val_loss: 0.0281 - val_accuracy: 0.8567\n",
            "Epoch 5/5\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 0.0232 - accuracy: 0.8888 - val_loss: 0.0263 - val_accuracy: 0.8621\n",
            "Training time: 264.79737926600046 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "# The Iris dataset is a classic dataset for classification, containing 3 types of Iris flowers\n",
        "iris = load_iris()\n",
        "X = iris.data  # Feature matrix (measurements of the flowers)\n",
        "y = iris.target  # Target vector (types of Iris flowers)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# 80% of data is used for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "# StandardScaler standardizes features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to data and then transform it\n",
        "X_test = scaler.transform(X_test)        # Perform standardization by centering and scaling\n",
        "\n",
        "# One-hot encode the labels\n",
        "# Convert class vectors (integers) to binary class matrices\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "# Determine the number of features and classes\n",
        "num_features = X_train.shape[1]  # Number of features\n",
        "num_classes = y_train.shape[1]   # Number of classes\n",
        "\n",
        "# AutoKeras model\n",
        "# AutoKeras is an AutoML system based on Keras. It automatically tries different model architectures.\n",
        "# max_trials is the number of different models to try.\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True)\n",
        "\n",
        "# Start timing the AutoKeras training\n",
        "start_ak = timeit.default_timer()\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "# Stop timing and print the training duration\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate the AutoKeras model\n",
        "# Evaluates the model on the testing dataset\n",
        "_, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "# Print separators for output clarity\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom model\n",
        "# Create an instance of a custom optimized model with specific parameters\n",
        "model = create_optimized_model(num_features, 10, num_classes, 'accuracy')\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "\n",
        "# Start timing the custom model training\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# Train the custom model\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "# Stop timing and print the training duration\n",
        "end = timeit.default_timer()\n",
        "print(f\"Training time: {end - start} seconds\")\n",
        "\n",
        "# Evaluate the custom model\n",
        "# Evaluates the model on the testing dataset\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "KXztQpoaiuYu",
        "outputId": "16e78bc1-bf75-4975-f4e0-e774213a514e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.625\n",
            "\n",
            "Best val_accuracy So Far: 0.9583333134651184\n",
            "Total elapsed time: 00h 00m 12s\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 1.0156 - accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.4250\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8991 - accuracy: 0.5833\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8462 - accuracy: 0.7083\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.7667\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7833\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.8083\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.8083\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.8083\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.8083\n",
            "AutoKeras Training time: 65.78878034599984 seconds\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.5578 - accuracy: 0.8333\n",
            "AutoKeras Model Accuracy: 0.8333333134651184\n",
            "******************************************************************************************\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 0.6030 - accuracy: 0.4417 - val_loss: 0.4593 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.6500 - val_loss: 0.2891 - val_accuracy: 0.7000\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2434 - accuracy: 0.7333 - val_loss: 0.1933 - val_accuracy: 0.8333\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.8250 - val_loss: 0.1354 - val_accuracy: 0.8667\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.8500 - val_loss: 0.1030 - val_accuracy: 0.8667\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.8583 - val_loss: 0.0877 - val_accuracy: 0.8667\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.8667 - val_loss: 0.0803 - val_accuracy: 0.9000\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.8750 - val_loss: 0.0758 - val_accuracy: 0.9333\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9000 - val_loss: 0.0726 - val_accuracy: 0.9333\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9000 - val_loss: 0.0688 - val_accuracy: 0.9333\n",
            "Training time: 1.9307551170004444 seconds\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0688 - accuracy: 0.9333\n",
            "SWAG Model Accuracy: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# The 'digits' dataset is a collection of 8x8 pixel images of handwritten digits\n",
        "digits = load_digits()\n",
        "X = digits.data  # Feature matrix (pixel values of images)\n",
        "y = to_categorical(digits.target)  # One-hot encode the target labels\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# 80% of data is used for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data\n",
        "# MinMaxScaler scales each feature to a given range, here between 0 and 1.\n",
        "# This is important for neural network models which are sensitive to input scale.\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to data, then transform it\n",
        "X_test = scaler.transform(X_test)        # Apply the same transformation to the test data\n",
        "\n",
        "# Determine the number of features and classes from the data\n",
        "num_features = X_train.shape[1]  # Number of features (64 pixels per image in this case)\n",
        "num_classes = y_train.shape[1]   # Number of classes (digits 0-9, so 10 classes)\n",
        "\n",
        "# Print the number of features for confirmation\n",
        "print(num_features)\n",
        "\n",
        "# AutoKeras model\n",
        "# AutoKeras is an AutoML system based on Keras, automating the process of model selection and training.\n",
        "# max_trials indicates how many different models to try.\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Define the number of epochs for training\n",
        "epochs = 5\n",
        "\n",
        "# Train the AutoKeras model\n",
        "# Fit the model to the training data\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate the AutoKeras model on the test set\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "# Print separator for clarity in output\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model\n",
        "# Creating an instance of a custom optimized model with specific parameters\n",
        "model = create_optimized_model(num_features, 200, num_classes, 'accuracy')\n",
        "\n",
        "# Training parameters for the custom model\n",
        "batch_size = 10  # Number of samples per gradient update\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model to the training data using defined batch size and epochs\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the custom model on the test set\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEhk7EEBPb6",
        "outputId": "65a9357a-c8f7-44b9-e095-a4d10df9b7eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 19s]\n",
            "val_accuracy: 0.7684210538864136\n",
            "\n",
            "Best val_accuracy So Far: 0.8105263113975525\n",
            "Total elapsed time: 00h 01m 30s\n",
            "Epoch 1/5\n",
            "45/45 [==============================] - 2s 4ms/step - loss: 1.8918 - accuracy: 0.4210\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0654 - accuracy: 0.6875\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.7815\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.8288\n",
            "Epoch 5/5\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8636\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.5038 - accuracy: 0.8472\n",
            "AutoKeras Model Accuracy: 0.8472222089767456\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 5ms/step - loss: 0.0556 - accuracy: 0.8323\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9631\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0169 - accuracy: 0.9770\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9875\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.0120 - accuracy: 0.9944\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0142 - accuracy: 0.9861\n",
            "SWAG Accuracy: 0.9861111044883728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# The Wine dataset is a classic multiclass classification dataset\n",
        "wine = load_wine()\n",
        "X = wine.data  # Feature matrix (chemical constituents of wines)\n",
        "y = to_categorical(wine.target)  # One-hot encode the target labels\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# 80% of data is used for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data\n",
        "# MinMaxScaler scales each feature to a given range, here between 0 and 1\n",
        "# This is important for neural network models which are sensitive to input scale\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to data, then transform it\n",
        "X_test = scaler.transform(X_test)        # Apply the same transformation to the test data\n",
        "\n",
        "# Determine the number of features and classes from the data\n",
        "num_features = X_train.shape[1]  # Number of features\n",
        "num_classes = y_train.shape[1]   # Number of classes\n",
        "\n",
        "# Print the number of features for confirmation\n",
        "print(num_features)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# AutoKeras model\n",
        "# AutoKeras is an AutoML system based on Keras, automating the process of model selection and training\n",
        "# max_trials indicates how many different models to try\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "# Fit the model to the training data\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate the AutoKeras model on the test set\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "# Print separators for clarity in output\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model\n",
        "# Creating an instance of a custom optimized model with specific parameters\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model to the training data using defined batch size and epochs\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the custom model on the test set\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "u6pEsuuoBPYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240abdf6-6008-4e39-fac3-3e1c0dbabc3b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.5714285969734192\n",
            "\n",
            "Best val_accuracy So Far: 1.0\n",
            "Total elapsed time: 00h 00m 23s\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.0299 - accuracy: 0.3873\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9343 - accuracy: 0.5141\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8535 - accuracy: 0.6127\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7816 - accuracy: 0.6972\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7164 - accuracy: 0.7817\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7065 - accuracy: 0.7778\n",
            "AutoKeras Model Accuracy: 0.7777777910232544\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 0.3226 - accuracy: 0.3380\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.5563\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.8521\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.9014\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9296\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.9444\n",
            "SWAG Accuracy: 0.9444444179534912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# The Breast Cancer dataset is a binary classification dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data  # Feature matrix (characteristics of the cell nuclei)\n",
        "y = cancer.target  # Target vector (cancer diagnosis: malignant or benign)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "# 80% of data is used for training and 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data\n",
        "# MinMaxScaler scales each feature to a given range, here between 0 and 1\n",
        "# This is important for neural network models which are sensitive to input scale\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to data, then transform it\n",
        "X_test = scaler.transform(X_test)        # Apply the same transformation to the test data\n",
        "\n",
        "# Determine the number of features from the data\n",
        "num_features = X_train.shape[1]  # Number of features\n",
        "\n",
        "# Print the number of features for confirmation\n",
        "print(num_features)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# AutoKeras model\n",
        "# AutoKeras is an AutoML system based on Keras, automating the process of model selection and training\n",
        "# max_trials indicates how many different models to try\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "# Fit the model to the training data\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate the AutoKeras model on the test set\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "# Print separators for clarity in output\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model\n",
        "# Creating an instance of a custom optimized model with specific parameters\n",
        "# Here, the output layer has 1 unit because it's a binary classification problem\n",
        "model = create_optimized_model(num_features, 20, 1, 'accuracy')\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model to the training data using defined batch size and epochs\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the custom model on the test set\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7N_ZWiPBPS2",
        "outputId": "c78cca4d-1726-4d44-cbba-85926ed39648"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 04s]\n",
            "val_accuracy: 0.9577465057373047\n",
            "\n",
            "Best val_accuracy So Far: 0.9718309640884399\n",
            "Total elapsed time: 00h 00m 21s\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 3s 6ms/step - loss: 0.3575 - accuracy: 0.8637\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2153 - accuracy: 0.9341\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9385\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1526 - accuracy: 0.9451\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.9538\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3579 - accuracy: 0.9649\n",
            "AutoKeras Model Accuracy: 0.9649122953414917\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.6022\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.8571\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.8901\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9275\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9341\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9298\n",
            "Accuracy: 0.9298245906829834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import autokeras as ak\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load Boston Housing data\n",
        "# The Boston Housing dataset contains information about various houses in Boston\n",
        "# It's used for regression tasks to predict the value of houses based on different attributes\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "# Using MinMaxScaler to scale the data\n",
        "# MinMaxScaler scales each feature to a given range, here between 0 and 1\n",
        "# This scaling can improve the performance of neural network models\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to data, then transform it\n",
        "X_test = scaler.transform(X_test)        # Apply the same transformation to the test data\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 5\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model for regression\n",
        "# AutoKeras StructuredDataRegressor automatically tries different model architectures\n",
        "# max_trials indicates how many different models to try\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Start timing the AutoKeras model training\n",
        "start_ak = timeit.default_timer()\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Stop timing and print the training duration\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate the AutoKeras model\n",
        "# Evaluates the model's performance in terms of loss and mean absolute error (MAE)\n",
        "loss, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "# Print separators for output clarity\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model for regression\n",
        "# Create an instance of a custom optimized model with specific parameters\n",
        "# The model is designed for regression with Mean Absolute Error (MAE) as the metric\n",
        "input_dim = X_train.shape[1]  # Number of input features\n",
        "optimized_model = create_optimized_model(input_dim, input_dim, 1, 'mae')  # Using input_dim as hidden_dim and 1 output unit\n",
        "\n",
        "# Start timing the custom model training\n",
        "start = timeit.default_timer()\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model to the training data using defined batch size and epochs\n",
        "history = optimized_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "# Stop timing and print the training duration\n",
        "end = timeit.default_timer()\n",
        "print(f\"Training time: {end - start} seconds\")\n",
        "# Evaluate the AutoKeras model\n",
        "# Evaluates the model's performance in terms of loss and mean absolute error (MAE)\n",
        "loss, _mae = optimized_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {_mae}\")\n",
        "\n",
        "# Print separators for output clarity\n"
      ],
      "metadata": {
        "id": "Bh72fFHYpQ3R",
        "outputId": "deda3652-3032-4486-b6fd-4a92ba94c40f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 14s]\n",
            "val_loss: 16.00876808166504\n",
            "\n",
            "Best val_loss So Far: 13.422754287719727\n",
            "Total elapsed time: 00h 00m 36s\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 524.3591 - mean_squared_error: 524.3591\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 253.2520 - mean_squared_error: 253.2520\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 56.7244 - mean_squared_error: 56.7244\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 27.7045 - mean_squared_error: 27.7045\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.3050 - mean_squared_error: 21.3050\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 19.5173 - mean_squared_error: 19.5173\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.4249 - mean_squared_error: 18.4249\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 17.5090 - mean_squared_error: 17.5090\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.6954 - mean_squared_error: 16.6954\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 15.9657 - mean_squared_error: 15.9657\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 15.2667 - mean_squared_error: 15.2667\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 14.5798 - mean_squared_error: 14.5798\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.9560 - mean_squared_error: 13.9560\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.4055 - mean_squared_error: 13.4055\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 12.9125 - mean_squared_error: 12.9125\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.4839 - mean_squared_error: 12.4839\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.0849 - mean_squared_error: 12.0849\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.7478 - mean_squared_error: 11.7478\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.4437 - mean_squared_error: 11.4437\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.1550 - mean_squared_error: 11.1550\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.8786 - mean_squared_error: 10.8786\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.6233 - mean_squared_error: 10.6233\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.3889 - mean_squared_error: 10.3889\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.1676 - mean_squared_error: 10.1676\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.9730 - mean_squared_error: 9.9730\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.7807 - mean_squared_error: 9.7807\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.6044 - mean_squared_error: 9.6044\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.4311 - mean_squared_error: 9.4311\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.2699 - mean_squared_error: 9.2699\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.1074 - mean_squared_error: 9.1074\n",
            "AutoKeras Training time: 51.92831626500083 seconds\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 24.4021 - mean_squared_error: 24.4021\n",
            "AutoKeras Model MAE: 24.402070999145508\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 2s 5ms/step - loss: 411.0184 - mae: 17.6104 - val_loss: 196.9481 - val_mae: 11.2951\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 122.2498 - mae: 8.4930 - val_loss: 106.6100 - val_mae: 7.8296\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 79.7303 - mae: 6.7793 - val_loss: 75.8141 - val_mae: 6.4980\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 59.2664 - mae: 5.6072 - val_loss: 62.4123 - val_mae: 5.8782\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 50.5475 - mae: 5.1644 - val_loss: 55.4390 - val_mae: 5.4538\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 44.3896 - mae: 4.8149 - val_loss: 51.7854 - val_mae: 5.5311\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 39.8292 - mae: 4.6118 - val_loss: 43.6085 - val_mae: 4.9220\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 34.8162 - mae: 4.3532 - val_loss: 40.0518 - val_mae: 4.6769\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 31.8822 - mae: 4.1691 - val_loss: 37.0082 - val_mae: 4.4748\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 28.0622 - mae: 3.8909 - val_loss: 34.9070 - val_mae: 4.3085\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 25.7396 - mae: 3.7507 - val_loss: 34.4990 - val_mae: 4.2552\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 24.2927 - mae: 3.6188 - val_loss: 33.2171 - val_mae: 4.1622\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 22.8395 - mae: 3.4849 - val_loss: 32.5645 - val_mae: 4.0500\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 21.6590 - mae: 3.4153 - val_loss: 31.5913 - val_mae: 3.9411\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.0240 - mae: 3.3211 - val_loss: 29.9007 - val_mae: 3.8312\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 19.6625 - mae: 3.1925 - val_loss: 29.2132 - val_mae: 3.7221\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 19.2132 - mae: 3.1288 - val_loss: 28.6559 - val_mae: 3.6945\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.9880 - mae: 3.1267 - val_loss: 30.5163 - val_mae: 3.9906\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.7133 - mae: 3.0175 - val_loss: 26.1302 - val_mae: 3.5170\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 17.4715 - mae: 2.9446 - val_loss: 27.5716 - val_mae: 3.6720\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 17.3686 - mae: 2.8820 - val_loss: 26.2096 - val_mae: 3.4685\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.2478 - mae: 2.8196 - val_loss: 25.5375 - val_mae: 3.3839\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.9447 - mae: 2.8013 - val_loss: 23.8035 - val_mae: 3.2355\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.9167 - mae: 2.7803 - val_loss: 25.2864 - val_mae: 3.3674\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.0775 - mae: 2.6752 - val_loss: 23.9752 - val_mae: 3.2685\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.0143 - mae: 2.6748 - val_loss: 25.3832 - val_mae: 3.3443\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 14.4072 - mae: 2.6635 - val_loss: 23.7714 - val_mae: 3.2486\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 14.6287 - mae: 2.6879 - val_loss: 25.0975 - val_mae: 3.2589\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 14.1169 - mae: 2.6698 - val_loss: 23.1251 - val_mae: 3.1201\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 13.7250 - mae: 2.5897 - val_loss: 25.9613 - val_mae: 3.3379\n",
            "Training time: 11.498651162999522 seconds\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 25.9613 - mae: 3.3379\n",
            "AutoKeras Model MAE: 3.3378913402557373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the dataset\n",
        "# The Diabetes dataset is commonly used for regression analysis\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data  # Feature matrix (medical measurements)\n",
        "y = diabetes.target  # Target variable (quantitative measure of disease progression)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# test_size=0.2 allocates 20% of the data for testing and the rest for training\n",
        "# random_state=42 ensures reproducibility of the results\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features using MinMaxScaler\n",
        "# MinMaxScaler scales each feature to a range between 0 and 1\n",
        "# This scaling is beneficial for neural network models\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to the training data and transform it\n",
        "X_test = scaler.transform(X_test)        # Transform the test data using the same scale\n",
        "\n",
        "# Determine the number of features from the data\n",
        "num_features = X_train.shape[1]  # Number of features in the dataset\n",
        "print(num_features)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras StructuredDataRegressor model\n",
        "# This is an AutoML model that automatically searches for the best model architecture\n",
        "# max_trials=3 sets the number of different models AutoKeras will try\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "# Fit the model on the training data\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the AutoKeras model\n",
        "# Evaluates the model's performance in terms of loss and mean absolute error (MAE)\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "# Print separators for clarity in output\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model\n",
        "# Create an instance of a custom optimized model for regression\n",
        "# This model uses the mean absolute error (MAE) as a performance metric\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')  # The model predicts a single output\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the custom model\n",
        "# Evaluates the model's performance in terms of loss and MAE\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n"
      ],
      "metadata": {
        "id": "KyPriNtHq-OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00dabfd4-56af-424a-e8c4-9a0a55e0095c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 10s]\n",
            "val_loss: 2850.165771484375\n",
            "\n",
            "Best val_loss So Far: 2850.165771484375\n",
            "Total elapsed time: 00h 00m 26s\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29247.7910 - mean_squared_error: 29247.7910\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27681.0391 - mean_squared_error: 27681.0391\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23830.2070 - mean_squared_error: 23830.2070\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 16874.4863 - mean_squared_error: 16874.4863\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 9236.7383 - mean_squared_error: 9236.7383\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5420.9854 - mean_squared_error: 5420.9854\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4483.4556 - mean_squared_error: 4483.4556\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4040.1130 - mean_squared_error: 4040.1130\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3754.9741 - mean_squared_error: 3754.9741\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3557.8923 - mean_squared_error: 3557.8923\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3412.5527 - mean_squared_error: 3412.5527\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3299.1431 - mean_squared_error: 3299.1433\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3208.4836 - mean_squared_error: 3208.4836\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3136.1313 - mean_squared_error: 3136.1318\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3077.1943 - mean_squared_error: 3077.1943\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3028.6782 - mean_squared_error: 3028.6782\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2988.3611 - mean_squared_error: 2988.3611\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2953.9131 - mean_squared_error: 2953.9131\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2924.5059 - mean_squared_error: 2924.5059\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2899.2803 - mean_squared_error: 2899.2803\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2876.8169 - mean_squared_error: 2876.8169\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2857.2080 - mean_squared_error: 2857.2078\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2839.4368 - mean_squared_error: 2839.4368\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2823.9658 - mean_squared_error: 2823.9658\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2809.5525 - mean_squared_error: 2809.5525\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2796.6877 - mean_squared_error: 2796.6877\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2785.0081 - mean_squared_error: 2785.0081\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2774.2515 - mean_squared_error: 2774.2515\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2764.2585 - mean_squared_error: 2764.2585\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2754.7871 - mean_squared_error: 2754.7871\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2850.0671 - mean_squared_error: 2850.0671\n",
            "AutoKeras Model MAE: 2850.067138671875\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29165.6523 - mae: 152.0632\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26101.8926 - mae: 142.2029\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 16514.7754 - mae: 106.4850\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 6332.6426 - mae: 63.4390\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 5375.6978 - mae: 58.1258\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 5055.5259 - mae: 57.2865\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4760.2715 - mae: 55.6476\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4539.8101 - mae: 54.6837\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4395.7520 - mae: 53.7780\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4203.7021 - mae: 53.0006\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4110.1357 - mae: 52.0485\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3966.3535 - mae: 51.4860\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3863.8284 - mae: 50.7405\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3790.6650 - mae: 50.2142\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3717.9937 - mae: 49.7727\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3653.9836 - mae: 49.4373\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3602.2458 - mae: 49.2016\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3605.4404 - mae: 49.1568\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3532.5598 - mae: 48.7612\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3506.3835 - mae: 48.4883\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3472.8096 - mae: 48.1983\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3425.3269 - mae: 47.5231\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3402.9592 - mae: 47.7995\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3338.8528 - mae: 47.1516\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3321.6658 - mae: 47.0806\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3305.5679 - mae: 46.8954\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3264.4058 - mae: 46.6447\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3234.1409 - mae: 46.1318\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3216.2263 - mae: 46.2842\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3201.8704 - mae: 46.0845\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3124.8101 - mae: 45.4862\n",
            "SWAG Model MAE: 45.48616409301758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "# The Olivetti Faces dataset contains a set of face images\n",
        "faces = fetch_olivetti_faces()\n",
        "\n",
        "X = faces.images  # Images of faces\n",
        "y = to_categorical(faces.target)  # One-hot encode the target labels\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# test_size=0.2 allocates 20% of the data for testing, rest for training\n",
        "# random_state=42 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the image data to flatten the image arrays (64x64 pixels)\n",
        "X_train = X_train.reshape((-1, 64*64))\n",
        "X_test = X_test.reshape((-1, 64*64))\n",
        "\n",
        "# Initialize a MinMaxScaler\n",
        "# This scales each feature to a given range, here between 0.01 and 0.99\n",
        "# Scaling images can improve the performance of neural network models\n",
        "min_max_scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "# Fit and transform the training data using the scaler\n",
        "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "X_test_scaled = min_max_scaler.transform(X_test)\n",
        "\n",
        "# Determine the number of features and classes from the data\n",
        "num_features = X_train.shape[1]  # Number of features (flattened image size)\n",
        "num_classes = y.shape[1]         # Number of classes (distinct faces)\n",
        "\n",
        "# Print the number of classes for confirmation\n",
        "print(num_classes)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 10\n",
        "epochs = 15\n",
        "\n",
        "# AutoKeras model for classification\n",
        "# AutoKeras StructuredDataClassifier automatically tries different model architectures\n",
        "# max_trials=5 sets the number of different models AutoKeras will try\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "# Fit the model on the training data\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate the AutoKeras model\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "# Print separators for clarity in output\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Custom optimized model for classification\n",
        "# Creating an instance of a custom optimized model with specific parameters\n",
        "# The model uses accuracy as the performance metric\n",
        "model = create_optimized_model(num_features, 600, num_classes, 'accuracy', 0.0001)  # Learning rate is set to 0.0001\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model on the training data using defined batch size and epochs\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the custom model\n",
        "# Evaluates the model's performance in terms of loss and accuracy\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-zaXKibDx7L",
        "outputId": "8410701e-8d4b-481d-f0d8-35ce62e28928"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 26s]\n",
            "val_accuracy: 0.90625\n",
            "\n",
            "Best val_accuracy So Far: 0.921875\n",
            "Total elapsed time: 00h 12m 15s\n",
            "Epoch 1/15\n",
            "10/10 [==============================] - 56s 33ms/step - loss: 3.5355 - accuracy: 0.1344\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 0s 32ms/step - loss: 1.9764 - accuracy: 0.4281\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 1.2810 - accuracy: 0.6156\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.9327 - accuracy: 0.7156\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 0.6149 - accuracy: 0.8594\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.5160 - accuracy: 0.8813\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.3889 - accuracy: 0.9000\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.3358 - accuracy: 0.9156\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.3205 - accuracy: 0.9156\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.2635 - accuracy: 0.9406\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.2355 - accuracy: 0.9500\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.2439 - accuracy: 0.9469\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.1775 - accuracy: 0.9688\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.1725 - accuracy: 0.9500\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.2240 - accuracy: 0.9375\n",
            "3/3 [==============================] - 44s 73ms/step - loss: 0.5978 - accuracy: 0.8625\n",
            "AutoKeras Model Accuracy: 0.862500011920929\n",
            "******************************************************************************************\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 4s 74ms/step - loss: 0.1949 - accuracy: 0.0219\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0437 - accuracy: 0.1656\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0331 - accuracy: 0.4094\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0296 - accuracy: 0.5250\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 3s 85ms/step - loss: 0.0250 - accuracy: 0.7469\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.0243 - accuracy: 0.7937\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.0217 - accuracy: 0.8625\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 3s 83ms/step - loss: 0.0182 - accuracy: 0.9312\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 2s 70ms/step - loss: 0.0185 - accuracy: 0.9312\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 2s 71ms/step - loss: 0.0175 - accuracy: 0.9500\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 2s 69ms/step - loss: 0.0162 - accuracy: 0.9688\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 2s 72ms/step - loss: 0.0145 - accuracy: 0.9969\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 3s 92ms/step - loss: 0.0135 - accuracy: 0.9937\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.0135 - accuracy: 0.9875\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.0125 - accuracy: 0.9969\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0209 - accuracy: 0.8250\n",
            "SWAG Model Accuracy: 0.824999988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the Linnerud dataset\n",
        "# The Linnerud dataset is a multivariate dataset containing physical measurements and exercise data\n",
        "linnerud = load_linnerud()\n",
        "X = linnerud.data  # Physical measurements (independent variables)\n",
        "y = linnerud.target  # Exercise data (dependent variables)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# test_size=0.2 allocates 20% of the data for testing and the rest for training\n",
        "# random_state=42 ensures reproducibility of the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data\n",
        "# MinMaxScaler scales each feature to a given range, here between 0 and 1\n",
        "# This scaling can improve the performance of neural network models\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)  # Fit to the training data and transform it\n",
        "X_test = scaler.transform(X_test)        # Transform the test data using the same scale\n",
        "\n",
        "# Determine the number of features from the data\n",
        "num_features = X_train.shape[1]  # Number of features in the dataset\n",
        "print(num_features)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras StructuredDataRegressor model\n",
        "# This is an AutoML model that automatically searches for the best model architecture\n",
        "# max_trials=3 sets the number of different models AutoKeras will try\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "# Fit the model on the training data\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate the AutoKeras model\n",
        "# Evaluates the model's performance in terms of loss and mean absolute error (MAE)\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "# Custom optimized model for regression\n",
        "# Creating an instance of a custom optimized model with specific parameters\n",
        "# This model uses mean absolute error (MAE) as a performance metric\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')  # The model predicts a single output\n",
        "\n",
        "# Train the custom model\n",
        "# Fit the model on the training data using defined batch size and epochs\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the custom model\n",
        "# Evaluates the model's performance in terms of loss and MAE\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHA1-SM7FDDf",
        "outputId": "a475f521-8fd2-4d53-9b06-49b7376428a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_loss: 12321.6513671875\n",
            "\n",
            "Best val_loss So Far: 12223.953125\n",
            "Total elapsed time: 00h 00m 19s\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 11ms/step - loss: 12131.4863 - mean_squared_error: 12131.4863\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12122.8203 - mean_squared_error: 12122.8203\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12114.1611 - mean_squared_error: 12114.1611\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12105.2480 - mean_squared_error: 12105.2480\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12096.0723 - mean_squared_error: 12096.0723\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12086.7188 - mean_squared_error: 12086.7188\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12077.1738 - mean_squared_error: 12077.1738\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12067.3398 - mean_squared_error: 12067.3398\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12057.2559 - mean_squared_error: 12057.2559\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12046.8574 - mean_squared_error: 12046.8574\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12036.1768 - mean_squared_error: 12036.1768\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12025.0762 - mean_squared_error: 12025.0762\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12013.6289 - mean_squared_error: 12013.6289\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12001.7891 - mean_squared_error: 12001.7891\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11989.6562 - mean_squared_error: 11989.6562\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11977.1084 - mean_squared_error: 11977.1084\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11964.1396 - mean_squared_error: 11964.1396\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11950.7012 - mean_squared_error: 11950.7012\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11936.7178 - mean_squared_error: 11936.7178\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11921.9316 - mean_squared_error: 11921.9316\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11906.5225 - mean_squared_error: 11906.5225\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11890.4590 - mean_squared_error: 11890.4590\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11873.7100 - mean_squared_error: 11873.7100\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11856.2051 - mean_squared_error: 11856.2051\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11837.9238 - mean_squared_error: 11837.9238\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11818.8555 - mean_squared_error: 11818.8555\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11798.9023 - mean_squared_error: 11798.9023\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11777.9961 - mean_squared_error: 11777.9961\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11755.9941 - mean_squared_error: 11755.9941\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11733.0479 - mean_squared_error: 11733.0479\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 12403.6953 - mean_squared_error: 12403.6953\n",
            "AutoKeras Model MAE: 12403.6953125\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 2s 8ms/step - loss: 12257.5029 - mae: 90.1781\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12242.5762 - mae: 90.0928\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12226.2227 - mae: 89.9994\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12210.6738 - mae: 89.9121\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12194.9277 - mae: 89.8217\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12179.3320 - mae: 89.7324\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12163.1953 - mae: 89.6406\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12147.0098 - mae: 89.5480\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12129.9219 - mae: 89.4500\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12114.4326 - mae: 89.3623\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12097.3369 - mae: 89.2643\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12079.0410 - mae: 89.1586\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12061.1934 - mae: 89.0564\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12041.3262 - mae: 88.9412\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12020.3867 - mae: 88.8199\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12000.6426 - mae: 88.7067\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11978.1953 - mae: 88.5756\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11954.1396 - mae: 88.4361\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11929.7070 - mae: 88.2951\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11901.8389 - mae: 88.1338\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11875.0879 - mae: 87.9776\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11843.7744 - mae: 87.7939\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11812.8350 - mae: 87.6118\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11778.9043 - mae: 87.4109\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11742.9277 - mae: 87.1977\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11703.2949 - mae: 86.9656\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11662.5635 - mae: 86.7254\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11619.1631 - mae: 86.4637\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11574.0254 - mae: 86.1940\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11522.2002 - mae: 85.8807\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 12266.8145 - mae: 88.0236\n",
            "SWAG Model MAE: 88.02359008789062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXIlXrDnG-PT"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}