{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Autokeras library\n",
        "\n",
        "\n",
        "# Import required libraries\n",
        "import timeit\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Embedding, Dense, concatenate, Dropout, Flatten, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects\n",
        "from keras.utils import  to_categorical, plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(110)\n",
        "# Defining new activation functions\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: K.pow(x, 1)),\n",
        "        ('X_2', lambda x: K.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: K.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: K.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: K.pow(x, 2) / 40320),\n",
        "        ('X_3', lambda x: K.pow(x, 3) / 6),\n",
        "        ('X_4', lambda x: K.pow(x, 4) / 24),\n",
        "        ('X_5', lambda x: K.pow(x, 5) / 120),\n",
        "        ('X_6', lambda x: K.pow(x, 6) / 720),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model(input_dim,  hidden_dim , output_dim , metrics_ ):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    concat_first_layer = concatenate([layer_1_x1, layer_1_x2])\n",
        "\n",
        "    # Second layer with custom activations\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "\n",
        "    # Third layer with custom activations\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4)\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1, layer_1_x2, concat_first_layer,\n",
        "                                       layer_x3_x4, layer_x5_x6])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    # Compile the model\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=metrics_)\n",
        "    # model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# optimized_model = create_optimized_model(784,784, 10)\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD",
        "outputId": "c58b14a1-77a3-4e38-dc14-698e49626552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "600/600 [==============================] - 13s 5ms/step - loss: 0.0410 - accuracy: 0.8389 - val_loss: 0.0254 - val_accuracy: 0.9099\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0204 - accuracy: 0.9371 - val_loss: 0.0196 - val_accuracy: 0.9353\n",
            "Training time: 16.397827482000004 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess Iris data\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 10, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "start = timeit.default_timer()\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "KXztQpoaiuYu",
        "outputId": "8ce8ed2f-6f3a-4510-bf27-a6fa37104bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 3s 20ms/step - loss: 0.6485 - accuracy: 0.5167 - val_loss: 0.4542 - val_accuracy: 0.5667\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3776 - accuracy: 0.6667 - val_loss: 0.2697 - val_accuracy: 0.6333\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2349 - accuracy: 0.7333 - val_loss: 0.1786 - val_accuracy: 0.7333\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1655 - accuracy: 0.7750 - val_loss: 0.1354 - val_accuracy: 0.8667\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.8417 - val_loss: 0.1113 - val_accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1068 - accuracy: 0.8417 - val_loss: 0.0989 - val_accuracy: 0.9000\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.8750 - val_loss: 0.0915 - val_accuracy: 0.9333\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.8833 - val_loss: 0.0827 - val_accuracy: 0.9667\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.8917 - val_loss: 0.0766 - val_accuracy: 0.9667\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9000 - val_loss: 0.0722 - val_accuracy: 0.9667\n",
            "Training time: 4.586682243000041 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = to_categorical(digits.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 200, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 20\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "CCEhk7EEBPb6",
        "outputId": "8446a4c9-8590-4488-a933-4fd9adacd89f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "Epoch 1/20\n",
            "144/144 [==============================] - 2s 4ms/step - loss: 2.6331 - accuracy: 0.4099\n",
            "Epoch 2/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 16.9314 - accuracy: 0.3354\n",
            "Epoch 3/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 9.9765 - accuracy: 0.3793\n",
            "Epoch 4/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 1.9988 - accuracy: 0.6006\n",
            "Epoch 5/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.3387 - accuracy: 0.8135\n",
            "Epoch 6/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.8970\n",
            "Epoch 7/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0582 - accuracy: 0.9116\n",
            "Epoch 8/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9339\n",
            "Epoch 9/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9388\n",
            "Epoch 10/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9422\n",
            "Epoch 11/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0346 - accuracy: 0.9443\n",
            "Epoch 12/20\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.0324 - accuracy: 0.9555\n",
            "Epoch 13/20\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.0333 - accuracy: 0.9589\n",
            "Epoch 14/20\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.0464 - accuracy: 0.9457\n",
            "Epoch 15/20\n",
            "144/144 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9450\n",
            "Epoch 16/20\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.2276 - accuracy: 0.8887\n",
            "Epoch 17/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.4871 - accuracy: 0.7662\n",
            "Epoch 18/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.5219 - accuracy: 0.7884\n",
            "Epoch 19/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.3166 - accuracy: 0.8511\n",
            "Epoch 20/20\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9576\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9194\n",
            "Accuracy: 0.9194444417953491\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = to_categorical(wine.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 20\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "u6pEsuuoBPYI",
        "outputId": "dcd56c63-fb91-4240-8f84-ca7ed4b1096a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "Epoch 1/20\n",
            "15/15 [==============================] - 2s 5ms/step - loss: 1.1348 - accuracy: 0.5070\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.6268\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.7676\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1747 - accuracy: 0.8521\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1334 - accuracy: 0.9085\n",
            "Epoch 6/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9296\n",
            "Epoch 7/20\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0944 - accuracy: 0.9366\n",
            "Epoch 8/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9507\n",
            "Epoch 9/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9648\n",
            "Epoch 10/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9648\n",
            "Epoch 11/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9648\n",
            "Epoch 12/20\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9648\n",
            "Epoch 13/20\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9859\n",
            "Epoch 14/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9859\n",
            "Epoch 15/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9789\n",
            "Epoch 16/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9789\n",
            "Epoch 17/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9789\n",
            "Epoch 18/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9859\n",
            "Epoch 19/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9859\n",
            "Epoch 20/20\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9859\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 20\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "g7N_ZWiPBPS2",
        "outputId": "52e32467-76c8-4f49-cf87-85c9d1291c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "Epoch 1/20\n",
            "46/46 [==============================] - 2s 4ms/step - loss: 1.3719 - accuracy: 0.6615\n",
            "Epoch 2/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7275\n",
            "Epoch 3/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.7890\n",
            "Epoch 4/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8264\n",
            "Epoch 5/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.8396\n",
            "Epoch 6/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.8967\n",
            "Epoch 7/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9209\n",
            "Epoch 8/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9187\n",
            "Epoch 9/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9341\n",
            "Epoch 10/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 0.9363\n",
            "Epoch 11/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9297\n",
            "Epoch 12/20\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.1034 - accuracy: 0.9385\n",
            "Epoch 13/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9516\n",
            "Epoch 14/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9560\n",
            "Epoch 15/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9626\n",
            "Epoch 16/20\n",
            "46/46 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9516\n",
            "Epoch 17/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9604\n",
            "Epoch 18/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9538\n",
            "Epoch 19/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9626\n",
            "Epoch 20/20\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9670\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9474\n",
            "Accuracy: 0.9473684430122375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import timeit\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import datasets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Boston Housing data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and train the model\n",
        "input_dim = X_train.shape[1]\n",
        "optimized_model = create_optimized_model(input_dim, input_dim , 1 , 'mae') # input_dim and hidden_dim\n",
        "batch_size = 5\n",
        "epochs = 100\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "id": "Bh72fFHYpQ3R",
        "outputId": "aba81f75-e2c3-4ae9-c8b9-e39b89617966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "81/81 [==============================] - 2s 7ms/step - loss: 422.4798 - mae: 18.4384 - val_loss: 285.5947 - val_mae: 15.0036\n",
            "Epoch 2/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 189.0670 - mae: 11.4974 - val_loss: 136.1927 - val_mae: 10.0943\n",
            "Epoch 3/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 74.8571 - mae: 6.9165 - val_loss: 78.5353 - val_mae: 6.8714\n",
            "Epoch 4/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 38.5398 - mae: 4.6600 - val_loss: 59.3132 - val_mae: 5.6685\n",
            "Epoch 5/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 30.3591 - mae: 4.2077 - val_loss: 57.0448 - val_mae: 5.5512\n",
            "Epoch 6/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 26.6982 - mae: 3.9680 - val_loss: 48.9142 - val_mae: 5.0451\n",
            "Epoch 7/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 23.9488 - mae: 3.7597 - val_loss: 43.0389 - val_mae: 4.6806\n",
            "Epoch 8/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 22.4871 - mae: 3.6269 - val_loss: 39.6823 - val_mae: 4.4826\n",
            "Epoch 9/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 20.2763 - mae: 3.4523 - val_loss: 37.0281 - val_mae: 4.2424\n",
            "Epoch 10/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 18.8847 - mae: 3.3004 - val_loss: 34.6127 - val_mae: 4.1229\n",
            "Epoch 11/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 17.6205 - mae: 3.2242 - val_loss: 31.8517 - val_mae: 3.9551\n",
            "Epoch 12/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 16.8451 - mae: 3.1303 - val_loss: 31.0917 - val_mae: 3.7845\n",
            "Epoch 13/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 15.4902 - mae: 2.9773 - val_loss: 29.9951 - val_mae: 3.6539\n",
            "Epoch 14/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 14.8585 - mae: 2.8739 - val_loss: 29.1236 - val_mae: 3.5158\n",
            "Epoch 15/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 14.0703 - mae: 2.8183 - val_loss: 28.7240 - val_mae: 3.5458\n",
            "Epoch 16/100\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 13.1539 - mae: 2.7117 - val_loss: 26.8863 - val_mae: 3.4004\n",
            "Epoch 17/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 12.8985 - mae: 2.6506 - val_loss: 25.9029 - val_mae: 3.3106\n",
            "Epoch 18/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 12.0334 - mae: 2.5938 - val_loss: 24.2460 - val_mae: 3.2202\n",
            "Epoch 19/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 11.8447 - mae: 2.5427 - val_loss: 23.8336 - val_mae: 3.1425\n",
            "Epoch 20/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 11.6796 - mae: 2.5363 - val_loss: 22.7910 - val_mae: 3.0559\n",
            "Epoch 21/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 10.9494 - mae: 2.4576 - val_loss: 22.7636 - val_mae: 3.0363\n",
            "Epoch 22/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 10.6255 - mae: 2.4157 - val_loss: 24.3428 - val_mae: 3.1388\n",
            "Epoch 23/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 10.5140 - mae: 2.4072 - val_loss: 24.9707 - val_mae: 3.1527\n",
            "Epoch 24/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 10.3478 - mae: 2.4026 - val_loss: 21.6197 - val_mae: 2.9384\n",
            "Epoch 25/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.8803 - mae: 2.3420 - val_loss: 21.3610 - val_mae: 2.9127\n",
            "Epoch 26/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.6898 - mae: 2.3004 - val_loss: 21.5010 - val_mae: 3.0323\n",
            "Epoch 27/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.4546 - mae: 2.2830 - val_loss: 21.6323 - val_mae: 2.9636\n",
            "Epoch 28/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.5820 - mae: 2.2900 - val_loss: 21.5513 - val_mae: 2.9615\n",
            "Epoch 29/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.2826 - mae: 2.2578 - val_loss: 19.1902 - val_mae: 2.8811\n",
            "Epoch 30/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.3469 - mae: 2.2462 - val_loss: 18.6780 - val_mae: 2.7685\n",
            "Epoch 31/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.8440 - mae: 2.2271 - val_loss: 19.1795 - val_mae: 2.8677\n",
            "Epoch 32/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.8770 - mae: 2.2081 - val_loss: 17.2924 - val_mae: 2.7516\n",
            "Epoch 33/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 9.0019 - mae: 2.2008 - val_loss: 19.8432 - val_mae: 2.8547\n",
            "Epoch 34/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.8421 - mae: 2.1976 - val_loss: 17.1932 - val_mae: 2.7384\n",
            "Epoch 35/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.4708 - mae: 2.1364 - val_loss: 17.6185 - val_mae: 2.7122\n",
            "Epoch 36/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.4747 - mae: 2.1584 - val_loss: 18.2532 - val_mae: 2.8597\n",
            "Epoch 37/100\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 8.2952 - mae: 2.1365 - val_loss: 19.8663 - val_mae: 2.9039\n",
            "Epoch 38/100\n",
            "81/81 [==============================] - 1s 15ms/step - loss: 8.6534 - mae: 2.1777 - val_loss: 16.5300 - val_mae: 2.7465\n",
            "Epoch 39/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.3871 - mae: 2.1408 - val_loss: 16.1538 - val_mae: 2.6379\n",
            "Epoch 40/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.0976 - mae: 2.1142 - val_loss: 19.2043 - val_mae: 3.0070\n",
            "Epoch 41/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.2003 - mae: 2.0902 - val_loss: 16.5627 - val_mae: 2.8411\n",
            "Epoch 42/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.9162 - mae: 2.0732 - val_loss: 15.0847 - val_mae: 2.5059\n",
            "Epoch 43/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 8.1639 - mae: 2.1078 - val_loss: 14.7487 - val_mae: 2.5752\n",
            "Epoch 44/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 7.7289 - mae: 2.0579 - val_loss: 17.4796 - val_mae: 2.7943\n",
            "Epoch 45/100\n",
            "81/81 [==============================] - 1s 9ms/step - loss: 7.7062 - mae: 2.0203 - val_loss: 15.2867 - val_mae: 2.5658\n",
            "Epoch 46/100\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 7.7504 - mae: 2.0701 - val_loss: 15.4761 - val_mae: 2.7053\n",
            "Epoch 47/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 7.6174 - mae: 2.0450 - val_loss: 14.3696 - val_mae: 2.5858\n",
            "Epoch 48/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 7.8495 - mae: 2.0617 - val_loss: 12.5888 - val_mae: 2.4254\n",
            "Epoch 49/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 7.7682 - mae: 2.0580 - val_loss: 13.7975 - val_mae: 2.5238\n",
            "Epoch 50/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.5749 - mae: 2.0151 - val_loss: 13.9440 - val_mae: 2.5585\n",
            "Epoch 51/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.4184 - mae: 2.0033 - val_loss: 13.9301 - val_mae: 2.6325\n",
            "Epoch 52/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.2415 - mae: 1.9736 - val_loss: 15.2099 - val_mae: 2.7549\n",
            "Epoch 53/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.2523 - mae: 1.9651 - val_loss: 15.5287 - val_mae: 2.8785\n",
            "Epoch 54/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.6991 - mae: 2.0320 - val_loss: 13.6925 - val_mae: 2.6417\n",
            "Epoch 55/100\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 7.3943 - mae: 1.9702 - val_loss: 15.4493 - val_mae: 2.8630\n",
            "Epoch 56/100\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 7.4044 - mae: 2.0039 - val_loss: 14.6597 - val_mae: 2.7434\n",
            "Epoch 57/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.0671 - mae: 1.9529 - val_loss: 12.0288 - val_mae: 2.4561\n",
            "Epoch 58/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.0526 - mae: 1.9204 - val_loss: 11.7599 - val_mae: 2.3895\n",
            "Epoch 59/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.9641 - mae: 1.9354 - val_loss: 13.5391 - val_mae: 2.6795\n",
            "Epoch 60/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.9447 - mae: 1.9385 - val_loss: 11.4450 - val_mae: 2.4089\n",
            "Epoch 61/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.8307 - mae: 1.8737 - val_loss: 11.1378 - val_mae: 2.4000\n",
            "Epoch 62/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.5378 - mae: 1.8770 - val_loss: 14.3074 - val_mae: 2.7417\n",
            "Epoch 63/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 7.2637 - mae: 1.9844 - val_loss: 12.8881 - val_mae: 2.5794\n",
            "Epoch 64/100\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 6.6717 - mae: 1.8742 - val_loss: 13.0636 - val_mae: 2.6500\n",
            "Epoch 65/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.7752 - mae: 1.9033 - val_loss: 12.1100 - val_mae: 2.5764\n",
            "Epoch 66/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.4325 - mae: 1.8530 - val_loss: 10.6355 - val_mae: 2.3661\n",
            "Epoch 67/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.7471 - mae: 1.8859 - val_loss: 12.7421 - val_mae: 2.6397\n",
            "Epoch 68/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.5793 - mae: 1.8662 - val_loss: 10.7542 - val_mae: 2.3830\n",
            "Epoch 69/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.5926 - mae: 1.8736 - val_loss: 11.9733 - val_mae: 2.5320\n",
            "Epoch 70/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.5278 - mae: 1.8667 - val_loss: 11.6847 - val_mae: 2.5062\n",
            "Epoch 71/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.4542 - mae: 1.8489 - val_loss: 11.6269 - val_mae: 2.4828\n",
            "Epoch 72/100\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 7.0076 - mae: 1.9319 - val_loss: 10.9851 - val_mae: 2.4287\n",
            "Epoch 73/100\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 6.6814 - mae: 1.8633 - val_loss: 11.2568 - val_mae: 2.4187\n",
            "Epoch 74/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 6.6442 - mae: 1.9032 - val_loss: 12.5016 - val_mae: 2.6393\n",
            "Epoch 75/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 6.3623 - mae: 1.8146 - val_loss: 12.7056 - val_mae: 2.6280\n",
            "Epoch 76/100\n",
            "81/81 [==============================] - 1s 8ms/step - loss: 6.4469 - mae: 1.8372 - val_loss: 11.2272 - val_mae: 2.4440\n",
            "Epoch 77/100\n",
            "81/81 [==============================] - 1s 7ms/step - loss: 6.5457 - mae: 1.8512 - val_loss: 10.1221 - val_mae: 2.2957\n",
            "Epoch 78/100\n",
            "81/81 [==============================] - 1s 6ms/step - loss: 6.3026 - mae: 1.8193 - val_loss: 11.3570 - val_mae: 2.4351\n",
            "Epoch 79/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.3189 - mae: 1.8192 - val_loss: 11.3763 - val_mae: 2.4436\n",
            "Epoch 80/100\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 6.4190 - mae: 1.8716 - val_loss: 11.8073 - val_mae: 2.5635\n",
            "Epoch 81/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.3789 - mae: 1.8397 - val_loss: 11.7893 - val_mae: 2.5142\n",
            "Epoch 82/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.4408 - mae: 1.8367 - val_loss: 10.9500 - val_mae: 2.4426\n",
            "Epoch 83/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.1307 - mae: 1.7959 - val_loss: 11.0048 - val_mae: 2.4219\n",
            "Epoch 84/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.0180 - mae: 1.8042 - val_loss: 10.0248 - val_mae: 2.2779\n",
            "Epoch 85/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.0596 - mae: 1.7888 - val_loss: 10.5956 - val_mae: 2.3658\n",
            "Epoch 86/100\n",
            "81/81 [==============================] - 0s 6ms/step - loss: 5.9249 - mae: 1.7504 - val_loss: 11.2545 - val_mae: 2.4575\n",
            "Epoch 87/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.3362 - mae: 1.7957 - val_loss: 9.2623 - val_mae: 2.1698\n",
            "Epoch 88/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.0255 - mae: 1.7707 - val_loss: 10.2293 - val_mae: 2.3096\n",
            "Epoch 89/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.9173 - mae: 1.7792 - val_loss: 11.7185 - val_mae: 2.4910\n",
            "Epoch 90/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.1440 - mae: 1.7991 - val_loss: 11.1455 - val_mae: 2.4170\n",
            "Epoch 91/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.9457 - mae: 1.7702 - val_loss: 9.7985 - val_mae: 2.2718\n",
            "Epoch 92/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.9811 - mae: 1.7844 - val_loss: 10.1956 - val_mae: 2.2729\n",
            "Epoch 93/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.7176 - mae: 1.7536 - val_loss: 13.2606 - val_mae: 2.6380\n",
            "Epoch 94/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.3246 - mae: 1.8144 - val_loss: 10.8578 - val_mae: 2.4268\n",
            "Epoch 95/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.0125 - mae: 1.7713 - val_loss: 10.9015 - val_mae: 2.3691\n",
            "Epoch 96/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.7091 - mae: 1.7693 - val_loss: 10.7129 - val_mae: 2.3227\n",
            "Epoch 97/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 6.0039 - mae: 1.7563 - val_loss: 10.1058 - val_mae: 2.3226\n",
            "Epoch 98/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.5612 - mae: 1.7130 - val_loss: 9.6012 - val_mae: 2.2307\n",
            "Epoch 99/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.5690 - mae: 1.7064 - val_loss: 10.7615 - val_mae: 2.3449\n",
            "Epoch 100/100\n",
            "81/81 [==============================] - 0s 5ms/step - loss: 5.7496 - mae: 1.7278 - val_loss: 10.0585 - val_mae: 2.2910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "batch_size = 10\n",
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "KyPriNtHq-OU",
        "outputId": "931b677f-0a3d-4bdc-e7c0-b42c1ca79d37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 2s 4ms/step - loss: 28582.7051 - mae: 150.3803\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 24822.7812 - mae: 137.9283\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 14633.7646 - mae: 98.0223\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 5654.5830 - mae: 59.5233\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 5073.3301 - mae: 57.2022\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4738.1538 - mae: 55.6386\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4529.4351 - mae: 54.7821\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4381.6143 - mae: 54.2393\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4327.6309 - mae: 53.4523\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 4067.7883 - mae: 51.9712\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3976.6956 - mae: 51.4895\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3872.0215 - mae: 50.8812\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3815.8430 - mae: 50.6333\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3767.8892 - mae: 50.0954\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3646.7104 - mae: 49.3869\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3617.1626 - mae: 49.0564\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3605.9302 - mae: 49.1111\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3539.2000 - mae: 48.9061\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3488.8301 - mae: 48.0669\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3448.2573 - mae: 48.0815\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3388.3381 - mae: 47.7696\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3383.3789 - mae: 47.3877\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3357.7644 - mae: 47.6095\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3317.6304 - mae: 47.1822\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3285.3096 - mae: 46.7145\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3262.9333 - mae: 46.8863\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3235.3218 - mae: 46.7072\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3235.7744 - mae: 46.3118\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3223.4578 - mae: 46.7516\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3176.6006 - mae: 45.9571\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3153.6543 - mae: 45.8330\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3143.3169 - mae: 45.8624\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3142.3162 - mae: 45.5404\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3104.0339 - mae: 45.4090\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 3104.2251 - mae: 45.4499\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 3075.4062 - mae: 45.2210\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3088.5320 - mae: 45.2653\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3044.1516 - mae: 44.7222\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3065.3955 - mae: 45.3821\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3073.7939 - mae: 45.0727\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3054.8245 - mae: 45.1146\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3075.5757 - mae: 45.0474\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3064.6516 - mae: 45.1588\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3011.7178 - mae: 44.6663\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2999.5430 - mae: 44.4547\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 3050.3970 - mae: 45.1034\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 3000.2876 - mae: 44.5306\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2993.3677 - mae: 44.4384\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3008.3496 - mae: 44.7942\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 3009.5415 - mae: 44.3553\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2981.5337 - mae: 44.5519\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2990.5266 - mae: 44.3397\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2972.0779 - mae: 44.3239\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2979.3601 - mae: 44.3868\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2993.7800 - mae: 44.3991\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 3025.6125 - mae: 44.8895\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2947.9619 - mae: 44.1004\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2953.7825 - mae: 44.2201\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2955.7639 - mae: 43.9437\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2941.3708 - mae: 44.0706\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2965.5811 - mae: 44.1356\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2938.8025 - mae: 44.0592\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2942.9543 - mae: 44.0275\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2943.0486 - mae: 44.1091\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2935.2107 - mae: 43.9553\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2932.2317 - mae: 43.8934\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2935.5010 - mae: 43.9176\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2935.2949 - mae: 43.9128\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2940.1008 - mae: 44.0203\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2922.9539 - mae: 43.8378\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2965.9827 - mae: 44.4088\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2927.3062 - mae: 43.9608\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2918.0662 - mae: 43.6289\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2955.0383 - mae: 44.0512\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2967.5698 - mae: 44.3162\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2913.0190 - mae: 43.8653\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2935.8101 - mae: 43.7835\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2922.3237 - mae: 44.0980\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2920.5042 - mae: 43.8350\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2937.8286 - mae: 43.8979\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2917.1675 - mae: 43.9923\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2919.6838 - mae: 43.6878\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2938.8625 - mae: 44.0498\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2902.6487 - mae: 43.6687\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2926.0828 - mae: 44.0620\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2901.6672 - mae: 43.8422\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2910.3696 - mae: 43.9201\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2883.5398 - mae: 43.5072\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2897.0693 - mae: 43.8249\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2904.9895 - mae: 43.8135\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2893.6311 - mae: 43.7060\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2889.9617 - mae: 43.6677\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2888.4966 - mae: 43.7328\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2899.8611 - mae: 43.7566\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2902.3083 - mae: 43.6493\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2890.7993 - mae: 43.7169\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2877.9458 - mae: 43.5627\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2890.3186 - mae: 43.5912\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2892.3708 - mae: 43.5242\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2908.8433 - mae: 43.8081\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2948.7539 - mae: 44.0464\n",
            "Accuracy: 44.046390533447266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.images\n",
        "y = to_categorical(faces.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape((-1, 64*64))\n",
        "X_test = X_test.reshape((-1, 64*64))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 20\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "c-zaXKibDx7L",
        "outputId": "0c796c95-3142-4b0d-88c1-0a6d9e5bb456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to /root/scikit_learn_data\n",
            "4096\n",
            "Epoch 1/20\n",
            "32/32 [==============================] - 2s 4ms/step - loss: 1.7785 - accuracy: 0.0188\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.0375\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.0500\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.0844\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.2250\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.2688\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.4437\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.5125\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.6531\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.7063\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.7594\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.8062\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0217 - accuracy: 0.8438\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.8687\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.8844\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 0.9281\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0202 - accuracy: 0.9125\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9344\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9469\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.3500\n",
            "Accuracy: 0.3499999940395355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_linnerud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "linnerud = load_linnerud()\n",
        "X = linnerud.data\n",
        "y = linnerud.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "batch_size = 10\n",
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "BHA1-SM7FDDf",
        "outputId": "a380f082-4996-47e0-9647-5e17ef58e0c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 13ms/step - loss: 12183.2539 - mae: 89.7331\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12163.3691 - mae: 89.6184\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12148.4424 - mae: 89.5347\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12133.5527 - mae: 89.4530\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12117.9482 - mae: 89.3636\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12099.7412 - mae: 89.2621\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12085.3242 - mae: 89.1800\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12070.1846 - mae: 89.0918\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12054.3633 - mae: 89.0009\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12036.9561 - mae: 88.9000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12018.6113 - mae: 88.7925\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12001.3516 - mae: 88.6919\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11982.4609 - mae: 88.5831\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11966.9688 - mae: 88.4923\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11947.9014 - mae: 88.3800\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11924.7812 - mae: 88.2412\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11903.7852 - mae: 88.1167\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11885.3652 - mae: 88.0096\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11862.1016 - mae: 87.8703\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11835.2080 - mae: 87.7064\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11813.4707 - mae: 87.5795\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11784.1045 - mae: 87.3973\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11756.2607 - mae: 87.2305\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11730.2432 - mae: 87.0767\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11699.9785 - mae: 86.8876\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11666.8369 - mae: 86.6847\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11628.8809 - mae: 86.4422\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11598.5410 - mae: 86.2577\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11557.5508 - mae: 85.9895\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11516.4980 - mae: 85.7303\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 11479.5898 - mae: 85.5050\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11430.0830 - mae: 85.1719\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11389.5977 - mae: 84.9232\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11338.4570 - mae: 84.5885\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11282.2383 - mae: 84.1901\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11236.9229 - mae: 83.9024\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11178.2256 - mae: 83.5446\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11113.2666 - mae: 83.2081\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11057.6621 - mae: 82.8996\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10988.9170 - mae: 82.5341\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10931.8555 - mae: 82.2054\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10855.9863 - mae: 81.7751\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10782.9180 - mae: 81.3581\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10709.0469 - mae: 80.9176\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10636.9131 - mae: 80.5142\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10552.6465 - mae: 80.2037\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10470.8730 - mae: 79.8526\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10393.0762 - mae: 79.4928\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10313.1719 - mae: 79.0665\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10225.9658 - mae: 78.6376\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10141.4199 - mae: 78.2101\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10048.9111 - mae: 77.7127\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9970.3242 - mae: 77.2857\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9878.7988 - mae: 76.7368\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9795.3418 - mae: 76.2423\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9711.8584 - mae: 75.6962\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9610.9336 - mae: 75.0134\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9523.0586 - mae: 74.4057\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9423.6348 - mae: 73.7352\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9337.5068 - mae: 73.1189\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9229.2324 - mae: 72.3487\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9127.2578 - mae: 71.5935\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9028.6562 - mae: 70.9162\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8921.5137 - mae: 70.1804\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8819.7002 - mae: 69.5880\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8703.5039 - mae: 69.0394\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8596.5176 - mae: 68.3979\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8477.3076 - mae: 67.8571\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8370.2529 - mae: 67.3065\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8251.0195 - mae: 66.7865\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8125.6792 - mae: 66.4184\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8017.6079 - mae: 65.9636\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7906.8418 - mae: 65.5401\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7783.5635 - mae: 65.1889\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7666.2065 - mae: 64.8791\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7559.8027 - mae: 64.6072\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7448.5068 - mae: 64.3203\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7339.2573 - mae: 63.9062\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7238.6060 - mae: 63.6117\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7140.7339 - mae: 63.2335\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7049.6855 - mae: 62.8679\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6961.0088 - mae: 62.5065\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6877.3643 - mae: 62.0470\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6798.2305 - mae: 61.7088\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6721.9331 - mae: 61.4531\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6661.0234 - mae: 61.2692\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6597.9341 - mae: 61.0529\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6528.0142 - mae: 60.8577\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6475.1309 - mae: 60.7715\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6419.1572 - mae: 60.5774\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6354.3682 - mae: 60.3160\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6311.2212 - mae: 60.1808\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6250.1118 - mae: 59.9177\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6202.3975 - mae: 59.7136\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6150.0117 - mae: 59.4302\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6094.0156 - mae: 59.1417\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6040.7090 - mae: 58.7892\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5990.0908 - mae: 58.5202\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5943.2119 - mae: 58.2436\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5889.5630 - mae: 57.9623\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 8129.5396 - mae: 64.1007\n",
            "Accuracy: 64.10066986083984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrUBZ25zFcIT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}