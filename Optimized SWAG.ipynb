{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras -q\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD",
        "outputId": "f87a9aa4-82aa-4c68-b5bb-e46e083df7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/148.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m143.4/148.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Embedding, Dense, concatenate, Dropout, Flatten, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects, to_categorical, plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.datasets import load_iris, load_digits, load_wine, load_diabetes, load_breast_cancer, fetch_olivetti_faces, load_linnerud\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.datasets import load_digits"
      ],
      "metadata": {
        "id": "MYXZP4_9n-R7",
        "outputId": "01e59a31-c002-4337-d673-d4b70e92feba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set random seed\n",
        "np.random.seed(110)\n",
        "# Defining new activation functions\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: K.pow(x, 1)),\n",
        "        ('X_2', lambda x: K.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: K.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: K.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: K.pow(x, 2) / 40320),\n",
        "        ('X_3', lambda x: K.pow(x, 3) / 6),\n",
        "        ('X_4', lambda x: K.pow(x, 4) / 24),\n",
        "        ('X_5', lambda x: K.pow(x, 5) / 120),\n",
        "        ('X_6', lambda x: K.pow(x, 6) / 720),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model(input_dim,  hidden_dim , output_dim , metrics_ ):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    concat_first_layer = concatenate([layer_1_x1, layer_1_x2])\n",
        "\n",
        "    # Second layer with custom activations\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "\n",
        "    # Third layer with custom activations\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4)\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1, layer_1_x2, concat_first_layer,\n",
        "                                       layer_x3_x4, layer_x5_x6])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    # Compile the model\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=metrics_)\n",
        "    # model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xID7aH81K83q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized_model = create_optimized_model(784,784, 10)\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "8aQhT2LoKZDH",
        "outputId": "de12355f-b4e0-4e44-d272-c3a059aaef9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "600/600 [==============================] - 58s 90ms/step - loss: 0.0417 - accuracy: 0.8381 - val_loss: 0.0259 - val_accuracy: 0.9082\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 38s 64ms/step - loss: 0.0210 - accuracy: 0.9335 - val_loss: 0.0204 - val_accuracy: 0.9290\n",
            "Training time: 147.50257042699997 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True) # Set max_trials to an appropriate number\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=10)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "_, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 10, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "start = timeit.default_timer()\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n",
        "\n",
        "# Evaluate your model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "KXztQpoaiuYu",
        "outputId": "a742d712-b460-4bc5-f653-11a60570f466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.875\n",
            "\n",
            "Best val_accuracy So Far: 0.9166666865348816\n",
            "Total elapsed time: 00h 00m 05s\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 0.9903 - accuracy: 0.3500\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9019 - accuracy: 0.5667\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8268 - accuracy: 0.6500\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.6583\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.6583\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6583\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6583\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6750\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.6833\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.6917\n",
            "AutoKeras Training time: 8.31083792700008 seconds\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.4481 - accuracy: 0.7667\n",
            "AutoKeras Model Accuracy: 0.7666666507720947\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 2s 25ms/step - loss: 0.8052 - accuracy: 0.5167 - val_loss: 0.6104 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4757 - accuracy: 0.4833 - val_loss: 0.3791 - val_accuracy: 0.3667\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3199 - accuracy: 0.5083 - val_loss: 0.2646 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.5833 - val_loss: 0.2017 - val_accuracy: 0.6333\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.6417 - val_loss: 0.1633 - val_accuracy: 0.7000\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1654 - accuracy: 0.6500 - val_loss: 0.1401 - val_accuracy: 0.7000\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.6667 - val_loss: 0.1259 - val_accuracy: 0.7000\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1275 - accuracy: 0.7333 - val_loss: 0.1132 - val_accuracy: 0.8667\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1154 - accuracy: 0.7917 - val_loss: 0.1032 - val_accuracy: 0.9000\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1061 - accuracy: 0.8500 - val_loss: 0.0938 - val_accuracy: 0.9000\n",
            "Training time: 2.3449986339999214 seconds\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0938 - accuracy: 0.9000\n",
            "SWAG Model Accuracy: 0.8999999761581421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = to_categorical(digits.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 200, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEhk7EEBPb6",
        "outputId": "8b67d919-d199-41bc-83c4-2ea4a465ea15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 17s]\n",
            "val_accuracy: 0.8140350580215454\n",
            "\n",
            "Best val_accuracy So Far: 0.8456140160560608\n",
            "Total elapsed time: 00h 01m 19s\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 1s 4ms/step - loss: 1.9293 - accuracy: 0.3960\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0875 - accuracy: 0.7314\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.8198\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8754\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.9081\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.9255\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2352 - accuracy: 0.9395\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9513\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1634 - accuracy: 0.9631\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9729\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8972\n",
            "AutoKeras Model Accuracy: 0.8972222208976746\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 5ms/step - loss: 0.0491 - accuracy: 0.8559\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0228 - accuracy: 0.9694\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0171 - accuracy: 0.9826\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9896\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 7ms/step - loss: 0.0117 - accuracy: 0.9923\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9806\n",
            "SWAG Accuracy: 0.980555534362793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = to_categorical(wine.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6pEsuuoBPYI",
        "outputId": "eeed143c-18bf-4459-8bb1-b34205dad1dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.5714285969734192\n",
            "\n",
            "Best val_accuracy So Far: 0.7857142686843872\n",
            "Total elapsed time: 00h 00m 13s\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 1.0947 - accuracy: 0.3873\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0027 - accuracy: 0.4789\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9250 - accuracy: 0.6761\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8542 - accuracy: 0.8310\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7863 - accuracy: 0.9225\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7700 - accuracy: 0.8889\n",
            "AutoKeras Model Accuracy: 0.8888888955116272\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.1847 - accuracy: 0.7606\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9437\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9718\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9577\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9789\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9722\n",
            "SWAG Accuracy: 0.9722222089767456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7N_ZWiPBPS2",
        "outputId": "908448ed-9b5d-40b7-a3e5-c641285c164f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.9436619877815247\n",
            "\n",
            "Best val_accuracy So Far: 0.98591548204422\n",
            "Total elapsed time: 00h 00m 16s\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 0.6014 - accuracy: 0.6747\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.9253\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9516\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9582\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9714\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9649\n",
            "AutoKeras Model Accuracy: 0.9649122953414917\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "46/46 [==============================] - 2s 3ms/step - loss: 0.2258 - accuracy: 0.6330\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.8659\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9055\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9143\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9319\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9211\n",
            "Accuracy: 0.9210526347160339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Boston Housing data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "batch_size = 5\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "input_dim = X_train.shape[1]\n",
        "optimized_model = create_optimized_model(input_dim, input_dim , 1 , 'mae') # input_dim and hidden_dim\n",
        "\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "id": "Bh72fFHYpQ3R",
        "outputId": "7d9cbed8-ac1f-4ea2-a507-fb62dadc770d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_loss: 12.249702453613281\n",
            "\n",
            "Best val_loss So Far: 12.249702453613281\n",
            "Total elapsed time: 00h 00m 27s\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 228.7417 - mean_squared_error: 228.7417\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 22.1088 - mean_squared_error: 22.1088\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.2738 - mean_squared_error: 16.2738\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.5260 - mean_squared_error: 13.5260\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.9613 - mean_squared_error: 11.9613\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.0543 - mean_squared_error: 11.0543\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.4837 - mean_squared_error: 10.4837\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.0791 - mean_squared_error: 10.0791\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.7614 - mean_squared_error: 9.7614\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.5075 - mean_squared_error: 9.5075\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.2707 - mean_squared_error: 9.2707\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.0655 - mean_squared_error: 9.0655\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.8808 - mean_squared_error: 8.8808\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.7077 - mean_squared_error: 8.7077\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.5416 - mean_squared_error: 8.5416\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.3903 - mean_squared_error: 8.3903\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.2403 - mean_squared_error: 8.2403\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.1160 - mean_squared_error: 8.1160\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.9822 - mean_squared_error: 7.9822\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.8498 - mean_squared_error: 7.8498\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.7344 - mean_squared_error: 7.7344\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.6107 - mean_squared_error: 7.6107\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.4887 - mean_squared_error: 7.4887\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.3688 - mean_squared_error: 7.3688\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.2620 - mean_squared_error: 7.2620\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.1515 - mean_squared_error: 7.1515\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.0478 - mean_squared_error: 7.0478\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.9452 - mean_squared_error: 6.9452\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.8382 - mean_squared_error: 6.8382\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.7465 - mean_squared_error: 6.7465\n",
            "AutoKeras Training time: 39.24834932099998 seconds\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 20.0327 - mean_squared_error: 20.0327\n",
            "AutoKeras Model MAE: 20.032712936401367\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 4ms/step - loss: 377.4185 - mae: 16.4731 - val_loss: 177.3897 - val_mae: 10.4597\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 117.9101 - mae: 7.9733 - val_loss: 96.3088 - val_mae: 7.1744\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 77.0547 - mae: 6.3827 - val_loss: 71.2641 - val_mae: 6.0899\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 58.5357 - mae: 5.4696 - val_loss: 57.5505 - val_mae: 5.6275\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 48.3287 - mae: 5.0117 - val_loss: 49.4470 - val_mae: 5.1017\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 41.3742 - mae: 4.5508 - val_loss: 41.5290 - val_mae: 4.8089\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 34.3203 - mae: 4.1645 - val_loss: 35.8112 - val_mae: 4.5163\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 28.8520 - mae: 3.7800 - val_loss: 34.2293 - val_mae: 4.3876\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 24.8903 - mae: 3.4896 - val_loss: 30.1459 - val_mae: 4.0247\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 22.9205 - mae: 3.3601 - val_loss: 28.1962 - val_mae: 3.8183\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 21.5498 - mae: 3.2745 - val_loss: 26.0616 - val_mae: 3.6635\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 20.6995 - mae: 3.1565 - val_loss: 26.0309 - val_mae: 3.6119\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 19.6322 - mae: 3.0848 - val_loss: 24.6990 - val_mae: 3.4711\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 19.0928 - mae: 3.0255 - val_loss: 24.6283 - val_mae: 3.5108\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.9572 - mae: 2.9919 - val_loss: 27.3430 - val_mae: 3.6304\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.4062 - mae: 2.9839 - val_loss: 24.6986 - val_mae: 3.4608\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 17.9394 - mae: 2.9382 - val_loss: 23.5669 - val_mae: 3.3609\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 17.1477 - mae: 2.8544 - val_loss: 26.0327 - val_mae: 3.4929\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 17.0570 - mae: 2.8370 - val_loss: 24.3559 - val_mae: 3.3885\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.9132 - mae: 2.8490 - val_loss: 25.1882 - val_mae: 3.3995\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.6260 - mae: 2.8235 - val_loss: 25.3433 - val_mae: 3.3977\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.0525 - mae: 2.8184 - val_loss: 24.5431 - val_mae: 3.3327\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 15.5599 - mae: 2.7277 - val_loss: 25.9337 - val_mae: 3.3491\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 15.5470 - mae: 2.6984 - val_loss: 26.8959 - val_mae: 3.4481\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 14.7338 - mae: 2.6825 - val_loss: 25.6728 - val_mae: 3.4217\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 15.3202 - mae: 2.7289 - val_loss: 27.5145 - val_mae: 3.4790\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 14.6242 - mae: 2.6898 - val_loss: 25.5799 - val_mae: 3.3209\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 14.0333 - mae: 2.5857 - val_loss: 27.6116 - val_mae: 3.4104\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.7252 - mae: 2.5495 - val_loss: 27.4841 - val_mae: 3.4141\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 13.4506 - mae: 2.5858 - val_loss: 28.8513 - val_mae: 3.6284\n",
            "Training time: 7.565252289 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 100\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyPriNtHq-OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f98c261-8791-4344-e0c0-d7e67b28b0de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 21s]\n",
            "val_loss: 2964.636474609375\n",
            "\n",
            "Best val_loss So Far: 2862.560791015625\n",
            "Total elapsed time: 00h 00m 54s\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 1s 3ms/step - loss: 29522.8184 - mean_squared_error: 29522.8184\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 28841.8730 - mean_squared_error: 28841.8730\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 27605.8164 - mean_squared_error: 27605.8164\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 25202.9805 - mean_squared_error: 25202.9805\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 21240.2207 - mean_squared_error: 21240.2207\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 16057.1035 - mean_squared_error: 16057.1035\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 10876.8760 - mean_squared_error: 10876.8760\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 7217.5020 - mean_squared_error: 7217.5020\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 5470.3472 - mean_squared_error: 5470.3472\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4778.0146 - mean_squared_error: 4778.0146\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4431.0859 - mean_squared_error: 4431.0859\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4199.5420 - mean_squared_error: 4199.5420\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 4024.0273 - mean_squared_error: 4024.0273\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3882.7625 - mean_squared_error: 3882.7625\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3766.2490 - mean_squared_error: 3766.2490\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3666.8071 - mean_squared_error: 3666.8071\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3578.9055 - mean_squared_error: 3578.9055\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3500.7815 - mean_squared_error: 3500.7820\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3430.6106 - mean_squared_error: 3430.6106\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3367.5525 - mean_squared_error: 3367.5527\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3310.8442 - mean_squared_error: 3310.8442\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3260.2793 - mean_squared_error: 3260.2793\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3214.2161 - mean_squared_error: 3214.2161\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3172.0859 - mean_squared_error: 3172.0859\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3132.9971 - mean_squared_error: 3132.9971\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3097.4062 - mean_squared_error: 3097.4062\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3064.1377 - mean_squared_error: 3064.1377\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3033.7310 - mean_squared_error: 3033.7310\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3005.5229 - mean_squared_error: 3005.5234\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2979.6504 - mean_squared_error: 2979.6504\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2956.0195 - mean_squared_error: 2956.0195\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2934.7373 - mean_squared_error: 2934.7373\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2916.2588 - mean_squared_error: 2916.2588\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2899.2991 - mean_squared_error: 2899.2991\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2884.4934 - mean_squared_error: 2884.4934\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2870.7192 - mean_squared_error: 2870.7188\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2857.7576 - mean_squared_error: 2857.7576\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2845.6814 - mean_squared_error: 2845.6814\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2834.4431 - mean_squared_error: 2834.4431\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2823.8284 - mean_squared_error: 2823.8284\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2814.5906 - mean_squared_error: 2814.5906\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2805.7891 - mean_squared_error: 2805.7891\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2797.5933 - mean_squared_error: 2797.5933\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2790.0579 - mean_squared_error: 2790.0579\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2782.9133 - mean_squared_error: 2782.9133\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2776.2361 - mean_squared_error: 2776.2361\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2769.8391 - mean_squared_error: 2769.8394\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2763.6184 - mean_squared_error: 2763.6182\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2757.5339 - mean_squared_error: 2757.5339\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2751.6309 - mean_squared_error: 2751.6306\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2746.2151 - mean_squared_error: 2746.2151\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2740.8677 - mean_squared_error: 2740.8677\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2735.8252 - mean_squared_error: 2735.8252\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2730.9934 - mean_squared_error: 2730.9934\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2726.1511 - mean_squared_error: 2726.1511\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2721.6182 - mean_squared_error: 2721.6182\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2717.0969 - mean_squared_error: 2717.0969\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2712.5312 - mean_squared_error: 2712.5312\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2708.3804 - mean_squared_error: 2708.3804\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2704.1272 - mean_squared_error: 2704.1272\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2700.3013 - mean_squared_error: 2700.3013\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2696.1353 - mean_squared_error: 2696.1353\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2692.3457 - mean_squared_error: 2692.3457\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2688.6267 - mean_squared_error: 2688.6267\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2685.0300 - mean_squared_error: 2685.0300\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2681.3547 - mean_squared_error: 2681.3547\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2677.9778 - mean_squared_error: 2677.9778\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2674.1741 - mean_squared_error: 2674.1741\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2670.7605 - mean_squared_error: 2670.7605\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2667.1016 - mean_squared_error: 2667.1016\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2663.9106 - mean_squared_error: 2663.9106\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2660.2388 - mean_squared_error: 2660.2388\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2657.0740 - mean_squared_error: 2657.0740\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2653.7915 - mean_squared_error: 2653.7915\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2650.6838 - mean_squared_error: 2650.6838\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2647.4680 - mean_squared_error: 2647.4680\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2644.4333 - mean_squared_error: 2644.4331\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2641.3706 - mean_squared_error: 2641.3706\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2638.4771 - mean_squared_error: 2638.4771\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2635.4500 - mean_squared_error: 2635.4500\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2632.7710 - mean_squared_error: 2632.7710\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2629.8733 - mean_squared_error: 2629.8733\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2626.9946 - mean_squared_error: 2626.9946\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2624.4031 - mean_squared_error: 2624.4031\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2621.4766 - mean_squared_error: 2621.4771\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2618.6682 - mean_squared_error: 2618.6682\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2615.9214 - mean_squared_error: 2615.9214\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2613.1633 - mean_squared_error: 2613.1633\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2610.4211 - mean_squared_error: 2610.4211\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2607.4761 - mean_squared_error: 2607.4761\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2604.8591 - mean_squared_error: 2604.8591\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2601.8496 - mean_squared_error: 2601.8496\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2599.2124 - mean_squared_error: 2599.2124\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2596.0784 - mean_squared_error: 2596.0784\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2592.9746 - mean_squared_error: 2592.9746\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2590.1484 - mean_squared_error: 2590.1484\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2587.2412 - mean_squared_error: 2587.2412\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2583.9858 - mean_squared_error: 2583.9858\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2581.0901 - mean_squared_error: 2581.0901\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2577.8181 - mean_squared_error: 2577.8181\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2847.1284 - mean_squared_error: 2847.1284\n",
            "AutoKeras Model MAE: 2847.12841796875\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/100\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29210.3027 - mae: 152.2817\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26616.0898 - mae: 143.8725\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 17831.4258 - mae: 112.1782\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 6003.2231 - mae: 61.1081\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4931.0439 - mae: 56.4189\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4677.2749 - mae: 55.0728\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4474.9434 - mae: 54.2519\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4378.8403 - mae: 53.6789\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4184.2520 - mae: 52.5016\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4056.5725 - mae: 51.8826\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3975.4355 - mae: 51.3824\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3888.2471 - mae: 51.1641\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3820.5559 - mae: 50.4688\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3733.6619 - mae: 49.9446\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3689.5149 - mae: 49.7415\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3640.1895 - mae: 49.2364\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3572.4146 - mae: 48.8295\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3534.4011 - mae: 48.6788\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3510.9075 - mae: 48.1739\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3472.7131 - mae: 48.2888\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3452.3066 - mae: 47.9993\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3393.4094 - mae: 47.5819\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3344.3096 - mae: 47.2816\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3334.5642 - mae: 47.0893\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3282.8074 - mae: 46.7946\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3259.1541 - mae: 46.5729\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3248.2117 - mae: 46.4840\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3237.5647 - mae: 46.3604\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3188.0142 - mae: 46.0725\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3188.8838 - mae: 46.0547\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3184.5403 - mae: 45.8691\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3150.4158 - mae: 45.8089\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3123.0093 - mae: 45.4384\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3108.1621 - mae: 45.4735\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3081.1746 - mae: 45.1673\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3094.9023 - mae: 45.2752\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3069.8584 - mae: 45.1103\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3066.5793 - mae: 44.8930\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3049.8357 - mae: 45.1622\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3108.2744 - mae: 45.2777\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3061.1111 - mae: 44.9670\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3056.9426 - mae: 45.3376\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3036.7358 - mae: 44.7812\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3077.0784 - mae: 44.8614\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3001.3994 - mae: 44.3138\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3000.0364 - mae: 44.6079\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3030.0977 - mae: 44.7423\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2983.7542 - mae: 44.3191\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3004.8733 - mae: 44.4738\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2983.8845 - mae: 44.1725\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3008.0945 - mae: 44.3931\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2978.9482 - mae: 44.1834\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2999.5974 - mae: 44.3047\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2968.3728 - mae: 44.1657\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2972.1611 - mae: 44.2027\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2955.0596 - mae: 44.0785\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2961.4495 - mae: 44.1431\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2977.7793 - mae: 44.2157\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2944.4026 - mae: 43.9559\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2933.4514 - mae: 43.9245\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2929.6685 - mae: 43.9682\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2937.0891 - mae: 44.0722\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2927.2842 - mae: 43.9560\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2948.4917 - mae: 44.0855\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2941.7317 - mae: 43.8949\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2940.9502 - mae: 43.8249\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2922.8220 - mae: 43.8810\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2907.3921 - mae: 43.8095\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2967.2388 - mae: 44.2042\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2926.1345 - mae: 43.9248\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2911.1675 - mae: 43.7706\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2915.1680 - mae: 43.8800\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2905.4031 - mae: 43.6725\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2935.1746 - mae: 43.9873\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2919.9790 - mae: 43.8740\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2920.0588 - mae: 43.7469\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2909.6953 - mae: 43.7160\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2898.3938 - mae: 43.5947\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2911.1567 - mae: 43.6968\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2916.0364 - mae: 43.7617\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2910.5110 - mae: 43.7490\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2918.4463 - mae: 43.6758\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2909.9753 - mae: 43.7382\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2917.6472 - mae: 43.6785\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2910.8369 - mae: 43.6466\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2894.9688 - mae: 43.6429\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2899.9756 - mae: 43.5993\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2950.5942 - mae: 44.0190\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2882.7764 - mae: 43.5190\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2923.5396 - mae: 43.8184\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2908.9495 - mae: 43.7537\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2891.8337 - mae: 43.5325\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2902.2825 - mae: 43.6101\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2904.5056 - mae: 43.5469\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2893.0769 - mae: 43.4430\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2891.3376 - mae: 43.4317\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2887.3423 - mae: 43.5022\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2891.7400 - mae: 43.6119\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2889.2798 - mae: 43.5342\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 2881.9907 - mae: 43.4327\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 2883.6309 - mae: 43.4456\n",
            "SWAG Model MAE: 43.44557571411133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.images\n",
        "y = to_categorical(faces.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape((-1, 64*64))\n",
        "X_test = X_test.reshape((-1, 64*64))\n",
        "\n",
        "# Use MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "print(num_classes)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 6\n",
        "\n",
        "# # AutoKeras model\n",
        "# ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# # Train the AutoKeras model\n",
        "# ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# # Evaluate AutoKeras model\n",
        "# loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "# print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, num_features, num_classes, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "c-zaXKibDx7L",
        "outputId": "6e39b274-4420-4c38-ab8f-3720d2f54959"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-842c2614b119>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and preprocess the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_olivetti_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fetch_olivetti_faces' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "linnerud = load_linnerud()\n",
        "X = linnerud.data\n",
        "y = linnerud.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "batch_size = 10\n",
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHA1-SM7FDDf",
        "outputId": "497a7a94-d6e5-401c-c4c9-dd670df94142"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 12ms/step - loss: 12236.7773 - mae: 90.0593\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12203.7246 - mae: 89.8693\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12176.3438 - mae: 89.7125\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12145.0156 - mae: 89.5329\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12115.8711 - mae: 89.3676\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12086.8057 - mae: 89.1992\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12056.2979 - mae: 89.0207\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12025.0195 - mae: 88.8407\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11993.6465 - mae: 88.6577\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11962.9824 - mae: 88.4801\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 11927.8486 - mae: 88.2728\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11895.4570 - mae: 88.0840\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11860.9844 - mae: 87.8825\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11823.7891 - mae: 87.6602\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11786.8887 - mae: 87.4423\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11748.6445 - mae: 87.2185\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11705.3770 - mae: 86.9583\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11664.4600 - mae: 86.7130\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11616.4834 - mae: 86.4236\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11571.5771 - mae: 86.1548\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11518.8789 - mae: 85.8315\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11469.7803 - mae: 85.5330\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11416.7871 - mae: 85.2113\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11360.4844 - mae: 84.8658\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11299.5381 - mae: 84.4909\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11234.8555 - mae: 84.0785\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11168.6143 - mae: 83.6630\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11097.1650 - mae: 83.2180\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11024.9404 - mae: 82.7554\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10953.6484 - mae: 82.3030\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 10867.5801 - mae: 81.7369\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10783.4453 - mae: 81.1922\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10689.8047 - mae: 80.5563\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10602.1914 - mae: 79.9884\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10501.5312 - mae: 79.2989\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10403.5059 - mae: 78.6397\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10296.8828 - mae: 77.9055\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10177.3936 - mae: 77.0458\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10066.5703 - mae: 76.2703\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9943.4941 - mae: 75.4206\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9814.3848 - mae: 74.5331\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 9684.3906 - mae: 73.6652\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9549.6699 - mae: 72.7481\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 9411.0879 - mae: 71.7846\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9261.1426 - mae: 70.6476\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9115.9648 - mae: 69.5662\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 8967.2744 - mae: 68.5133\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8808.5371 - mae: 67.6406\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8654.9854 - mae: 66.8941\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8496.7900 - mae: 66.1780\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8333.2559 - mae: 65.3101\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 8168.9893 - mae: 64.5558\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8027.2056 - mae: 63.9070\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7869.0420 - mae: 63.0722\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7728.7837 - mae: 62.5513\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7591.6528 - mae: 61.9907\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7445.8965 - mae: 61.3914\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7341.0459 - mae: 61.1652\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7215.4741 - mae: 61.0139\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7119.9844 - mae: 60.9716\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7034.5566 - mae: 60.9366\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6960.7939 - mae: 60.8394\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6901.5327 - mae: 60.7268\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6856.1055 - mae: 60.6510\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6822.7388 - mae: 60.7688\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6809.7217 - mae: 60.8300\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6757.3613 - mae: 60.7793\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6740.3032 - mae: 60.9052\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6709.3726 - mae: 60.8998\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6679.0342 - mae: 60.8200\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6649.1855 - mae: 60.7038\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6616.2871 - mae: 60.5629\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6589.5288 - mae: 60.4388\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6562.0542 - mae: 60.2934\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6532.2310 - mae: 60.1189\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 6503.1602 - mae: 59.9919\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6477.6831 - mae: 59.9062\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6451.7612 - mae: 59.8209\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6424.9326 - mae: 59.7398\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6401.9082 - mae: 59.6521\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6376.5615 - mae: 59.5517\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6354.0625 - mae: 59.4934\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6328.3584 - mae: 59.4050\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6307.5693 - mae: 59.3345\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6284.2935 - mae: 59.2526\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6262.9556 - mae: 59.1832\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6242.1157 - mae: 59.1170\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6220.2104 - mae: 59.0179\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6197.0000 - mae: 58.9251\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6175.7573 - mae: 58.8361\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6158.7451 - mae: 58.7454\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6136.9961 - mae: 58.6318\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6119.0508 - mae: 58.5639\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6097.4697 - mae: 58.4775\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6080.5371 - mae: 58.4065\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6058.9189 - mae: 58.3165\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6041.9248 - mae: 58.2615\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6022.2554 - mae: 58.1981\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6005.0840 - mae: 58.1635\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5986.4810 - mae: 58.0967\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 5904.2275 - mae: 57.3307\n",
            "Accuracy: 57.33065414428711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXIlXrDnG-PT"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}