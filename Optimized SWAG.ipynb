{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras -q\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2f4cba-3ae3-40b4-992d-72e047f64213"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak\n",
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Embedding, Dense, concatenate, Dropout, Flatten, Activation\n",
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects, to_categorical, plot_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.datasets import load_iris, load_digits, load_wine, load_diabetes, load_breast_cancer, fetch_olivetti_faces, load_linnerud\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from sklearn.datasets import load_digits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYXZP4_9n-R7",
        "outputId": "fa4480a5-9044-4b99-cf70-d1a347cbb2d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(110)\n",
        "\n",
        "# Define custom activation functions and update the custom objects dictionary\n",
        "def define_activation_functions():\n",
        "    \"\"\"\n",
        "    Define custom activation functions and update the custom objects dictionary.\n",
        "    \"\"\"\n",
        "    # Define activation functions and their respective names\n",
        "    activation_functions = [\n",
        "        ('X_1', lambda x: tf.pow(x, 1)),\n",
        "        ('X_2', lambda x: tf.pow(x, 2) / 2),\n",
        "        ('X_2_', lambda x: tf.pow(x, 2) / 24),\n",
        "        ('X_2__', lambda x: tf.pow(x, 2) / 720),\n",
        "        ('X_2___', lambda x: tf.pow(x, 2) / 40320),\n",
        "    ]\n",
        "\n",
        "    # Update the custom objects dictionary with the defined activation functions\n",
        "    for name, function in activation_functions:\n",
        "        get_custom_objects().update({name: Activation(function)})\n",
        "\n",
        "# Define and register the custom activation functions\n",
        "define_activation_functions()\n",
        "\n",
        "def create_optimized_model(input_dim, hidden_dim, output_dim, metrics='accuracy', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Create an optimized SWAG model with a custom architecture.\n",
        "\n",
        "    :param input_dim: int, dimension of the input data\n",
        "    :param output_dim: int, dimension of the output data\n",
        "    :param hidden_dim: int, hidden layer dimension, default is 50\n",
        "    :return: Model, a compiled Keras model\n",
        "    \"\"\"\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "\n",
        "    # First layer with custom activations\n",
        "    layer_1_x1 = Dense(hidden_dim, activation='X_1')(input_layer)\n",
        "    layer_1_x2 = Dense(hidden_dim, activation='X_2')(input_layer)\n",
        "    concat_first_layer = concatenate([layer_1_x1, layer_1_x2])\n",
        "\n",
        "    # Second layer with custom activations\n",
        "    layer_x3_x4 = Dense(hidden_dim, activation='X_2_')(concat_first_layer)\n",
        "\n",
        "    # Third layer with custom activations\n",
        "    layer_x5_x6 = Dense(hidden_dim, activation='X_2__')(layer_x3_x4)\n",
        "\n",
        "    # Concatenate all layers\n",
        "    concat_second_layer = concatenate([layer_1_x1, layer_1_x2, concat_first_layer,\n",
        "                                       layer_x3_x4, layer_x5_x6])\n",
        "\n",
        "    # Output layer for the concatenated layers\n",
        "    output_first_layer = Dense(hidden_dim, activation='linear')(concat_second_layer)\n",
        "\n",
        "    # Final output layer\n",
        "    output_layer = Dense(output_dim, activation='linear')(output_first_layer)\n",
        "\n",
        "    # Create and compile the model\n",
        "    model = Model(input_layer, output_layer)\n",
        "\n",
        "    # Define the optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model with specified loss and metrics\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[metrics])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "xID7aH81K83q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized_model = create_optimized_model(784,784, 10)\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "id": "8aQhT2LoKZDH",
        "outputId": "693a7c3b-0a78-4de6-f37e-98a2c67f74cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "600/600 [==============================] - 44s 70ms/step - loss: 0.0414 - accuracy: 0.8407 - val_loss: 0.0261 - val_accuracy: 0.9100\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 0.0206 - accuracy: 0.9356 - val_loss: 0.0193 - val_accuracy: 0.9334\n",
            "Training time: 143.68491479 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train, x_test = (x_train + 10) / 300.0, (x_test + 10) / 300.0\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create and train the model\n",
        "optimized_model = create_optimized_model(784, 500, 10 , 'accuracy')\n",
        "batch_size = 100\n",
        "epochs = 2\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVNTPp71EwH5",
        "outputId": "c4c58107-3436-4e1a-c811-75ead2565d37"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "600/600 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.7804"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7d5f6df5e5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 39s 63ms/step - loss: 0.1130 - accuracy: 0.7804 - val_loss: 0.0329 - val_accuracy: 0.8299\n",
            "Epoch 2/2\n",
            "600/600 [==============================] - 37s 62ms/step - loss: 0.0298 - accuracy: 0.8534 - val_loss: 0.0301 - val_accuracy: 0.8443\n",
            "Training time: 83.51366655300012 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train = to_categorical(y_train, 3)\n",
        "y_test = to_categorical(y_test, 3)\n",
        "\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=3, overwrite=True) # Set max_trials to an appropriate number\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=10)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "_, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 10, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "start = timeit.default_timer()\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n",
        "\n",
        "# Evaluate your model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "KXztQpoaiuYu",
        "outputId": "31b4f082-d31a-4ef0-cb15-c63b20d8c5ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 02s]\n",
            "val_accuracy: 0.7083333134651184\n",
            "\n",
            "Best val_accuracy So Far: 0.9166666865348816\n",
            "Total elapsed time: 00h 00m 07s\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 1.1562 - accuracy: 0.3750\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.4500\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0367 - accuracy: 0.5167\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.5667\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9356 - accuracy: 0.5833\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8889 - accuracy: 0.6333\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8439 - accuracy: 0.6917\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8009 - accuracy: 0.7667\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7192 - accuracy: 0.8167\n",
            "AutoKeras Training time: 9.745031700000027 seconds\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.6444 - accuracy: 0.8667\n",
            "AutoKeras Model Accuracy: 0.8666666746139526\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 1s 16ms/step - loss: 2.3860 - accuracy: 0.2667 - val_loss: 1.9895 - val_accuracy: 0.2333\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1718 - accuracy: 0.3083 - val_loss: 0.7984 - val_accuracy: 0.2333\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.4667 - val_loss: 0.3370 - val_accuracy: 0.7333\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.7083 - val_loss: 0.1795 - val_accuracy: 0.7333\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.7417 - val_loss: 0.1355 - val_accuracy: 0.8333\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1180 - accuracy: 0.7917 - val_loss: 0.1186 - val_accuracy: 0.8333\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.8250 - val_loss: 0.1058 - val_accuracy: 0.8667\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.8500 - val_loss: 0.0979 - val_accuracy: 0.9000\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0889 - accuracy: 0.9000 - val_loss: 0.0926 - val_accuracy: 0.9333\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9250 - val_loss: 0.0871 - val_accuracy: 0.9667\n",
            "Training time: 1.7188232759999664 seconds\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0871 - accuracy: 0.9667\n",
            "SWAG Model Accuracy: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = to_categorical(digits.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 200, num_classes, 'accuracy')\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCEhk7EEBPb6",
        "outputId": "6a2dc92b-c15b-4601-acf9-fdd1a882d267"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 16s]\n",
            "val_accuracy: 0.7824561595916748\n",
            "\n",
            "Best val_accuracy So Far: 0.8070175647735596\n",
            "Total elapsed time: 00h 01m 21s\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 1s 4ms/step - loss: 2.2017 - accuracy: 0.2317\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.6601 - accuracy: 0.5428\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1857 - accuracy: 0.6701\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.8611 - accuracy: 0.7662\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.8031\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.8441\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8629\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8831\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.9012\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.9123\n",
            "12/12 [==============================] - 1s 4ms/step - loss: 0.4514 - accuracy: 0.8833\n",
            "AutoKeras Model Accuracy: 0.8833333253860474\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "144/144 [==============================] - 2s 5ms/step - loss: 0.0517 - accuracy: 0.8587\n",
            "Epoch 2/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9638\n",
            "Epoch 3/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9812\n",
            "Epoch 4/5\n",
            "144/144 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9910\n",
            "Epoch 5/5\n",
            "144/144 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9930\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9861\n",
            "SWAG Accuracy: 0.9861111044883728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = to_categorical(wine.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, num_classes, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "u6pEsuuoBPYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cca1ec1-439c-4392-b2aa-e5db3a92d784"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.8571428656578064\n",
            "\n",
            "Best val_accuracy So Far: 0.9285714030265808\n",
            "Total elapsed time: 00h 00m 11s\n",
            "Epoch 1/5\n",
            "5/5 [==============================] - 1s 5ms/step - loss: 1.2534 - accuracy: 0.2887\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0856 - accuracy: 0.4577\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0563 - accuracy: 0.4648\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9120 - accuracy: 0.5704\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8769 - accuracy: 0.6268\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8572 - accuracy: 0.7778\n",
            "AutoKeras Model Accuracy: 0.7777777910232544\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 2ms/step - loss: 0.3067 - accuracy: 0.3451\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.7113\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.8310\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.8873\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9437\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9722\n",
            "SWAG Accuracy: 0.9722222089767456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'accuracy')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7N_ZWiPBPS2",
        "outputId": "66d4122c-909c-4d25-9628-cc2dd9e8cc91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 03s]\n",
            "val_accuracy: 0.47887325286865234\n",
            "\n",
            "Best val_accuracy So Far: 0.98591548204422\n",
            "Total elapsed time: 00h 00m 15s\n",
            "Epoch 1/5\n",
            "15/15 [==============================] - 1s 4ms/step - loss: 0.4757 - accuracy: 0.8703\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9495\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9604\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9758\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9802\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9649\n",
            "AutoKeras Model Accuracy: 0.9649122953414917\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/5\n",
            "46/46 [==============================] - 2s 3ms/step - loss: 0.2519 - accuracy: 0.6132\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.8418\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.8813\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.8989\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9341\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9386\n",
            "Accuracy: 0.9385964870452881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load Boston Housing data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
        "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
        ")\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "batch_size = 5\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "start_ak = timeit.default_timer()\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "end_ak = timeit.default_timer()\n",
        "print(f\"AutoKeras Training time: {end_ak - start_ak} seconds\")\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "input_dim = X_train.shape[1]\n",
        "optimized_model = create_optimized_model(input_dim, input_dim , 1 , 'mae') # input_dim and hidden_dim\n",
        "\n",
        "start = timeit.default_timer()\n",
        "history = optimized_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "\n",
        "# Training time\n",
        "print(f\"Training time: {end - start} seconds\")\n"
      ],
      "metadata": {
        "id": "Bh72fFHYpQ3R",
        "outputId": "c5b5d6db-1c85-4e8f-bd86-4d84c9ecff09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 06s]\n",
            "val_loss: 12.89281177520752\n",
            "\n",
            "Best val_loss So Far: 12.217472076416016\n",
            "Total elapsed time: 00h 00m 26s\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 2ms/step - loss: 262.0479 - mean_squared_error: 262.0479\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 24.0782 - mean_squared_error: 24.0782\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.5472 - mean_squared_error: 16.5472\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 13.8998 - mean_squared_error: 13.8998\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 12.2794 - mean_squared_error: 12.2794\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 11.2639 - mean_squared_error: 11.2639\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.5905 - mean_squared_error: 10.5905\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 10.1265 - mean_squared_error: 10.1265\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.7682 - mean_squared_error: 9.7682\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.4873 - mean_squared_error: 9.4873\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.2291 - mean_squared_error: 9.2291\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 9.0142 - mean_squared_error: 9.0142\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 8.7991 - mean_squared_error: 8.7991\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.6172 - mean_squared_error: 8.6172\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.4351 - mean_squared_error: 8.4351\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.2566 - mean_squared_error: 8.2566\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 8.1072 - mean_squared_error: 8.1072\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.9492 - mean_squared_error: 7.9492\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.8037 - mean_squared_error: 7.8037\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.6526 - mean_squared_error: 7.6526\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.5227 - mean_squared_error: 7.5227\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.3995 - mean_squared_error: 7.3995\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.2654 - mean_squared_error: 7.2654\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.1495 - mean_squared_error: 7.1495\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 7.0357 - mean_squared_error: 7.0357\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.9244 - mean_squared_error: 6.9244\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.8264 - mean_squared_error: 6.8264\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.7361 - mean_squared_error: 6.7361\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.6276 - mean_squared_error: 6.6276\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 6.5353 - mean_squared_error: 6.5353\n",
            "AutoKeras Training time: 37.749356003 seconds\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 20.0172 - mean_squared_error: 20.0172\n",
            "AutoKeras Model MAE: 20.017202377319336\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "81/81 [==============================] - 1s 5ms/step - loss: 352.2473 - mae: 16.0676 - val_loss: 163.5985 - val_mae: 10.2490\n",
            "Epoch 2/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 120.4120 - mae: 8.4538 - val_loss: 104.2029 - val_mae: 7.7561\n",
            "Epoch 3/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 76.3062 - mae: 6.4739 - val_loss: 71.4652 - val_mae: 6.4464\n",
            "Epoch 4/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 55.4514 - mae: 5.4286 - val_loss: 55.7358 - val_mae: 5.5458\n",
            "Epoch 5/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 45.7745 - mae: 4.8650 - val_loss: 48.7308 - val_mae: 5.2400\n",
            "Epoch 6/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 40.5200 - mae: 4.5507 - val_loss: 42.9849 - val_mae: 4.9491\n",
            "Epoch 7/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 35.4368 - mae: 4.3301 - val_loss: 38.5175 - val_mae: 4.6535\n",
            "Epoch 8/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 32.2307 - mae: 4.0989 - val_loss: 34.8186 - val_mae: 4.4138\n",
            "Epoch 9/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 28.7158 - mae: 3.8248 - val_loss: 32.2421 - val_mae: 4.2001\n",
            "Epoch 10/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 26.0165 - mae: 3.6904 - val_loss: 31.9197 - val_mae: 4.1708\n",
            "Epoch 11/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 24.8996 - mae: 3.5717 - val_loss: 28.7128 - val_mae: 3.8773\n",
            "Epoch 12/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 23.4901 - mae: 3.4620 - val_loss: 29.9951 - val_mae: 4.0052\n",
            "Epoch 13/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 23.2670 - mae: 3.4063 - val_loss: 26.8082 - val_mae: 3.6532\n",
            "Epoch 14/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.4263 - mae: 3.2753 - val_loss: 26.1139 - val_mae: 3.6093\n",
            "Epoch 15/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 21.1000 - mae: 3.2206 - val_loss: 25.2478 - val_mae: 3.5523\n",
            "Epoch 16/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 20.5809 - mae: 3.1849 - val_loss: 24.0736 - val_mae: 3.4322\n",
            "Epoch 17/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 20.5083 - mae: 3.1830 - val_loss: 26.2785 - val_mae: 3.6622\n",
            "Epoch 18/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 20.2784 - mae: 3.0680 - val_loss: 23.7860 - val_mae: 3.4281\n",
            "Epoch 19/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 19.2496 - mae: 3.0528 - val_loss: 23.6450 - val_mae: 3.4102\n",
            "Epoch 20/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.5000 - mae: 2.9939 - val_loss: 25.2281 - val_mae: 3.5506\n",
            "Epoch 21/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.2406 - mae: 2.9317 - val_loss: 25.6203 - val_mae: 3.6024\n",
            "Epoch 22/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 18.7125 - mae: 3.0458 - val_loss: 23.2666 - val_mae: 3.3694\n",
            "Epoch 23/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 18.0480 - mae: 2.9422 - val_loss: 22.9319 - val_mae: 3.3559\n",
            "Epoch 24/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 17.4266 - mae: 2.8844 - val_loss: 22.3395 - val_mae: 3.3026\n",
            "Epoch 25/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.9039 - mae: 2.8781 - val_loss: 22.1580 - val_mae: 3.2710\n",
            "Epoch 26/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.5498 - mae: 2.8660 - val_loss: 21.9129 - val_mae: 3.2626\n",
            "Epoch 27/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 17.3677 - mae: 2.9606 - val_loss: 22.2063 - val_mae: 3.2744\n",
            "Epoch 28/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 16.5527 - mae: 2.7960 - val_loss: 22.9947 - val_mae: 3.3738\n",
            "Epoch 29/30\n",
            "81/81 [==============================] - 0s 3ms/step - loss: 16.1358 - mae: 2.8517 - val_loss: 21.8297 - val_mae: 3.2307\n",
            "Epoch 30/30\n",
            "81/81 [==============================] - 0s 2ms/step - loss: 15.7531 - mae: 2.7358 - val_loss: 24.0100 - val_mae: 3.4293\n",
            "Training time: 11.327014303000169 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "diabetes = load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features to be between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyPriNtHq-OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd6385d-2b85-40d7-d2d7-29080076cc84"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 09s]\n",
            "val_loss: 3579.044189453125\n",
            "\n",
            "Best val_loss So Far: 2992.968505859375\n",
            "Total elapsed time: 00h 00m 23s\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29118.2246 - mean_squared_error: 29118.2246\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 27349.4844 - mean_squared_error: 27349.4844\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 23291.1250 - mean_squared_error: 23291.1250\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 16400.8848 - mean_squared_error: 16400.8848\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 9049.7822 - mean_squared_error: 9049.7822\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5199.1216 - mean_squared_error: 5199.1216\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4316.0596 - mean_squared_error: 4316.0596\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3975.3679 - mean_squared_error: 3975.3677\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3746.4487 - mean_squared_error: 3746.4487\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3584.9932 - mean_squared_error: 3584.9932\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3464.8042 - mean_squared_error: 3464.8042\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3371.3445 - mean_squared_error: 3371.3445\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3295.4717 - mean_squared_error: 3295.4717\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3231.5793 - mean_squared_error: 3231.5793\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3177.4985 - mean_squared_error: 3177.4985\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3131.4841 - mean_squared_error: 3131.4841\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3091.9133 - mean_squared_error: 3091.9133\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3057.1589 - mean_squared_error: 3057.1589\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3026.4675 - mean_squared_error: 3026.4675\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2999.1863 - mean_squared_error: 2999.1863\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2974.5811 - mean_squared_error: 2974.5811\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2952.2864 - mean_squared_error: 2952.2864\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2931.2852 - mean_squared_error: 2931.2847\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2913.0957 - mean_squared_error: 2913.0957\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2895.8867 - mean_squared_error: 2895.8867\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2879.6763 - mean_squared_error: 2879.6763\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2864.6907 - mean_squared_error: 2864.6907\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2850.9714 - mean_squared_error: 2850.9714\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2837.8076 - mean_squared_error: 2837.8076\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 2825.3850 - mean_squared_error: 2825.3850\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 3124.2029 - mean_squared_error: 3124.2029\n",
            "AutoKeras Model MAE: 3124.202880859375\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/30\n",
            "36/36 [==============================] - 1s 2ms/step - loss: 29259.5469 - mae: 152.3281\n",
            "Epoch 2/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 26856.0742 - mae: 144.7139\n",
            "Epoch 3/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18374.2031 - mae: 114.2175\n",
            "Epoch 4/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 6672.6367 - mae: 64.0288\n",
            "Epoch 5/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 5206.6655 - mae: 58.0192\n",
            "Epoch 6/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4971.8965 - mae: 56.9463\n",
            "Epoch 7/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4753.2363 - mae: 55.9793\n",
            "Epoch 8/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4626.3203 - mae: 55.1261\n",
            "Epoch 9/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4556.3125 - mae: 55.0020\n",
            "Epoch 10/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4380.4062 - mae: 53.9596\n",
            "Epoch 11/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4283.3413 - mae: 53.4073\n",
            "Epoch 12/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4184.5508 - mae: 52.8733\n",
            "Epoch 13/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4118.5410 - mae: 52.4687\n",
            "Epoch 14/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4122.2944 - mae: 52.3839\n",
            "Epoch 15/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 4019.8240 - mae: 52.0507\n",
            "Epoch 16/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3893.8394 - mae: 50.9216\n",
            "Epoch 17/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3865.3308 - mae: 50.8730\n",
            "Epoch 18/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3777.9419 - mae: 50.3772\n",
            "Epoch 19/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3735.6633 - mae: 50.1256\n",
            "Epoch 20/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3682.9385 - mae: 49.5993\n",
            "Epoch 21/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3656.1777 - mae: 49.3554\n",
            "Epoch 22/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3591.2903 - mae: 49.2973\n",
            "Epoch 23/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3548.5332 - mae: 48.6280\n",
            "Epoch 24/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3481.6453 - mae: 48.2408\n",
            "Epoch 25/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3487.2610 - mae: 48.4171\n",
            "Epoch 26/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3423.4180 - mae: 47.9145\n",
            "Epoch 27/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3393.7510 - mae: 47.7137\n",
            "Epoch 28/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3375.1550 - mae: 47.5822\n",
            "Epoch 29/30\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 3339.5725 - mae: 47.3773\n",
            "Epoch 30/30\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 3312.7634 - mae: 46.9221\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 3119.4688 - mae: 45.5820\n",
            "SWAG Model MAE: 45.58197784423828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "faces = fetch_olivetti_faces()\n",
        "\n",
        "X = faces.images\n",
        "y = to_categorical(faces.target)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape((-1, 64*64))\n",
        "X_test = X_test.reshape((-1, 64*64))\n",
        "\n",
        "min_max_scaler = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the same scaler\n",
        "X_test_scaled = min_max_scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "num_classes = y.shape[1]\n",
        "\n",
        "print(num_classes)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 15\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataClassifier(max_trials=5, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss, ak_accuracy = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model Accuracy: {ak_accuracy}\")\n",
        "\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "print('******************************************************************************************')\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 1000 , num_classes, 'accuracy',0.0001)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-zaXKibDx7L",
        "outputId": "00eb7844-8925-4a6f-ccd2-51ee8f57e2c0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "******************************************************************************************\n",
            "Epoch 1/15\n",
            "32/32 [==============================] - 12s 301ms/step - loss: 0.3583 - accuracy: 0.0281\n",
            "Epoch 2/15\n",
            "32/32 [==============================] - 5s 169ms/step - loss: 0.0413 - accuracy: 0.2188\n",
            "Epoch 3/15\n",
            "32/32 [==============================] - 5s 166ms/step - loss: 0.0307 - accuracy: 0.5156\n",
            "Epoch 4/15\n",
            "32/32 [==============================] - 11s 332ms/step - loss: 0.0265 - accuracy: 0.6906\n",
            "Epoch 5/15\n",
            "32/32 [==============================] - 5s 160ms/step - loss: 0.0241 - accuracy: 0.8000\n",
            "Epoch 6/15\n",
            "32/32 [==============================] - 5s 162ms/step - loss: 0.0214 - accuracy: 0.8719\n",
            "Epoch 7/15\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 0.0194 - accuracy: 0.9062\n",
            "Epoch 8/15\n",
            "32/32 [==============================] - 5s 166ms/step - loss: 0.0178 - accuracy: 0.9219\n",
            "Epoch 9/15\n",
            "32/32 [==============================] - 5s 157ms/step - loss: 0.0160 - accuracy: 0.9625\n",
            "Epoch 10/15\n",
            "32/32 [==============================] - 7s 218ms/step - loss: 0.0159 - accuracy: 0.9594\n",
            "Epoch 11/15\n",
            "32/32 [==============================] - 6s 178ms/step - loss: 0.0147 - accuracy: 0.9875\n",
            "Epoch 12/15\n",
            "32/32 [==============================] - 5s 155ms/step - loss: 0.0128 - accuracy: 0.9937\n",
            "Epoch 13/15\n",
            "32/32 [==============================] - 6s 196ms/step - loss: 0.0126 - accuracy: 0.9937\n",
            "Epoch 14/15\n",
            "32/32 [==============================] - 7s 206ms/step - loss: 0.0111 - accuracy: 0.9969\n",
            "Epoch 15/15\n",
            "32/32 [==============================] - 5s 165ms/step - loss: 0.0104 - accuracy: 0.9969\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0193 - accuracy: 0.8750\n",
            "Accuracy: 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "linnerud = load_linnerud()\n",
        "X = linnerud.data\n",
        "y = linnerud.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using MinMaxScaler to scale the data between 0 and 1\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "# num_classes = y_train.shape[1]\n",
        "\n",
        "print(num_features)\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 30\n",
        "\n",
        "# AutoKeras model\n",
        "ak_model = ak.StructuredDataRegressor(max_trials=3, overwrite=True)\n",
        "\n",
        "# Train the AutoKeras model\n",
        "ak_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "# Evaluate AutoKeras model\n",
        "loss_ak, ak_mae = ak_model.evaluate(X_test, y_test)\n",
        "print(f\"AutoKeras Model MAE: {ak_mae}\")\n",
        "\n",
        "# Create and train the model\n",
        "model = create_optimized_model(num_features, 20, 1, 'mae')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"SWAG Model MAE: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHA1-SM7FDDf",
        "outputId": "6f158ef8-defd-4a6e-ab6a-944f069f8990"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 05s]\n",
            "val_loss: 11774.1171875\n",
            "\n",
            "Best val_loss So Far: 11774.1171875\n",
            "Total elapsed time: 00h 00m 13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7a9a9fab6320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 12ms/step - loss: 12147.0664 - mean_squared_error: 12147.0664\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12113.1172 - mean_squared_error: 12113.1172\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12079.6738 - mean_squared_error: 12079.6738\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12043.1289 - mean_squared_error: 12043.1279\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12002.6738 - mean_squared_error: 12002.6738\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11958.1689 - mean_squared_error: 11958.1689\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11908.9062 - mean_squared_error: 11908.9062\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11854.0107 - mean_squared_error: 11854.0107\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11792.8945 - mean_squared_error: 11792.8945\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11724.8867 - mean_squared_error: 11724.8867\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11649.1445 - mean_squared_error: 11649.1445\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11565.0537 - mean_squared_error: 11565.0537\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11471.8291 - mean_squared_error: 11471.8281\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11368.7891 - mean_squared_error: 11368.7891\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11255.1699 - mean_squared_error: 11255.1699\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11130.2559 - mean_squared_error: 11130.2559\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10993.2607 - mean_squared_error: 10993.2607\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10843.4805 - mean_squared_error: 10843.4805\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10680.2363 - mean_squared_error: 10680.2363\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10502.8643 - mean_squared_error: 10502.8652\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10310.8613 - mean_squared_error: 10310.8613\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10103.9062 - mean_squared_error: 10103.9072\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9881.7490 - mean_squared_error: 9881.7490\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9644.3086 - mean_squared_error: 9644.3076\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9391.6465 - mean_squared_error: 9391.6465\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9124.0137 - mean_squared_error: 9124.0137\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8842.0430 - mean_squared_error: 8842.0430\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8546.4121 - mean_squared_error: 8546.4121\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8238.0869 - mean_squared_error: 8238.0869\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7918.4746 - mean_squared_error: 7918.4746\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 8789.0176 - mean_squared_error: 8789.0176\n",
            "AutoKeras Model MAE: 8789.017578125\n",
            "Epoch 1/30\n",
            "2/2 [==============================] - 1s 9ms/step - loss: 12117.7891 - mae: 89.3706\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12095.1152 - mae: 89.2397\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12073.4707 - mae: 89.1147\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12051.0225 - mae: 88.9835\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12028.0654 - mae: 88.8514\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12004.4062 - mae: 88.7133\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11979.2041 - mae: 88.5656\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11956.6973 - mae: 88.4336\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11931.8047 - mae: 88.2879\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11906.7725 - mae: 88.1417\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11880.3379 - mae: 87.9864\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11852.2773 - mae: 87.8212\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11822.3730 - mae: 87.6427\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11793.9199 - mae: 87.4741\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11762.4414 - mae: 87.2882\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11727.9629 - mae: 87.0826\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11693.6055 - mae: 86.8749\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11656.6377 - mae: 86.6533\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11617.3262 - mae: 86.4166\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11574.1602 - mae: 86.1564\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11534.7998 - mae: 85.9183\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11484.5752 - mae: 85.6099\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11436.8730 - mae: 85.3148\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11384.7715 - mae: 84.9899\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11330.4590 - mae: 84.6576\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11272.2812 - mae: 84.2966\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11213.0078 - mae: 83.9258\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11147.1621 - mae: 83.5089\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11073.0020 - mae: 83.0249\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11005.6338 - mae: 82.6081\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 11535.0078 - mae: 83.7098\n",
            "SWAG Model MAE: 83.70980072021484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXIlXrDnG-PT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}