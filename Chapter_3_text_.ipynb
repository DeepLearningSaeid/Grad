{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Chapter_3_text_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We analyzed the performance of seven different models on the Ionosphere Dataset using 10-fold cross-validation. Here are the detailed results and comparisons:\n",
        "\n",
        "Initial Results:\n",
        "\n",
        "    Chebyshev First kind: [91.43, 57.14, 80.0, 85.71, 94.29, 88.57, 91.43, 91.43, 100.0, 82.86], Mean: 86.29\n",
        "    Chebyshev Second kind: [91.43, 85.71, 85.71, 94.29, 88.57, 94.29, 97.14, 97.14, 82.86, 85.71], Mean: 90.29\n",
        "    SWAG: [91.43, 100.0, 91.43, 91.43, 97.14, 97.14, 97.14, 97.14, 97.14, 100.0], Mean: 96.0\n",
        "    Hermite: [48.57, 34.29, 71.43, 37.14, 42.86, 65.71, 48.57, 80.0, 65.71, 71.43], Mean: 56.57\n",
        "    Legendre: [91.43, 91.43, 94.29, 97.14, 100.0, 91.43, 94.29, 97.14, 97.14, 97.14], Mean: 95.14\n",
        "    Sin(nX): [85.71, 100.0, 97.14, 97.14, 100.0, 97.14, 97.14, 100.0, 100.0, 100.0], Mean: 97.43\n",
        "    AutoKeras: [82.86, 65.71, 77.14, 68.57, 91.43, 77.14, 68.57, 91.43, 74.29, 80.0], Mean: 77.71\n",
        "\n",
        "After applying a coefficient, new results have been obtained for some models:\n",
        "\n",
        "New Results after Coefficient:\n",
        "\n",
        "    Chebyshev First kind: [88.57, 100.0, 88.57, 97.14, 100.0, 97.14, 97.14, 97.14, 100.0, 100.0], Mean: 96.57\n",
        "    Chebyshev Second kind: [88.57, 100.0, 88.57, 94.29, 97.14, 97.14, 97.14, 97.14, 100.0, 100.0], Mean: 96.0\n",
        "    Hermite: [88.57, 100.0, 94.29, 97.14, 100.0, 97.14, 97.14, 97.14, 97.14, 100.0], Mean: 96.86\n",
        "    Legendre: [91.43, 100.0, 94.29, 97.14, 100.0, 97.14, 97.14, 97.14, 94.29, 100.0], Mean: 96.86"
      ],
      "metadata": {
        "id": "HPQTnrC8m03I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#****** ******** ******* ******** ******* ******** ****** ********\n",
        "You have provided results for 7 different models on the Ionosphere dataset using 10-fold cross-validation, as well as the results for 4 of the models after applying a coefficient. Let's analyze and compare the models before and after applying the coefficients:\n",
        "\n",
        "Before applying coefficients:\n",
        "\n",
        "    Chebyshev First kind\n",
        "    Mean Accuracy: 86.29%\n",
        "    Standard Deviation: 10.58%\n",
        "\n",
        "    Chebyshev Second kind\n",
        "    Mean Accuracy: 90.29%\n",
        "    Standard Deviation: 4.80%\n",
        "\n",
        "    SWAG\n",
        "    Mean Accuracy: 96.00%\n",
        "    Standard Deviation: 3.52%\n",
        "\n",
        "    Hermite\n",
        "    Mean Accuracy: 56.57%\n",
        "    Standard Deviation: 17.29%\n",
        "\n",
        "    Legendre\n",
        "    Mean Accuracy: 95.14%\n",
        "    Standard Deviation: 2.83%\n",
        "\n",
        "    Sin(nX)\n",
        "    Mean Accuracy: 97.43%\n",
        "    Standard Deviation: 4.62%\n",
        "\n",
        "    AutoKeras\n",
        "    Mean Accuracy: 77.71%\n",
        "    Standard Deviation: 8.67%\n",
        "\n",
        "After applying coefficients:\n",
        "\n",
        "    Chebyshev First kind (with coefficient)\n",
        "    Mean Accuracy: 96.57%\n",
        "    Standard Deviation: 4.39%\n",
        "\n",
        "    Chebyshev Second kind (with coefficient)\n",
        "    Mean Accuracy: 96.00%\n",
        "    Standard Deviation: 4.69%\n",
        "\n",
        "    Hermite (with coefficient)\n",
        "    Mean Accuracy: 96.86%\n",
        "    Standard Deviation: 3.66%\n",
        "\n",
        "    Legendre (with coefficient)\n",
        "    Mean Accuracy: 96.86%\n",
        "    Standard Deviation: 2.61%\n",
        "\n",
        "Comparison of results:\n",
        "\n",
        "    Chebyshev First kind: After applying the coefficient, the mean accuracy increased by 10.28%, and the standard deviation decreased by 6.19%, indicating better performance and less variability.\n",
        "    Chebyshev Second kind: The mean accuracy improved by 5.71%, and the standard deviation remained relatively stable (-0.11%) after applying the coefficient.\n",
        "    Hermite: The most significant improvement was observed in the Hermite model, with a mean accuracy increase of 40.29% and a standard deviation decrease of 13.63%.\n",
        "    Legendre: After applying the coefficient, the mean accuracy increased by 1.72%, and the standard deviation decreased by 0.22%.\n",
        "\n",
        "After applying the coefficients, the Chebyshev First kind, Chebyshev Second kind, Hermite, and Legendre models have similar mean accuracies and standard deviations, making them all suitable choices for the Ionosphere dataset. The Hermite model, in particular, has seen a dramatic improvement in performance.\n",
        "\n",
        "It's also worth noting that even after applying the coefficients, the Sin(nX) model (from the initial set of results) still performs competitively, with a mean accuracy of 97.43% and a standard deviation of 4.62%. The SWAG model also performs well, with a mean accuracy of 96.00% and a standard deviation of 3.52%.\n"
      ],
      "metadata": {
        "id": "OUuAzTFPorcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We conducted an analysis of seven different models applied to the Banknote Authentication Dataset using 10-fold cross-validation. The models are as follows: Chebyshev First Kind, Chebyshev Second Kind, SWAG, Hermite, Legendre, Sin(nX), and AutoKeras. Below, we detail their performance and compare them.\n",
        "\n",
        "Initial Results:\n",
        "\n",
        "    Chebyshev First: [98.55, 97.83, 98.54, 96.35, 97.81, 96.35, 99.27, 100.0, 100.0, 100.0]\n",
        "    Chebyshev Second: [99.28, 97.83, 98.54, 97.08, 97.81, 96.35, 99.27, 98.54, 100.0, 100.0]\n",
        "    SWAG: [100.0, 95.65, 98.54, 96.35, 97.81, 96.35, 99.27, 98.54, 98.54, 100.0]\n",
        "    Hermite: [98.55, 95.65, 96.35, 97.81, 97.08, 97.81, 99.27, 97.81, 98.54, 98.54]\n",
        "    Legendre: [100.0, 97.83, 98.54, 97.08, 97.81, 99.27, 100.0, 99.27, 97.81, 100.0]\n",
        "    Sin(nX): [100.0, 100.0, 97.81, 97.08, 97.81, 99.27, 100.0, 100.0, 100.0, 100.0]\n",
        "    AutoKeras: [62.32, 61.59, 72.99, 78.83, 70.8, 55.47, 71.53, 44.53, 55.47, 59.12]\n",
        "\n",
        "Results after applying coefficients:\n",
        "\n",
        "    Chebyshev First: [100.0, 97.83, 97.81, 97.08, 99.27, 96.35, 100.0, 98.54, 100.0, 100.0]\n",
        "    Chebyshev Second: [100.0, 97.1, 100.0, 97.08, 97.08, 96.35, 99.27, 99.27, 100.0, 100.0]\n",
        "    Hermite: [99.28, 97.83, 98.54, 97.08, 97.81, 98.54, 99.27, 98.54, 99.27, 100.0]\n",
        "    Legendre: [100.0, 97.83, 95.62, 96.35, 97.81, 96.35, 99.27, 98.54, 98.54, 100.0]"
      ],
      "metadata": {
        "id": "TEhuBV06nlB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#****** ******** ******* ******** ******* ******** ****** ********\n",
        "\n",
        "You have provided results for 7 different models on the Banknote Authentication dataset using 10-fold cross-validation, as well as the results for 4 of the models after applying a coefficient. Let's analyze and compare the models before and after applying the coefficients:\n",
        "\n",
        "Before applying coefficients:\n",
        "\n",
        "    Chebyshev First kind\n",
        "    Mean Accuracy: 98.47%\n",
        "    Standard Deviation: 1.28%\n",
        "\n",
        "    Chebyshev Second kind\n",
        "    Mean Accuracy: 98.47%\n",
        "    Standard Deviation: 1.22%\n",
        "\n",
        "    SWAG\n",
        "    Mean Accuracy: 98.11%\n",
        "    Standard Deviation: 1.65%\n",
        "\n",
        "    Hermite\n",
        "    Mean Accuracy: 97.74%\n",
        "    Standard Deviation: 1.26%\n",
        "\n",
        "    Legendre\n",
        "    Mean Accuracy: 98.76%\n",
        "    Standard Deviation: 1.19%\n",
        "\n",
        "    Sin(nX)\n",
        "    Mean Accuracy: 99.20%\n",
        "    Standard Deviation: 1.08%\n",
        "\n",
        "    AutoKeras\n",
        "    Mean Accuracy: 63.27%\n",
        "    Standard Deviation: 10.92%\n",
        "\n",
        "After applying coefficients:\n",
        "\n",
        "    Chebyshev First kind (with coefficient)\n",
        "    Mean Accuracy: 98.69%\n",
        "    Standard Deviation: 1.23%\n",
        "\n",
        "    Chebyshev Second kind (with coefficient)\n",
        "    Mean Accuracy: 98.62%\n",
        "    Standard Deviation: 1.42%\n",
        "\n",
        "    Hermite (with coefficient)\n",
        "    Mean Accuracy: 98.62%\n",
        "    Standard Deviation: 0.96%\n",
        "\n",
        "    Legendre (with coefficient)\n",
        "    Mean Accuracy: 98.03%\n",
        "    Standard Deviation: 1.71%\n",
        "\n",
        "Comparison of results:\n",
        "\n",
        "    Chebyshev First kind: After applying the coefficient, the mean accuracy increased by 0.22%, and the standard deviation decreased slightly by 0.05%.\n",
        "    Chebyshev Second kind: The mean accuracy improved by 0.15%, and the standard deviation increased by 0.20% after applying the coefficient.\n",
        "    Hermite: The Hermite model improved by 0.88% in mean accuracy, and the standard deviation decreased by 0.30% after applying the coefficient.\n",
        "    Legendre: After applying the coefficient, the mean accuracy decreased by 0.73%, and the standard deviation increased by 0.52%.\n",
        "\n",
        "After applying the coefficients, the Chebyshev First kind, Chebyshev Second kind, and Hermite models show similar mean accuracies and standard deviations, making them all suitable choices for the Banknote Authentication dataset. The Legendre model's performance slightly decreased after applying the coefficient.\n",
        "\n",
        "It's also worth noting that even after applying the coefficients, the Sin(nX) model (from the initial set of results) still performs competitively, with a mean accuracy of 99.20% and a standard deviation of 1.08%. The AutoKeras model, however, underperforms compared to the other models, with a mean accuracy of 63.27% and a standard deviation of 10.92%."
      ],
      "metadata": {
        "id": "kkdCTr-GpIat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We analyzed seven different models on the Connectionist Bench Dataset using 10-fold cross-validation. The models include Chebyshev First Kind, Chebyshev Second Kind, SWAG, Hermite, Legendre, Sin(nX), and AutoKeras. We provide a detailed comparison of their performances below.\n",
        "\n",
        "Initial Results:\n",
        "\n",
        "    Chebyshev First Kind: [100.0, 85.71, 95.24, 95.24, 95.24, 61.9, 90.48, 85.71, 90.0, 95.0]\n",
        "    Chebyshev Second Kind: [76.19, 90.48, 100.0, 95.24, 100.0, 95.24, 100.0, 100.0, 100.0, 95.0]\n",
        "    SWAG: [71.43, 95.24, 90.48, 85.71, 100.0, 90.48, 100.0, 100.0, 100.0, 100.0]\n",
        "    Hermite: [61.9, 76.19, 47.62, 61.9, 47.62, 57.14, 52.38, 42.86, 75.0, 75.0]\n",
        "    Legendre: [80.95, 90.48, 90.48, 90.48, 95.24, 95.24, 95.24, 100.0, 70.0, 100.0]\n",
        "    Sin(nX): [85.71, 90.48, 100.0, 85.71, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
        "    AutoKeras: [52.38, 61.9, 57.14, 61.9, 76.19, 61.9, 71.43, 57.14, 75.0, 55.0]\n",
        "\n",
        "Results after applying coefficients:\n",
        "\n",
        "    Chebyshev First Kind: [85.71, 95.24, 90.48, 80.95, 100.0, 95.24, 95.24, 95.24, 95.0, 100.0]\n",
        "    Chebyshev Second Kind: [80.95, 80.95, 90.48, 71.43, 100.0, 95.24, 100.0, 100.0, 100.0, 95.0]\n",
        "    Hermite: [76.19, 95.24, 95.24, 100.0, 100.0, 100.0, 95.24, 100.0, 100.0, 100.0]\n",
        "    Legendre: [85.71, 100.0, 85.71, 76.19, 100.0, 95.24, 95.24, 100.0, 100.0, 100.0]"
      ],
      "metadata": {
        "id": "DjNrg6b-nxwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#****** ******** ******* ******** ******* ******** ****** ********\n",
        "\n",
        "You have provided results for 7 different models on the Connectionist Bench dataset using 10-fold cross-validation, as well as the results for 4 of the models after applying a coefficient. Let's analyze and compare the models before and after applying the coefficients:\n",
        "\n",
        "Before applying coefficients:\n",
        "\n",
        "    Chebyshev First kind\n",
        "    Mean Accuracy: 89.45%\n",
        "    Standard Deviation: 10.52%\n",
        "\n",
        "    Chebyshev Second kind\n",
        "    Mean Accuracy: 95.21%\n",
        "    Standard Deviation: 7.33%\n",
        "\n",
        "    SWAG\n",
        "    Mean Accuracy: 93.33%\n",
        "    Standard Deviation: 9.24%\n",
        "\n",
        "    Hermite\n",
        "    Mean Accuracy: 59.76%\n",
        "    Standard Deviation: 12.16%\n",
        "\n",
        "    Legendre\n",
        "    Mean Accuracy: 90.81%\n",
        "    Standard Deviation: 9.01%\n",
        "\n",
        "    Sin(nX)\n",
        "    Mean Accuracy: 96.19%\n",
        "    Standard Deviation: 6.45%\n",
        "\n",
        "    AutoKeras\n",
        "    Mean Accuracy: 63.00%\n",
        "    Standard Deviation: 8.27%\n",
        "\n",
        "After applying coefficients:\n",
        "\n",
        "    Chebyshev First kind (with coefficient)\n",
        "    Mean Accuracy: 93.31%\n",
        "    Standard Deviation: 7.02%\n",
        "\n",
        "    Chebyshev Second kind (with coefficient)\n",
        "    Mean Accuracy: 91.40%\n",
        "    Standard Deviation: 9.30%\n",
        "\n",
        "    Hermite (with coefficient)\n",
        "    Mean Accuracy: 96.19%\n",
        "    Standard Deviation: 7.43%\n",
        "\n",
        "    Legendre (with coefficient)\n",
        "    Mean Accuracy: 93.81%\n",
        "    Standard Deviation: 8.80%\n",
        "\n",
        "Comparison of results:\n",
        "\n",
        "    Chebyshev First kind: After applying the coefficient, the mean accuracy increased by 3.86%, and the standard deviation decreased by 3.50%.\n",
        "    Chebyshev Second kind: The mean accuracy decreased by 3.81%, and the standard deviation increased by 1.97% after applying the coefficient.\n",
        "    Hermite: The Hermite model significantly improved by 36.43% in mean accuracy, and the standard deviation decreased by 4.73% after applying the coefficient.\n",
        "    Legendre: After applying the coefficient, the mean accuracy increased by 3.00%, and the standard deviation decreased by 0.21%.\n",
        "\n",
        "After applying the coefficients, the Hermite model (with coefficient) and Sin(nX) model (from the initial set of results) show the highest mean accuracies at 96.19% and have competitive standard deviations. The other models, including Chebyshev First kind (with coefficient) and Legendre (with coefficient), also perform well, but with slightly lower mean accuracies and higher standard deviations. The AutoKeras model underperforms compared to the other models, with a mean accuracy of 63.00% and a standard deviation of 8.27%."
      ],
      "metadata": {
        "id": "LGoKvuu5q4d4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We analyzed seven different models on the Pima Indians Diabetes Dataset using 10-fold cross-validation. The models include Chebyshev First Kind, Chebyshev Second Kind, SWAG, Hermite, Legendre, Sin(nX), and AutoKeras. We provide a detailed comparison of their performances below.\n",
        "\n",
        "Initial Results:\n",
        "\n",
        "    Chebyshev First Kind: [80.52, 77.92, 77.92, 74.03, 81.82, 81.82, 72.73, 77.63, 72.37, 77.63]\n",
        "    Chebyshev Second Kind: [79.22, 77.92, 79.22, 75.32, 84.42, 79.22, 74.03, 75.0, 71.05, 77.63]\n",
        "    SWAG: [76.62, 74.03, 83.12, 75.32, 79.22, 79.22, 71.43, 77.63, 73.68, 77.63]\n",
        "    Hermite: [77.92, 74.03, 67.53, 74.03, 72.73, 77.92, 64.94, 76.32, 50.0, 65.79]\n",
        "    Legendre: [80.52, 77.92, 79.22, 77.92, 83.12, 79.22, 74.03, 80.26, 76.32, 77.63]\n",
        "    Sin(nX): [76.62, 77.92, 74.03, 75.32, 83.12, 76.62, 70.13, 76.32, 75.0, 77.63]\n",
        "    AutoKeras: [64.94, 64.94, 63.64, 64.94, 64.94, 64.94, 64.94, 65.79, 65.79, 65.79]\n",
        "\n",
        "Results after applying coefficients:\n",
        "\n",
        "    Chebyshev First Kind: [79.22, 75.32, 81.82, 72.73, 83.12, 79.22, 71.43, 78.95, 76.32, 78.95]\n",
        "    Chebyshev Second Kind: [80.52, 76.62, 83.12, 74.03, 83.12, 81.82, 71.43, 80.26, 72.37, 78.95]\n",
        "    Hermite: [79.22, 77.92, 79.22, 77.92, 84.42, 79.22, 72.73, 77.63, 75.0, 77.63]\n",
        "    Legendre: [72.73, 72.73, 80.52, 74.03, 83.12, 80.52, 70.13, 77.63, 72.37, 77.63]"
      ],
      "metadata": {
        "id": "QEP3WMMCn-8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#****** ******** ******* ******** ******* ******** ****** ********\n",
        "\n",
        "You have provided results for 7 different models on the Pima Indians Diabetes dataset using 10-fold cross-validation, as well as the results for 4 of the models after applying a coefficient. Let's analyze and compare the models before and after applying the coefficients:\n",
        "\n",
        "Before applying coefficients:\n",
        "\n",
        "    Chebyshev First kind\n",
        "    Mean Accuracy: 77.44%\n",
        "    Standard Deviation: 2.92%\n",
        "\n",
        "    Chebyshev Second kind\n",
        "    Mean Accuracy: 77.30%\n",
        "    Standard Deviation: 3.46%\n",
        "\n",
        "    SWAG\n",
        "    Mean Accuracy: 76.79%\n",
        "    Standard Deviation: 3.35%\n",
        "\n",
        "    Hermite\n",
        "    Mean Accuracy: 70.12%\n",
        "    Standard Deviation: 9.40%\n",
        "\n",
        "    Legendre\n",
        "    Mean Accuracy: 78.62%\n",
        "    Standard Deviation: 2.81%\n",
        "\n",
        "    Sin(nX)\n",
        "    Mean Accuracy: 76.27%\n",
        "    Standard Deviation: 3.72%\n",
        "\n",
        "    AutoKeras\n",
        "    Mean Accuracy: 65.06%\n",
        "    Standard Deviation: 0.62%\n",
        "\n",
        "After applying coefficients:\n",
        "\n",
        "    Chebyshev First kind (with coefficient)\n",
        "    Mean Accuracy: 77.71%\n",
        "    Standard Deviation: 3.49%\n",
        "\n",
        "    Chebyshev Second kind (with coefficient)\n",
        "    Mean Accuracy: 78.22%\n",
        "    Standard Deviation: 3.93%\n",
        "\n",
        "    Hermite (with coefficient)\n",
        "    Mean Accuracy: 78.09%\n",
        "    Standard Deviation: 2.98%\n",
        "\n",
        "    Legendre (with coefficient)\n",
        "    Mean Accuracy: 76.14%\n",
        "    Standard Deviation: 4.62%\n",
        "\n",
        "Comparison of results:\n",
        "\n",
        "    Chebyshev First kind: After applying the coefficient, the mean accuracy increased by 0.27%, and the standard deviation increased by 0.57%.\n",
        "    Chebyshev Second kind: The mean accuracy increased by 0.92%, and the standard deviation increased by 0.47% after applying the coefficient.\n",
        "    Hermite: The Hermite model significantly improved by 7.97% in mean accuracy, and the standard deviation decreased by 6.42% after applying the coefficient.\n",
        "    Legendre: After applying the coefficient, the mean accuracy decreased by 2.48%, and the standard deviation increased by 1.81%.\n",
        "\n",
        "After applying the coefficients, the Chebyshev Second kind model (with coefficient) has the highest mean accuracy at 78.22%, followed closely by Hermite (with coefficient) at 78.09%. The original Legendre model without coefficients also performs well with a mean accuracy of 78.62%. The AutoKeras model underperforms compared to the other models, with a mean accuracy of 65.06% and a very low standard deviation of 0.62%.\n"
      ],
      "metadata": {
        "id": "5KnGj-dQr2N0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##We ran 6 different models on the MNIST dataset. To analyze the results in detail, let's compare the models.\n",
        "\n",
        "Chebyshev First kind\n",
        "Training accuracy: [0.7724, 0.9235, 0.9396]\n",
        "Validation accuracy: [0.8948, 0.9210, 0.9462]\n",
        "\n",
        "Chebyshev Second kind\n",
        "Training accuracy: [0.6996, 0.8852, 0.9199]\n",
        "Validation accuracy: [0.8343, 0.8788, 0.9119]\n",
        "\n",
        "SWAG\n",
        "Training accuracy: [0.9112, 0.9667, 0.9776]\n",
        "Validation accuracy: [0.9588, 0.9681, 0.9769]\n",
        "\n",
        "Hermite\n",
        "Training accuracy: [0.1201, 0.1284, 0.1352]\n",
        "Validation accuracy: [0.1126, 0.1264, 0.1555]\n",
        "\n",
        "Legendre\n",
        "Training accuracy: [0.8807, 0.9651, 0.9754]\n",
        "Validation accuracy: [0.9548, 0.9705, 0.9681]\n",
        "\n",
        "Sin\n",
        "Training accuracy: [0.7284, 0.8764, 0.9013]\n",
        "Validation accuracy: [0.8681, 0.8533, 0.8686]\n",
        "\n",
        "After applying the coefficient, we observed new results for some of the models. Let's compare the updated results in detail.\n",
        "\n",
        "Chebyshev First kind\n",
        "Training accuracy: [0.8897, 0.9608, 0.9714]\n",
        "Validation accuracy: [0.9548, 0.9645, 0.9698]\n",
        "\n",
        "Chebyshev Second kind\n",
        "Training accuracy: [0.8820, 0.9599, 0.9712]\n",
        "Validation accuracy: [0.9560, 0.9614, 0.9674]\n",
        "\n",
        "Hermite\n",
        "Training accuracy: [0.8466, 0.9542, 0.9655]\n",
        "Validation accuracy: [0.9490, 0.9600, 0.9626]\n",
        "\n",
        "Legendre\n",
        "Training accuracy: [0.9004, 0.9618, 0.9723]\n",
        "Validation accuracy: [0.9581, 0.9671, 0.9714]\n"
      ],
      "metadata": {
        "id": "Jk6MGBrU6qs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#****** ******** ******* ******** ******* ******** ****** ********\n",
        "\n",
        "We analyzed the performance of six different models on the MNIST dataset based on their training and validation accuracy over three epochs. Here are the detailed results and comparisons:\n",
        "\n",
        "Ch_First:\n",
        "Training accuracy: [0.7724, 0.9235, 0.9396]\n",
        "Validation accuracy: [0.8948, 0.9210, 0.9462]\n",
        "- The Ch_First model demonstrated consistent improvement in both training and validation accuracy over the three epochs.\n",
        "- It performed better than Ch_second and Sin models but was outperformed by SWAG and Legendre models.\n",
        "\n",
        "Ch_second:\n",
        "Training accuracy: [0.6996, 0.8852, 0.9199]\n",
        "Validation accuracy: [0.8343, 0.8788, 0.9119]\n",
        "- Ch_second showed continuous improvement in both training and validation accuracy across the epochs.\n",
        "- It performed better than the Sin and Hermite models but was outperformed by Ch_First, SWAG, and Legendre models.\n",
        "\n",
        "SWAG:\n",
        "Training accuracy: [0.9112, 0.9667, 0.9776]\n",
        "Validation accuracy: [0.9588, 0.9681, 0.9769]\n",
        "- The SWAG model displayed the best performance among all six models with the highest training and validation accuracy in each epoch.\n",
        "- It significantly outperformed all other models, making it the top choice for the MNIST dataset.\n",
        "\n",
        "Hermite:\n",
        "Training accuracy: [0.1201, 0.1284, 0.1352]\n",
        "Validation accuracy: [0.1126, 0.1264, 0.1555]\n",
        "- The Hermite model exhibited poor performance with the lowest training and validation accuracy throughout all epochs.\n",
        "- Given its low performance, it is not suitable for the MNIST dataset and is outperformed by all other models.\n",
        "\n",
        "Legendre:\n",
        "Training accuracy: [0.8807, 0.9651, 0.9754]\n",
        "Validation accuracy: [0.9548, 0.9705, 0.9681]\n",
        "- The Legendre model showed strong performance with high training and validation accuracy across all epochs.\n",
        "- Although not as accurate as the SWAG model, it outperformed Ch_First, Ch_second, Sin, and Hermite models.\n",
        "\n",
        "Sin:\n",
        "Training accuracy: [0.7284, 0.8764, 0.9013]\n",
        "Validation accuracy: [0.8681, 0.8533, 0.8686]\n",
        "- The Sin model exhibited lower training and validation accuracy compared to most other models across all epochs.\n",
        "- Its performance was better than Hermite but lagged behind Ch_First, Ch_second, SWAG, and Legendre models.\n",
        "\n",
        "In conclusion, the SWAG model demonstrated the best performance on the MNIST dataset, followed by the Legendre model. The Ch_First and Ch_second models performed moderately well, while the Sin model showed weaker performance. The Hermite model was the least suitable for the MNIST dataset, as it performed poorly in all epochs."
      ],
      "metadata": {
        "id": "whVHlh7Y_I13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying a coefficient, new results have been obtained for some models. Below is a detailed comparison between the previous and new results after applying the coefficient:\n",
        "\n",
        "Ch_First (Previous):\n",
        "Training accuracy: [0.7724, 0.9235, 0.9396]\n",
        "Validation accuracy: [0.8948, 0.9210, 0.9462]\n",
        "\n",
        "Ch_First (New):\n",
        "Training accuracy: [0.8897, 0.9608, 0.9714]\n",
        "Validation accuracy: [0.9548, 0.9645, 0.9698]\n",
        "- The Ch_First model shows significant improvement in both training and validation accuracy after applying the coefficient.\n",
        "- The performance is now more in line with the SWAG and Legendre models from the previous comparison.\n",
        "\n",
        "Ch_second (Previous):\n",
        "Training accuracy: [0.6996, 0.8852, 0.9199]\n",
        "Validation accuracy: [0.8343, 0.8788, 0.9119]\n",
        "\n",
        "Ch_second (New):\n",
        "Training accuracy: [0.8820, 0.9599, 0.9712]\n",
        "Validation accuracy: [0.9560, 0.9614, 0.9674]\n",
        "- The Ch_second model also experienced a considerable improvement in both training and validation accuracy after applying the coefficient.\n",
        "- Its performance is now much closer to the SWAG and Legendre models from the previous comparison.\n",
        "\n",
        "Hermite (Previous):\n",
        "Training accuracy: [0.1201, 0.1284, 0.1352]\n",
        "Validation accuracy: [0.1126, 0.1264, 0.1555]\n",
        "\n",
        "Hermite (New):\n",
        "Training accuracy: [0.8466, 0.9542, 0.9655]\n",
        "Validation accuracy: [0.9490, 0.9600, 0.9626]\n",
        "- The Hermite model showed a dramatic improvement in both training and validation accuracy after applying the coefficient.\n",
        "- Its performance has significantly increased, making it a much more competitive model compared to the previous results.\n",
        "\n",
        "Legendre (Previous):\n",
        "Training accuracy: [0.8807, 0.9651, 0.9754]\n",
        "Validation accuracy: [0.9548, 0.9705, 0.9681]\n",
        "\n",
        "Legendre (New):\n",
        "Training accuracy: [0.9004, 0.9618, 0.9723]\n",
        "Validation accuracy: [0.9581, 0.9671, 0.9714]\n",
        "- The Legendre model exhibited a slight improvement in both training and validation accuracy after applying the coefficient.\n",
        "- Its performance was already strong in the previous comparison, and this improvement further strengthens its position.\n",
        "\n",
        "In summary, after applying the coefficient, the Ch_First, Ch_second, and Hermite models have shown significant improvement in their performance, with the Hermite model experiencing the most dramatic increase. The Legendre model also improved slightly. With these new results, all four models are now more competitive and closer in performance to the top-performing models from the previous comparison (SWAG and Legendre).\n"
      ],
      "metadata": {
        "id": "7QH24nRyxKqC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nS64CLSR768E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}