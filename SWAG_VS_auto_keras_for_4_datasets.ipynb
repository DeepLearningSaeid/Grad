{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "18993f35214f6d02bb40d8f7b5660171a3d9384a",
        "collapsed": true,
        "id": "rraZNltGZHsM"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3YC01S2UddSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SWAG-DNN==0.1.31\n",
        "!pip install autokeras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "tUF4enr0JAzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3a265a00b0b7f1012da45001f83a0d75598ab96b",
        "id": "lcfca3UeZHsk"
      },
      "source": [
        "from SWAG_DNN.taylor import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "epochs=5\n",
        "batch_size=1\n",
        "\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
        "cvscores = []\n",
        "\n",
        "list_fun=['Ch_First','Ch_second','SWAG','Hermite','Legendre','Sin']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_fun(X,Y,Input_size):\n",
        "    list_fun=list_fun=['Ch_First','Ch_second','SWAG','Hermite','Legendre','Sin']\n",
        "    temp = list()\n",
        "    for i in list_fun:\n",
        "        print('############################################################################################################################')\n",
        "        print('############################################################################################################################')\n",
        "        print('############################################################################################################################')\n",
        "        cvscores = []\n",
        "        print(i)\n",
        "        model_1=globals()[i](Input_size,Input_size,1)\n",
        "        print(model_1.summary())\n",
        "        a = np.zeros(shape=(11,))\n",
        "        index1=0\n",
        "\n",
        "        for train, test in kfold.split(X, Y):\n",
        "            model_1.fit(X[train], Y[train], epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "            scores = model_1.evaluate(X[test], Y[test], verbose=0)\n",
        "            print(\"%s: %.2f%%\" % (model_1.metrics_names[1], scores[1]*100))\n",
        "            cvscores.append(scores[1] * 100)\n",
        "            a[index1]=scores[1]*100\n",
        "            index1=index1+1\n",
        "        a[index1]=np.mean(cvscores)\n",
        "        temp.append(a)\n",
        "        print(\"The Mean accuracy is %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "    print('**************************************************************************************************')\n",
        "    print('**************************************************************************************************')\n",
        "    print('**************************************************************************************************')\n",
        "    print('**************************************************************************************************')\n",
        "    return temp"
      ],
      "metadata": {
        "id": "MK7UurXBR9Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_keras(X_,Y_):\n",
        "  a = np.zeros(shape=(10,))\n",
        "  index1=0\n",
        "\n",
        "  for train, test in kfold.split(X_, Y_):\n",
        "      model_1 = ak.StructuredDataClassifier(max_trials=10)\n",
        "      model_1.fit(X_[train], Y_[train], epochs=5,verbose=0)\n",
        "      scores = model_1.evaluate(X_[test], Y_[test], verbose=0)\n",
        "      print(\" %.2f%%\" % ( scores[1]*100))\n",
        "      cvscores.append(scores[1] * 100)\n",
        "      a[index1]=scores[1]*100\n",
        "      index1=index1+1\n",
        "      print(np.mean(cvscores))\n",
        "  print('**************************************************************************************************')\n",
        "\n",
        "def SWAG_per(X_,Y_,Input_size,Hidden_size,output_size):\n",
        "    model_1=SWAG(Input_size,Hidden_size,output_size)\n",
        "    print(model_1.summary())\n",
        "    a = np.zeros(shape=(10,))\n",
        "    index1=0\n",
        "\n",
        "    for train, test in kfold.split(X_, Y_):\n",
        "        model_1.fit(X_[train], Y_[train], epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "        scores = model_1.evaluate(X_[test], Y_[test], verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (model_1.metrics_names[1], scores[1]*100))\n",
        "        cvscores.append(scores[1] * 100)\n",
        "        a[index1]=scores[1]*100\n",
        "        index1=index1+1\n",
        "\n",
        "    print(np.mean(cvscores))\n",
        "    print('**************************************************************************************************')"
      ],
      "metadata": {
        "id": "jQ1iG2LREIzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "51659646ab1c7e1c87283d427e7bab1c9ddb58a6",
        "id": "g48shk8hZHsl"
      },
      "source": [
        "#  ========================================================\n",
        "# First experiment\n",
        "##  Load data of   ionosphere data set\n",
        "\n",
        "\n",
        "This is a small dataset that you can <a href=\"https://www.kaggle.com/creepyghost/uci-ionosphere/version/1\">download from the kaggle </a>.\n",
        "\n",
        "\n",
        "### About this file:\n",
        "\n",
        "Source: Donated to UCI Machine Learning Repository by\n",
        "\n",
        "Donor:\n",
        "\n",
        "Vince Sigillito (vgs '@' aplcen.apl.jhu.edu)\n",
        "\n",
        "Source:\n",
        "\n",
        "Space Physics Group Applied Physics Laboratory Johns Hopkins University Johns Hopkins Road Laurel, MD 20723"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9e664b718ffcf89c49865b7c16d56603692fe233",
        "id": "SLSQzg2dZHsl"
      },
      "source": [
        "dataframe = read_csv('https://raw.githubusercontent.com/DeepLearningSaeid/New-Type-of-Deep-Learning/master/ionosphere_data_kaggle.csv', header=1)\n",
        "dataset = dataframe.values\n",
        "\n",
        "#Number of Rows and columns\n",
        "Number_rows,Input_size=dataset.shape\n",
        "\n",
        "X = dataset[:,0:Input_size-1].astype(float)\n",
        "Y = dataset[:,Input_size-1]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "ionosphere=SWAG_per(X,Y,Input_size-1,2*Input_size-1,1)\n",
        "auto_keras(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "82656e0b85d7dba3468014dc7ed34ac6cf344c04",
        "id": "vW6TNFKoZHsl"
      },
      "source": [
        "### We use 10 k-fold Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "27eed7ff58cf82c8891be7a4897c3e6119787f15",
        "id": "-ZZFPLZXZHsn"
      },
      "source": [
        "#  ========================================================\n",
        "# Second experiment\n",
        "##  Load data of  banknote authentication Data Set \n",
        "\n",
        "This is a small dataset that you can <a href=\"https://www.kaggle.com/jacksonharper/data_banknote_authentication\">download from the kaggle </a>.\n",
        "\n",
        "\n",
        "### About this file:\n",
        "\n",
        "https://www.kaggle.com/jacksonharper/data_banknote_authentication\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bdb386302802d49db72877cf44748d603cc549f5",
        "id": "khT76wZ8ZHso"
      },
      "source": [
        "dataframe = read_csv('https://raw.githubusercontent.com/DeepLearningSaeid/New-Type-of-Deep-Learning/master/data_banknote_authentication.csv' , header=None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "\n",
        "#Number of Rows and columns\n",
        "Number_rows,Input_size=dataset.shape\n",
        "\n",
        "X = dataset[:,0:Input_size-1].astype(float)\n",
        "Y = dataset[:,Input_size-1]\n",
        "X=normalize(X)\n",
        "X=rescale_range(X)\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "SWAG_per(X,Y,Input_size-1,2*Input_size-1,1)\n",
        "auto_keras(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a4f3d1b35c0a260c3e5deb1d41278f4e1834e807",
        "id": "_JlzgL8OZHso"
      },
      "source": [
        "#  ========================================================\n",
        "# Third experiment\n",
        "##  Load data of  Connectionist Bench (Sonar)\n",
        "\n",
        "This is a small dataset that you can <a href=\"https://www.kaggle.com/adx891/sonar-data-set\">download from the kaggle </a>.\n",
        "\n",
        "\n",
        "### About this file:\n",
        "\n",
        "Connectionist Bench (Sonar, Mines vs. Rocks) Data Set Download: Data Folder, Data Set Description\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4994aeadde7ce8549562411b2762ec43746beecd",
        "id": "JK6MB5B6ZHsp"
      },
      "source": [
        "dataframe = read_csv('https://raw.githubusercontent.com/DeepLearningSaeid/New-Type-of-Deep-Learning/master/sonar.all-data.csv', header=None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "\n",
        "#Number of Rows and columns\n",
        "Number_rows,Input_size=dataset.shape\n",
        "\n",
        "X = dataset[:,0:Input_size-1].astype(float)\n",
        "Y = dataset[:,Input_size-1]\n",
        "X=normalize(X)\n",
        "X=rescale_range(X)\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "sonar=SWAG_per(X,Y,Input_size-1,2*Input_size-1,1)\n",
        "auto_keras(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f829d47ace8dfe21048d5d12fea8a401237b518c",
        "collapsed": true,
        "id": "XOkqgdbGZHsp"
      },
      "source": [
        "#  ========================================================\n",
        "# Fourth  experiment    \n",
        "##  Load data of  Pima Indians Diabetes Database\n",
        "\n",
        "\n",
        "\n",
        "This is a small dataset that you can <a href=\"https://www.kaggle.com/uciml/pima-indians-diabetes-database\">download from the kaggle </a>.\n",
        "\n",
        "\n",
        "### About this file:\n",
        "\n",
        "The datasets consist of several medical predictor (independent) variables and one target (dependent) variable, Outcome. Independent variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ccf19230a88cfcb598b90cb0bf06a8f4695005a8",
        "id": "CtmFc6KzZHsq"
      },
      "source": [
        "dataframe = read_csv('https://raw.githubusercontent.com/DeepLearningSaeid/New-Type-of-Deep-Learning/master/diabetes.csv', header=1)\n",
        "dataset = dataframe.values\n",
        "\n",
        "\n",
        "#Number of Rows and columns\n",
        "Number_rows,Input_size=dataset.shape\n",
        "\n",
        "X = dataset[:,0:Input_size-1].astype(float)\n",
        "Y = dataset[:,Input_size-1]\n",
        "X=normalize(X)\n",
        "X=rescale_range(X)\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "diabetes=SWAG_per(X,Y,Input_size-1,2*Input_size-1,1)\n",
        "auto_keras(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fd5da88ef403a8b98cc7e1296a2a560a20918346",
        "id": "ckJO8s0XZHsu"
      },
      "source": [
        "# Fifth experiment\n",
        "## Load data of THE MNIST DATABASE of handwritten digits\n",
        "\n",
        "## About this file:\n",
        "The MNIST database of handwritten digits, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKfTe9gQSSkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SWAG_per(X_,Y_,Input_size,Hidden_size,output_size):\n",
        "    model_1=SWAG(Input_size,Hidden_size,output_size)\n",
        "    print(model_1.summary())\n",
        "    a = np.zeros(shape=(10,))\n",
        "    index1=0\n",
        "\n",
        "    for train, test in kfold.split(X_, Y_):\n",
        "        model_1.fit(X_[train], Y_[train], epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "        scores = model_1.evaluate(X_[test], Y_[test], verbose=0)\n",
        "        print(\"%s: %.2f%%\" % (model_1.metrics_names[1], scores[1]*100))\n",
        "        cvscores.append(scores[1] * 100)\n",
        "        a[index1]=scores[1]*100\n",
        "        index1=index1+1\n",
        "\n",
        "    print(np.mean(cvscores))\n",
        "    print('**************************************************************************************************')"
      ],
      "metadata": {
        "id": "rIHWEoJqSaO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as tk\n",
        "import numpy as np\n",
        "mnist = tk.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "yAGfUY2bW1E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert x_train.shape == (60000, 28, 28)\n",
        "assert x_test.shape == (10000, 28, 28)\n",
        "assert y_train.shape == (60000,)\n",
        "assert y_test.shape == (10000,)\n",
        "x = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))"
      ],
      "metadata": {
        "id": "ah30kwWsWZgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=x+1\n",
        "x=x / 3.0\n",
        "input_shape = (784, 1) #tensorflow channels_last\n",
        "num_classes = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "x = x.reshape(x.shape[0],img_rows*img_cols).astype('float32')/255\n",
        "y = to_categorical(y, num_classes)"
      ],
      "metadata": {
        "id": "SLX4bRubWbS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SWAG_per(x,y,784,784,10)\n",
        "auto_keras(x,y)"
      ],
      "metadata": {
        "id": "EvfIaJFnSqnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/SWAG_VS_auto_keras_for_4_datasets.ipynb'\n",
        "from google.colab import files\n",
        "files.download(path)"
      ],
      "metadata": {
        "id": "gewBo-nAk3Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = read_csv('https://raw.githubusercontent.com/DeepLearningSaeid/New-Type-of-Deep-Learning/master/Iris.csv', header=1)\n",
        "\n",
        "dataset = dataframe.values\n",
        "\n",
        "#Number of Rows and columns\n",
        "Number_rows,Input_size=dataset.shape\n",
        "\n",
        "X = dataset[:,0:Input_size-1].astype(float)\n",
        "Y = dataset[:,Input_size-1]\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y = encoder.transform(Y)\n",
        "y = to_categorical(Y, 3)"
      ],
      "metadata": {
        "id": "Vwnn-z8adT4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SWAG_per(X,y,Input_size-1,Input_size-1,3)\n"
      ],
      "metadata": {
        "id": "vmPCnuJphl4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "pMgXknaLhtKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "laGWTYlYic1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}