{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Optimized%20SWAG_pythorch_needs_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras -q\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wzehVN0lPEpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def x_1(x):\n",
        "    return np.power(x, 1)\n",
        "\n",
        "def dx_1(x):\n",
        "    return np.ones_like(x)\n",
        "\n",
        "def x_2(x):\n",
        "    return np.power(x, 2) / 2\n",
        "\n",
        "def dx_2(x):\n",
        "    return x\n",
        "\n",
        "def x_2_(x):\n",
        "    return np.power(x, 2) / 24\n",
        "\n",
        "def dx_2_(x):\n",
        "    return x / 12\n",
        "\n",
        "def x_2__(x):\n",
        "    return np.power(x, 2) / 720\n",
        "\n",
        "def dx_2__(x):\n",
        "    return x / 360\n",
        "\n",
        "class OptimizedModel:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.dense1_x1_w = np.random.randn(input_dim, hidden_dim) * np.sqrt(2. / input_dim)\n",
        "        self.dense1_x1_b = np.zeros(hidden_dim)\n",
        "        self.dense1_x2_w = np.random.randn(input_dim, hidden_dim) * np.sqrt(2. / input_dim)\n",
        "        self.dense1_x2_b = np.zeros(hidden_dim)\n",
        "        self.dense2_w = np.random.randn(hidden_dim * 2, hidden_dim) * np.sqrt(2. / (hidden_dim * 2))\n",
        "        self.dense2_b = np.zeros(hidden_dim)\n",
        "        self.dense3_w = np.random.randn(hidden_dim, hidden_dim) * np.sqrt(2. / hidden_dim)\n",
        "        self.dense3_b = np.zeros(hidden_dim)\n",
        "        self.dense_out_w = np.random.randn(hidden_dim * 4, hidden_dim) * np.sqrt(2. / (hidden_dim * 4))\n",
        "        self.dense_out_b = np.zeros(hidden_dim)\n",
        "        self.final_out_w = np.random.randn(hidden_dim, output_dim) * np.sqrt(2. / hidden_dim)\n",
        "        self.final_out_b = np.zeros(output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        self.z1 = np.dot(x, self.dense1_x1_w) + self.dense1_x1_b\n",
        "        self.x1 = x_1(self.z1)\n",
        "        self.z2 = np.dot(x, self.dense1_x2_w) + self.dense1_x2_b\n",
        "        self.x2 = x_2(self.z2)\n",
        "        self.concat1 = np.concatenate((self.x1, self.x2), axis=1)\n",
        "\n",
        "        self.z3 = np.dot(self.concat1, self.dense2_w) + self.dense2_b\n",
        "        self.x3 = x_2_(self.z3)\n",
        "        self.z4 = np.dot(self.x3, self.dense3_w) + self.dense3_b\n",
        "        self.x4 = x_2__(self.z4)\n",
        "\n",
        "        self.concat2 = np.concatenate((self.concat1, self.x3, self.x4), axis=1)\n",
        "        self.out1 = np.dot(self.concat2, self.dense_out_w) + self.dense_out_b\n",
        "        self.out = np.dot(self.out1, self.final_out_w) + self.final_out_b\n",
        "\n",
        "        return self.out\n",
        "\n",
        "    def backward(self, y_true):\n",
        "        learning_rate = 0.01\n",
        "\n",
        "        # Compute gradient of loss w.r.t outputs\n",
        "        d_loss = 2 * (self.out - y_true)\n",
        "\n",
        "        # Backprop through final output layer\n",
        "        d_final_out_w = self.out1.T @ d_loss\n",
        "        d_final_out_b = np.sum(d_loss, axis=0)\n",
        "\n",
        "        # Update final layer weights\n",
        "        self.final_out_w -= learning_rate * d_final_out_w\n",
        "        self.final_out_b -= learning_rate * d_final_out_b\n",
        "\n",
        "        # Propagate through final layer\n",
        "        d_out1 = d_loss @ self.final_out_w.T\n",
        "\n",
        "        # Backprop through dense_out layer\n",
        "        d_dense_out_w = self.concat2.T @ d_out1\n",
        "        d_dense_out_b = np.sum(d_out1, axis=0)\n",
        "\n",
        "        # Update dense_out layer weights\n",
        "        self.dense_out_w -= learning_rate * d_dense_out_w\n",
        "        self.dense_out_b -= learning_rate * d_dense_out_b\n",
        "\n",
        "        # Propagate through dense_out\n",
        "        d_concat2 = d_out1 @ self.dense_out_w.T\n",
        "\n",
        "        # Separate gradients for earlier layers from concat2\n",
        "        d_concat1 = d_concat2[:, :self.hidden_dim*2]\n",
        "        d_x3 = d_concat2[:, self.hidden_dim*2:self.hidden_dim*3] * dx_2_(self.z3)\n",
        "        d_x4 = d_concat2[:, self.hidden_dim*3:] * dx_2__(self.z4)\n",
        "\n",
        "        # Propagate through dense3\n",
        "        d_dense3_w = self.x3.T @ d_x4\n",
        "        d_dense3_b = np.sum(d_x4, axis=0)\n",
        "        d_x3 += d_x4 @ self.dense3_w.T\n",
        "\n",
        "        # Update dense3 layer weights\n",
        "        self.dense3_w -= learning_rate * d_dense3_w\n",
        "        self.dense3_b -= learning_rate * d_dense3_b\n",
        "\n",
        "        # Propagate through dense2\n",
        "        d_dense2_w = self.concat1.T @ d_x3\n",
        "        d_dense2_b = np.sum(d_x3, axis=0)\n",
        "\n",
        "        # Update dense2 layer weights\n",
        "        self.dense2_w -= learning_rate * d_dense2_w\n",
        "        self.dense2_b -= learning_rate * d_dense2_b\n",
        "\n",
        "        # Separate gradients for x1 and x2 from concat1\n",
        "        d_x1 = d_concat1[:, :self.hidden_dim] * dx_1(self.z1)\n",
        "        d_x2 = d_concat1[:, self.hidden_dim:] * dx_2(self.z2)\n",
        "\n",
        "        # Propagate through dense1_x1\n",
        "        d_dense1_x1_w = self.x.T @ d_x1\n",
        "        d_dense1_x1_b = np.sum(d_x1, axis=0)\n",
        "\n",
        "        # Update dense1_x1 layer weights\n",
        "        self.dense1_x1_w -= learning_rate * d_dense1_x1_w\n",
        "        self.dense1_x1_b -= learning_rate * d_dense1_x1_b\n",
        "\n",
        "        # Propagate through dense1_x2\n",
        "        d_dense1_x2_w = self.x.T @ d_x2\n",
        "        d_dense1_x2_b = np.sum(d_x2, axis=0)\n",
        "\n",
        "        # Update dense1_x2 layer weights\n",
        "        self.dense1_x2_w -= learning_rate * d_dense1_x2_w\n",
        "        self.dense1_x2_b -= learning_rate * d_dense1_x2_b\n",
        "\n"
      ],
      "metadata": {
        "id": "zuICKVoPf_kS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DVEhnzrVkkSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZDg_EHg3kxe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}