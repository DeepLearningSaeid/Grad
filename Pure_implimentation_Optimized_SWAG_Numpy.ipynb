{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN23LKUGL+r9MmmEXLeuApW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepLearningSaeid/Grad/blob/main/Pure_implimentation_Optimized_SWAG_Numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Activation functions\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def square(x):\n",
        "    return np.power(x, 2)\n",
        "\n",
        "def identity_derivative(x):\n",
        "    return np.ones_like(x)\n",
        "\n",
        "def square_derivative(x):\n",
        "    return 2 * x\n",
        "\n",
        "# Initialize network parameters\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, output_size):\n",
        "    return {\n",
        "        'W1': np.random.randn(input_size, hidden_size1) * 0.1,\n",
        "        'b1': np.zeros((1, hidden_size1)),\n",
        "        'W2': np.random.randn(input_size, hidden_size2) * 0.1,\n",
        "        'b2': np.zeros((1, hidden_size2)),\n",
        "        'W3': np.random.randn(hidden_size1 + hidden_size2, output_size) * 0.1,\n",
        "        'b3': np.zeros((1, output_size))\n",
        "    }\n",
        "\n",
        "# Forward pass\n",
        "def forward_pass(X, params):\n",
        "    Z1 = np.dot(X, params['W1']) + params['b1']\n",
        "    A1 = identity(Z1)\n",
        "\n",
        "    Z2 = np.dot(X, params['W2']) + params['b2']\n",
        "    A2 = square(Z2)\n",
        "\n",
        "    concatenated = np.concatenate((A1, A2), axis=1)\n",
        "\n",
        "    Z3 = np.dot(concatenated, params['W3']) + params['b3']\n",
        "    A3 = square(Z3)\n",
        "\n",
        "    return A3, (X, Z1, A1, Z2, A2, Z3, A3, concatenated)\n",
        "\n",
        "# Compute loss (Mean Squared Error)\n",
        "def compute_loss(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "# Backward pass\n",
        "def backward_pass(y_true, cache, params):\n",
        "    X, Z1, A1, Z2, A2, Z3, A3, concatenated = cache\n",
        "\n",
        "    dA3 = 2 * (A3 - y_true)\n",
        "    dZ3 = dA3 * square_derivative(Z3)\n",
        "    dW3 = np.dot(concatenated.T, dZ3)\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "    d_concatenated = np.dot(dZ3, params['W3'].T)\n",
        "    dA1, dA2 = d_concatenated[:, :hidden_size1], d_concatenated[:, hidden_size1:]\n",
        "\n",
        "    dZ1 = dA1 * identity_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    dZ2 = dA2 * square_derivative(Z2)\n",
        "    dW2 = np.dot(X.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2, 'dW3': dW3, 'db3': db3}\n",
        "    return grads\n",
        "\n",
        "# Update network parameters\n",
        "def update_parameters(params, grads, learning_rate):\n",
        "    for key in params.keys():\n",
        "        params[key] -= learning_rate * grads['d' + key]\n",
        "    return params\n",
        "\n",
        "# Load and preprocess the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "Y_onehot = np.eye(3)[y]  # Convert to one-hot encoding\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Network architecture\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 5\n",
        "hidden_size2 = 5\n",
        "output_size = 3\n",
        "\n",
        "# Initialize parameters\n",
        "params = initialize_parameters(input_size, hidden_size1, hidden_size2, output_size)\n",
        "\n",
        "# Training settings\n",
        "epochs = 200\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    output, cache = forward_pass(X_train, params)\n",
        "    loss = compute_loss(Y_train, output)\n",
        "    grads = backward_pass(Y_train, cache, params)\n",
        "    params = update_parameters(params, grads, learning_rate)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "output_test, _ = forward_pass(X_test, params)\n",
        "test_loss = compute_loss(Y_test, output_test)\n",
        "predictions = np.argmax(output_test, axis=1)\n",
        "# Convert predictions to one-hot encoded format\n",
        "predictions_onehot = np.eye(output_size)[predictions]\n",
        "\n",
        "# Compute accuracy using one-hot encoded predictions\n",
        "accuracy = np.mean(np.all(predictions_onehot == Y_test, axis=1))\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "lkkAcYvnRl4V",
        "outputId": "a0c5d887-7ad0-4661-fdc7-f8dd6a05d02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3313\n",
            "Epoch 20, Loss: 0.1103\n",
            "Epoch 40, Loss: 0.0825\n",
            "Epoch 60, Loss: 0.0697\n",
            "Epoch 80, Loss: 0.0413\n",
            "Epoch 100, Loss: 0.0320\n",
            "Epoch 120, Loss: 0.0292\n",
            "Epoch 140, Loss: 0.0389\n",
            "Epoch 160, Loss: 0.0352\n",
            "Epoch 180, Loss: 0.0333\n",
            "Test Loss: 0.0705\n",
            "Test Accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Activation functions\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def square(x):\n",
        "    return np.power(x, 2)\n",
        "\n",
        "def identity_derivative(x):\n",
        "    return np.ones_like(x)\n",
        "\n",
        "def square_derivative(x):\n",
        "    return 2 * x\n",
        "\n",
        "# Initialize network parameters\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "    return {\n",
        "        'W1': np.random.randn(input_size, hidden_size1) * 0.1,\n",
        "        'b1': np.zeros((1, hidden_size1)),\n",
        "        'W2': np.random.randn(input_size, hidden_size2) * 0.1,\n",
        "        'b2': np.zeros((1, hidden_size2)),\n",
        "        'W3': np.random.randn(hidden_size1 + hidden_size2, hidden_size3) * 0.1,\n",
        "        'b3': np.zeros((1, hidden_size3)),\n",
        "        'W4': np.random.randn(hidden_size3, output_size) * 0.1,\n",
        "        'b4': np.zeros((1, output_size))\n",
        "    }\n",
        "\n",
        "# Forward pass\n",
        "def forward_pass(X, params):\n",
        "    Z1 = np.dot(X, params['W1']) + params['b1']\n",
        "    A1 = identity(Z1)\n",
        "\n",
        "    Z2 = np.dot(X, params['W2']) + params['b2']\n",
        "    A2 = square(Z2)\n",
        "\n",
        "    concatenated = np.concatenate((A1, A2), axis=1)\n",
        "\n",
        "    Z3 = np.dot(concatenated, params['W3']) + params['b3']\n",
        "    A3 = square(Z3)\n",
        "\n",
        "\n",
        "    Z4 = np.dot(A3, params['W4']) + params['b4']\n",
        "    A4 = identity(Z4)  # Linear activation\n",
        "\n",
        "    return A4, (X, Z1, A1, Z2, A2, Z3, A3, Z4, A4, concatenated)\n",
        "\n",
        "# Compute loss (Mean Squared Error)\n",
        "def compute_loss(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "# Backward pass\n",
        "def backward_pass(y_true, cache, params):\n",
        "    X, Z1, A1, Z2, A2, Z3, A3, Z4, A4, concatenated = cache\n",
        "\n",
        "    dA4 = 2 * (A4 - y_true)\n",
        "    dZ4 = dA4 * identity_derivative(Z4)  # Derivative of linear activation is 1\n",
        "    dW4 = np.dot(A3.T, dZ4)\n",
        "    db4 = np.sum(dZ4, axis=0, keepdims=True)\n",
        "\n",
        "    dA3 = np.dot(dZ4, params['W4'].T)\n",
        "    dZ3 = dA3 * square_derivative(Z3)\n",
        "    dW3 = np.dot(concatenated.T, dZ3)\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "    d_concatenated = np.dot(dZ3, params['W3'].T)\n",
        "    dA1, dA2 = d_concatenated[:, :hidden_size1], d_concatenated[:, hidden_size1:]\n",
        "\n",
        "    dZ1 = dA1 * identity_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    dZ2 = dA2 * square_derivative(Z2)\n",
        "    dW2 = np.dot(X.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2, 'dW3': dW3, 'db3': db3, 'dW4': dW4, 'db4': db4}\n",
        "    return grads\n",
        "\n",
        "# Update network parameters\n",
        "def update_parameters(params, grads, learning_rate):\n",
        "    for key in params.keys():\n",
        "        params[key] -= learning_rate * grads['d' + key]\n",
        "    return params\n",
        "\n",
        "# Load and preprocess the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "Y_onehot = np.eye(3)[y]  # Convert to one-hot encoding\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Network architecture\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 5\n",
        "hidden_size2 = 5\n",
        "hidden_size3 = 5\n",
        "output_size = 3\n",
        "\n",
        "# Initialize parameters\n",
        "params = initialize_parameters(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)\n",
        "\n",
        "# Training settings\n",
        "epochs = 200\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    output, cache = forward_pass(X_train, params)\n",
        "    loss = compute_loss(Y_train, output)\n",
        "    grads = backward_pass(Y_train, cache, params)\n",
        "    params = update_parameters(params, grads, learning_rate)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "output_test, _ = forward_pass(X_test, params)\n",
        "test_loss = compute_loss(Y_test, output_test)\n",
        "predictions = np.argmax(output_test, axis=1)\n",
        "# Convert predictions to one-hot encoded format\n",
        "predictions_onehot = np.eye(output_size)[predictions]\n",
        "\n",
        "# Compute accuracy using one-hot encoded predictions\n",
        "accuracy = np.mean(np.all(predictions_onehot == Y_test, axis=1))\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "ct7XnKWhcBTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9021d41-4906-4719-cb57-5bc014eaf8c4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3336\n",
            "Epoch 20, Loss: 0.2219\n",
            "Epoch 40, Loss: 0.2210\n",
            "Epoch 60, Loss: 0.2169\n",
            "Epoch 80, Loss: 0.1628\n",
            "Epoch 100, Loss: 0.1215\n",
            "Epoch 120, Loss: 0.1140\n",
            "Epoch 140, Loss: 0.0881\n",
            "Epoch 160, Loss: 0.0454\n",
            "Epoch 180, Loss: 0.0337\n",
            "Test Loss: 0.0847\n",
            "Test Accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Activation functions\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def square(x):\n",
        "    return np.power(x, 2)/4\n",
        "\n",
        "def square_(x):\n",
        "    return np.power(x, 2)/24\n",
        "\n",
        "def identity_derivative(x):\n",
        "    return np.ones_like(x)\n",
        "\n",
        "def square_derivative(x):\n",
        "    return 2 * x\n",
        "\n",
        "# Initialize network parameters\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "    return {\n",
        "        'W1': np.random.randn(input_size, hidden_size1) * 0.1,\n",
        "        'b1': np.zeros((1, hidden_size1)),\n",
        "        'W2': np.random.randn(input_size, hidden_size2) * 0.1,\n",
        "        'b2': np.zeros((1, hidden_size2)),\n",
        "        'W3': np.random.randn(hidden_size1 + hidden_size2, hidden_size3) * 0.1,\n",
        "        'b3': np.zeros((1, hidden_size3)),\n",
        "        'W4': np.random.randn(hidden_size3 + hidden_size1 + hidden_size2, output_size) * 0.1,\n",
        "        'b4': np.zeros((1, output_size))\n",
        "    }\n",
        "\n",
        "# Forward pass\n",
        "def forward_pass(X, params):\n",
        "    Z1 = np.dot(X, params['W1']) + params['b1']\n",
        "    A1 = identity(Z1)\n",
        "\n",
        "    Z2 = np.dot(X, params['W2']) + params['b2']\n",
        "    A2 = square(Z2)\n",
        "\n",
        "    concatenated = np.concatenate((A1, A2), axis=1)\n",
        "\n",
        "    Z3 = np.dot(concatenated, params['W3']) + params['b3']\n",
        "    A3 = square_(Z3)\n",
        "\n",
        "    concatenated_A3 = np.concatenate((A3, concatenated), axis=1)\n",
        "\n",
        "    Z4 = np.dot(concatenated_A3, params['W4']) + params['b4']\n",
        "    A4 = identity(Z4)  # Linear activation\n",
        "\n",
        "    return A4, (X, Z1, A1, Z2, A2, Z3, A3, concatenated_A3, Z4, A4, concatenated)\n",
        "\n",
        "# Compute loss (Mean Squared Error)\n",
        "def compute_loss(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "# Backward pass\n",
        "def backward_pass(y_true, cache, params):\n",
        "    X, Z1, A1, Z2, A2, Z3, A3, concatenated_A3, Z4, A4, concatenated = cache\n",
        "\n",
        "    dA4 = 2 * (A4 - y_true)\n",
        "    dZ4 = dA4 * identity_derivative(Z4)  # Derivative of linear activation is 1\n",
        "    dW4 = np.dot(concatenated_A3.T, dZ4)\n",
        "    db4 = np.sum(dZ4, axis=0, keepdims=True)\n",
        "\n",
        "    d_concatenated_A3 = np.dot(dZ4, params['W4'].T)\n",
        "    dA3 = d_concatenated_A3[:, :hidden_size3]\n",
        "    d_concatenated = d_concatenated_A3[:, hidden_size3:]\n",
        "\n",
        "    dZ3 = dA3 * square_derivative(Z3)\n",
        "    dW3 = np.dot(concatenated.T, dZ3)\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "    dA2 = d_concatenated[:, hidden_size1:]  # Corrected dA2 calculation\n",
        "    d_concatenated_Z2 = dA2 * square_derivative(Z2)\n",
        "\n",
        "    dA1 = d_concatenated[:, :hidden_size1]\n",
        "    dZ1 = dA1 * identity_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    dZ2 = d_concatenated_Z2\n",
        "    dW2 = np.dot(X.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2, 'dW3': dW3, 'db3': db3, 'dW4': dW4, 'db4': db4}\n",
        "    return grads\n",
        "\n",
        "# Update network parameters\n",
        "def update_parameters(params, grads, learning_rate):\n",
        "    for key in params.keys():\n",
        "        params[key] -= learning_rate * grads['d' + key]\n",
        "    return params\n",
        "\n",
        "# Load and preprocess the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "Y_onehot = np.eye(3)[y]\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Network architecture\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 5\n",
        "hidden_size2 = 5\n",
        "hidden_size3 = 5\n",
        "output_size = 3\n",
        "\n",
        "# Initialize parameters\n",
        "params = initialize_parameters(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)\n",
        "\n",
        "# Training settings\n",
        "epochs = 200\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    output, cache = forward_pass(X_train, params)\n",
        "    loss = compute_loss(Y_train, output)\n",
        "    grads = backward_pass(Y_train, cache, params)\n",
        "    params = update_parameters(params, grads, learning_rate)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "output_test, _ = forward_pass(X_test, params)\n",
        "test_loss = compute_loss(Y_test, output_test)\n",
        "predictions = np.argmax(output_test, axis=1)\n",
        "predictions_onehot = np.eye(output_size)[predictions]\n",
        "accuracy = np.mean(np.all(predictions_onehot == Y_test, axis=1))\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxIbYV68iOcK",
        "outputId": "4a69dd92-bb12-484b-8593-3449cc3cdda2"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3276\n",
            "Epoch 20, Loss: 0.1047\n",
            "Epoch 40, Loss: 0.0735\n",
            "Epoch 60, Loss: 0.0500\n",
            "Epoch 80, Loss: 0.0397\n",
            "Epoch 100, Loss: 0.0356\n",
            "Epoch 120, Loss: 0.0339\n",
            "Epoch 140, Loss: 0.0330\n",
            "Epoch 160, Loss: 0.0517\n",
            "Epoch 180, Loss: 0.0486\n",
            "Test Loss: 0.0552\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Activation functions\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def square(x):\n",
        "    return np.power(x, 2)/4\n",
        "\n",
        "def square_(x):\n",
        "    return np.power(x, 2)/24\n",
        "\n",
        "def identity_derivative(x):\n",
        "    return np.ones_like(x)\n",
        "\n",
        "def square_derivative(x):\n",
        "    return 2 * x\n",
        "\n",
        "# Initialize network parameters\n",
        "def initialize_parameters(input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "    return {\n",
        "        'W1': np.random.randn(input_size, hidden_size1) * 0.1,\n",
        "        'b1': np.zeros((1, hidden_size1)),\n",
        "        'W2': np.random.randn(input_size, hidden_size2) * 0.1,\n",
        "        'b2': np.zeros((1, hidden_size2)),\n",
        "        'W3': np.random.randn(hidden_size1 + hidden_size2, hidden_size3) * 0.1,\n",
        "        'b3': np.zeros((1, hidden_size3)),\n",
        "        'W4': np.random.randn(hidden_size3 + hidden_size1 + hidden_size2, output_size) * 0.1,\n",
        "        'b4': np.zeros((1, output_size))\n",
        "    }\n",
        "\n",
        "# Forward pass\n",
        "def forward_pass(X, params):\n",
        "    Z1 = np.dot(X, params['W1']) + params['b1']\n",
        "    A1 = identity(Z1)\n",
        "\n",
        "    Z2 = np.dot(X, params['W2']) + params['b2']\n",
        "    A2 = square(Z2)\n",
        "\n",
        "    concatenated = np.concatenate((A1, A2), axis=1)\n",
        "\n",
        "    Z3 = np.dot(concatenated, params['W3']) + params['b3']\n",
        "    A3 = square_(Z3)\n",
        "\n",
        "    concatenated_A3 = np.concatenate((A3, concatenated), axis=1)\n",
        "\n",
        "    Z4 = np.dot(concatenated_A3, params['W4']) + params['b4']\n",
        "    A4 = identity(Z4)  # Linear activation\n",
        "\n",
        "    return A4, (X, Z1, A1, Z2, A2, Z3, A3, concatenated_A3, Z4, A4, concatenated)\n",
        "\n",
        "# Compute loss (Mean Squared Error)\n",
        "def compute_loss(y_true, y_pred):\n",
        "    return np.mean(np.square(y_true - y_pred))\n",
        "\n",
        "# Backward pass\n",
        "def backward_pass(y_true, cache, params):\n",
        "    X, Z1, A1, Z2, A2, Z3, A3, concatenated_A3, Z4, A4, concatenated = cache\n",
        "\n",
        "    dA4 = 2 * (A4 - y_true)\n",
        "    dZ4 = dA4 * identity_derivative(Z4)  # Derivative of linear activation is 1\n",
        "    dW4 = np.dot(concatenated_A3.T, dZ4)\n",
        "    db4 = np.sum(dZ4, axis=0, keepdims=True)\n",
        "\n",
        "    d_concatenated_A3 = np.dot(dZ4, params['W4'].T)\n",
        "    dA3 = d_concatenated_A3[:, :hidden_size3]\n",
        "    d_concatenated = d_concatenated_A3[:, hidden_size3:]\n",
        "\n",
        "    dZ3 = dA3 * square_derivative(Z3)\n",
        "    dW3 = np.dot(concatenated.T, dZ3)\n",
        "    db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "    dA2 = d_concatenated[:, hidden_size1:]  # Corrected dA2 calculation\n",
        "    d_concatenated_Z2 = dA2 * square_derivative(Z2)\n",
        "\n",
        "    dA1 = d_concatenated[:, :hidden_size1]\n",
        "    dZ1 = dA1 * identity_derivative(Z1)\n",
        "    dW1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    dZ2 = d_concatenated_Z2\n",
        "    dW2 = np.dot(X.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "    grads = {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2, 'dW3': dW3, 'db3': db3, 'dW4': dW4, 'db4': db4}\n",
        "    return grads\n",
        "\n",
        "# Update network parameters\n",
        "def update_parameters(params, grads, learning_rate):\n",
        "    for key in params.keys():\n",
        "        params[key] -= learning_rate * grads['d' + key]\n",
        "    return params\n",
        "\n",
        "# Load and preprocess the Breast Cancer Wisconsin dataset\n",
        "breast_cancer = load_breast_cancer()\n",
        "X, y = breast_cancer.data, breast_cancer.target\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "Y_onehot = np.eye(2)[y]  # One-hot encode target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Network architecture\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 5\n",
        "hidden_size2 = 5\n",
        "hidden_size3 = 5\n",
        "output_size = 2  # Two classes: benign and malignant\n",
        "\n",
        "# Initialize parameters\n",
        "params = initialize_parameters(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)\n",
        "\n",
        "# Training settings\n",
        "epochs = 200\n",
        "learning_rate = 0.00001\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    output, cache = forward_pass(X_train, params)\n",
        "    loss = compute_loss(Y_train, output)\n",
        "    grads = backward_pass(Y_train, cache, params)\n",
        "    params = update_parameters(params, grads, learning_rate)\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "# Evaluate the model\n",
        "output_test, _ = forward_pass(X_test, params)\n",
        "test_loss = compute_loss(Y_test, output_test)\n",
        "predictions = np.argmax(output_test, axis=1)\n",
        "predictions_onehot = np.eye(output_size)[predictions]\n",
        "accuracy = np.mean(np.all(predictions_onehot == Y_test, axis=1))\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "fFpUX6rCBB6z",
        "outputId": "c3602985-8de1-4493-fee3-0b2e46ca449a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.5474\n",
            "Epoch 20, Loss: 0.3874\n",
            "Epoch 40, Loss: 0.2831\n",
            "Epoch 60, Loss: 0.2106\n",
            "Epoch 80, Loss: 0.1623\n",
            "Epoch 100, Loss: 0.1320\n",
            "Epoch 120, Loss: 0.1132\n",
            "Epoch 140, Loss: 0.1013\n",
            "Epoch 160, Loss: 0.0936\n",
            "Epoch 180, Loss: 0.0885\n",
            "Test Loss: 0.0783\n",
            "Test Accuracy: 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DZVS8akICEa1"
      },
      "execution_count": 116,
      "outputs": []
    }
  ]
}